{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#script to read in .csv output files from SmartRoot analysis, concatenate them and then analyse and make plots\n",
    "#use qpcr conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob \n",
    "import sys\n",
    "import argparse\n",
    "import statsmodels.api as sm\n",
    "#sats annotations\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "from bioinfokit.analys import stat\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "#estimated marginal mean contrasts\n",
    "from pymer4.utils import get_resource_path\n",
    "from pymer4.models import Lmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #define arguments\n",
    "# parser = argparse.ArgumentParser(description='Analyse SmartRoot output')\n",
    "# parser.add_argument('-i', '--input', help='input directory', required=True)\n",
    "# parser.add_argument('-o', '--output', help='output directory', required=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to recursively find all .csv files in a directory and concatenate them into a single dataframe\n",
    "def concat_csv_recursive(PATH, EXT):\n",
    "    #find all .csv files in the directory\n",
    "    csv_files = [file for path, subdir, fname in os.walk(PATH) \n",
    "                for file in glob.glob(os.path.join(path, EXT))]\n",
    "        #glob.glob(f'{directory}/{EXT}', recursive=True)\n",
    "    #print(csv_files)\n",
    "    #initialise empty dataframe\n",
    "    df = pd.DataFrame()\n",
    "    #loop through all files and concatenate them into a single dataframe\n",
    "    for file in csv_files:\n",
    "        df = pd.concat([df, pd.read_csv(file)], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_data(df,output_location):\n",
    "    #sort dataframe by sample name\n",
    "    df = df.sort_values(by=['image'])\n",
    "    #remove duplicate rows\n",
    "    df = df.drop_duplicates(keep='first')\n",
    "    #make nitrate concentration column using image column\n",
    "    df['nitrate_concentration'] = df['image'].str.split('_').str[1]\n",
    "    #make sample name column using image column\n",
    "    df['sample_name'] = df['image'].str.split('_').str[0]\n",
    "    #make plate column\n",
    "    df['plate'] = df['sample_name']+'_'+df['image'].str.split('_').str[2]\n",
    "    #remove spaces from column names\n",
    "    df.columns = df.columns.str.replace(' ', '')\n",
    "   \n",
    "    \n",
    "    #make several new columns\n",
    "    #first make new df which will contain one row per plant\n",
    "    df_plant = df[df.root_order == 0]\n",
    "    #remove all lines which have no length or which are NaN\n",
    "    df_plant = df_plant[df_plant.length.notnull()]\n",
    "    #df_plant = df_plant[df_plant.length != 0]\n",
    "    # df_plant = df.groupby(['sample_name', 'plate', 'nitrate_concentration',root_ontology]).agg({'image':'count', 'nitrate_concentration':'first', 'sample_name':'first', 'plate':'first'})\n",
    "    #print(df_plant)\n",
    "    ## PR = primary root length (cm)\n",
    "    #change length column to PR\n",
    "    df_plant['PR'] = df_plant['length']\n",
    "    # LR = lateral root number (visible from scan)\n",
    "    #for each root in df_plant, count the number of rows whose parent root in df is the same as the root id in df_plant\n",
    "    df_plant['LR'] = df_plant.apply(lambda row: df[(df.parent == row.root) & (df.root_order == 1)].shape[0], axis=1)\n",
    "    #make list of first order lateral root ids\n",
    "    df_plant['LR_ids'] = df_plant.apply(lambda row: df[(df.parent == row.root) & (df.root_order == 1)].root.tolist(), axis=1)\n",
    "    #for each id in LR_ids, count the number of rows whose parent root in df is the same as the root id \n",
    "    df_plant['LR_2nd_order'] = df_plant.apply(lambda row: df[(df.parent.isin(row.LR_ids)) & (df.root_order == 2)].shape[0], axis=1)\n",
    "    # LRL = total lateral root length (all LRs added together - cm). Have separate column for 2nd order lateral roots\n",
    "    \n",
    "    df_plant['LRL_1st_order'] = df_plant.apply(lambda row: df[(df.parent == row.root) & (df.root_order == 1)].length.sum(), axis=1)\n",
    "    df_plant['LRL_2nd_order'] = df_plant.apply(lambda row: df[(df.parent.isin(row.LR_ids)) & (df.root_order == 2)].length.sum(), axis=1)\n",
    "    #add LRL and 2nd order LRL to get total LRL\n",
    "    df_plant['LRL'] = df_plant['LRL_1st_order'] + df_plant['LRL_2nd_order']\n",
    "    # ALRL = average lateral root length (LRL/LR - cm)\n",
    "    df_plant['ALRL'] = (df_plant.LRL) / (df_plant.LR)\n",
    "   # df_plant['ALRL'] = df_plant.apply(lambda row: (row.LRL / row.LR, axis=1)\n",
    "    # TRL = total root length (PR + LRL)\n",
    "    df_plant['TRL'] = df_plant.PR + df_plant.LRL\n",
    "    # LRD = lateral root density (LR/PR)\n",
    "    df_plant['LRD'] = df_plant.LR / df_plant.PR\n",
    "    # LRL_div_TRL = percentage of LRL contributing to TRL (LRL/TRL)\n",
    "    df_plant['LRL_div_TRL'] = (df_plant.LRL) / df_plant.TRL\n",
    "\n",
    "    #add genotype column\n",
    "    df_plant['genotype'] = df_plant['root_name'].str.split('_').str[0]\n",
    "    #remove spaces from genotype\n",
    "    df_plant['genotype'] = df_plant['genotype'].str.replace(' ', '')\n",
    "\n",
    "    #add log columns for PR, LR, LR_2nd_order, LRL, LRL_2nd_order. ALRL, TRL, LRD, LRL_div_TRL\n",
    "    df_plant['log_PR'] = np.log(df_plant.PR)\n",
    "    df_plant['log_LR'] = np.log(df_plant.LR)\n",
    "    df_plant['log_LR_2nd_order'] = np.log(df_plant.LR_2nd_order)\n",
    "    df_plant['log_LRL'] = np.log(df_plant.LRL)\n",
    "    df_plant['LRL_1st_order'] = df_plant.LRL_1st_order\n",
    "    df_plant['log_LRL_2nd_order'] = np.log(df_plant.LRL_2nd_order)\n",
    "    df_plant['log_ALRL'] = np.log(df_plant.ALRL)\n",
    "    df_plant['log_TRL'] = np.log(df_plant.TRL)\n",
    "    df_plant['log_LRD'] = np.log(df_plant.LRD)\n",
    "    df_plant['log_LRL_div_TRL'] = np.log(df_plant.LRL_div_TRL)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #save df as tsv file\n",
    "    df_plant.to_csv(f'{output_location}/single_plant_data.tsv', sep='\\t', index=False)\n",
    "    #count number of plants for each plant line\n",
    "\n",
    "    #partition variation across mutants relative to wild type using principal component analysis of all RSA traits\n",
    "    #do stats: Using a two-way ANOVA, three phenotypic categories: genotype effects in both nitrogen conditions (genotype-dependent), genotype effects in only one condition (nitrogen-condition-dependent) or genotype by nitrogen condition-dependent effects \n",
    "    \n",
    "\n",
    "    #print(len(df))\n",
    "    return df, df_plant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set matplotlib rc parameters\n",
    "def set_rc_params():\n",
    "    #set matplotlib default parameters\n",
    "    rcParams['xtick.major.width'] = 2\n",
    "    rcParams['ytick.major.width'] = 2\n",
    "    rcParams['axes.linewidth'] = 2\n",
    "    rcParams['lines.linewidth'] = 2\n",
    "    #remove top and right lines\n",
    "    rcParams['axes.spines.top'] = False\n",
    "    rcParams['axes.spines.right'] = False\n",
    "    #font size\n",
    "    fontsize = 14\n",
    "    rcParams['font.size'] = fontsize\n",
    "    #for getting the microsoft font Arial working, please follow this guide: https://alexanderlabwhoi.github.io/post/2021-03-missingfont/\n",
    "    rcParams['font.family'] = 'sans-serif'\n",
    "    rcParams['font.sans-serif'] = ['Arial']\n",
    "    #allow font to be edited later in pdf editor\n",
    "    #make svg text editable\n",
    "    rcParams['svg.fonttype'] = 'none'\n",
    "    rcParams ['pdf.fonttype'] = 42 \n",
    "    #align y-axis top most tick with end of axis\n",
    "    rcParams['axes.autolimit_mode'] = 'round_numbers'\n",
    "    #set margins to ensure any error bars fit\n",
    "    rcParams['axes.xmargin'] = 0.2\n",
    "    rcParams['axes.ymargin'] = 0.2\n",
    "    #define bar width\n",
    "    #bar_width = 0.65\n",
    "    #allow math text to be displayed\n",
    "    #rcParams['mathtext.default'] = 'regular'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qqplots(df,variables,sample_name, output_location):\n",
    "        \"\"\"function to make qq plots\"\"\"\n",
    "        #make qq plots for each variable\n",
    "        for var in variables:\n",
    "            #run anova\n",
    "            #only run if not empty array\n",
    "            try:\n",
    "\n",
    "                anova = smf.ols(f'{var} ~ genotype*nitrate_concentration + plate', data=df).fit()\n",
    "                #make qq  of residuals\n",
    "                _ = sm.qqplot(anova.resid, line='s')\n",
    "\n",
    "                \n",
    "                #save figure\n",
    "                plt.savefig(f'{output_location}/qqplot_{var}_{sample_name}_residuals.svg',format=\"svg\",\n",
    "                                    bbox_inches=\"tight\",transparent=True)\n",
    "                plt.cla()\n",
    "                plt.close('all')\n",
    "        \n",
    "            except ValueError:\n",
    "                print(f'{sample_name}_{var} is empty array, skipping')\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(df,var,y_label,sample_name,box_pair_p_values, output_location):\n",
    "    \"\"\"function to make box plots\"\"\"\n",
    "    #print(df.genotype.unique())\n",
    "    #print(df.nitrate_concentration.unique())\n",
    "    #make box plot\n",
    "    #print(df.genotype.unique())\n",
    "    #print(box_pair_p_values)\n",
    "    #filter dict by significance and put in a new dictionary\n",
    "    # box_pairs_significant = {}\n",
    "    # for k,v in box_pair_p_values.items():\n",
    "    #     if v <0.05:\n",
    "    #         box_pairs_significant[k] = v\n",
    "\n",
    "    # def convert_pvalue_to_asterisks(pvalue):\n",
    "    #     if pvalue <= 0.001:\n",
    "    #         return \"***\"\n",
    "    #     elif pvalue <= 0.01:\n",
    "    #         return \"**\"\n",
    "    #     elif pvalue <= 0.05:\n",
    "    #         return \"*\"\n",
    "    #     return \"ns\"\n",
    "    \n",
    "    \n",
    "    order = ['1mM','10mM']\n",
    "    fig_args = {'x':'nitrate_concentration', 'y':var,'data':df, 'order':order, 'dodge':True,'hue':'genotype','hue_order':['col0',sample_name]}\n",
    "    configuration = {'test':None, 'text_format':'star', 'pvalue_thresholds':[[1e-3, \"***\"],[1e-2, \"**\"],[0.05, \"*\"],[1, \"ns\"]]}#\"pairs\":list(box_pairs_significant.keys()),\"pvalues\":list(box_pairs_significant.values()), 'loc':'inside'\n",
    "    _ = plt.figure(figsize=(5,5))\n",
    "\n",
    "    fig = sns.boxplot(**fig_args, linewidth=2, palette=[\"white\", \"grey\"])\n",
    "    fig = sns.swarmplot(**fig_args, color='black', palette=[\"black\", \"black\"],size=4)\n",
    "    #get pairs and pvalues\n",
    "    #print(box_pairs_significant)\n",
    "    pairs=list(box_pair_p_values.keys())\n",
    "    #print(f'pairs={pairs}')\n",
    "    \n",
    "    pvalues=list(box_pair_p_values.values())\n",
    "    #print(f'pvalues={pvalues}')\n",
    "    # #add statsannotator = Annotator(fig, pairs, **fig_args,verbose=False)\n",
    "    annotator = Annotator(fig, pairs, **fig_args,verbose=False, show_non_significant=False)#show_non_significant=False will be added in the next version of statsannotator\n",
    "    #annotator.set_pvalues(pvalues)\n",
    "    annotator.configure(**configuration)\n",
    "    \n",
    "    annotator.set_pvalues_and_annotate(pvalues)\n",
    "\n",
    "    _ = fig.set(xlabel='$KNO_{3}$ concentration', ylabel=y_label)\n",
    "    #set y axis limit to start at 0\n",
    "    _ = plt.ylim(0,None)\n",
    "\n",
    "    ##plot legend, excluding legend from swarm plot\n",
    "    h,l = fig.get_legend_handles_labels()\n",
    "    #change name of label\n",
    "    l[0] = \"Col-0\"\n",
    "    l[1] = sample_name\n",
    "    #l[2] = \"1 mM nitrate\"     \n",
    "    leg = plt.legend(h[0:2],l[0:2],fontsize=14,frameon=False,)#.set_linewidth(2)#,bbox_to_anchor=(0,0.85), loc='best',\n",
    "    #set linewith of each legend object\n",
    "    for legobj in leg.legendHandles:\n",
    "        legobj.set_linewidth(2)\n",
    "    # change axes labels\n",
    "    #_ = plt.ylabel('Relative expression (a.u.)')\n",
    "\n",
    "    #save plot to file\n",
    "    plt.savefig(\n",
    "                    f'{output_location}/{var}_{sample_name}_boxplot.pdf',\n",
    "                    format=\"pdf\",\n",
    "                    bbox_inches=\"tight\",transparent=True)\n",
    "    plt.savefig(\n",
    "                    f'{output_location}/{var}_{sample_name}_boxplot.svg',\n",
    "                    format=\"svg\",\n",
    "                    bbox_inches=\"tight\",transparent=True)\n",
    "    plt.cla()  # clear axis              \n",
    "    plt.close('all')   \n",
    "        \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginal_effects(df,variables,sample_name, output_location):\n",
    "        \"\"\"function to calculate marginal means for interaction genotype*nitrate_concentration\"\"\"\n",
    "        for var, y_label in variables.items():\n",
    "            #remove NaN values from dataframe\n",
    "            df = df.dropna(subset=[var]).copy()\n",
    "            \n",
    "            #only run if not empty array\n",
    "            #try:\n",
    "\n",
    "            #run anova\n",
    "            anova = smf.ols(f'{var} ~ genotype*nitrate_concentration + plate', data=df).fit()\n",
    "            #get marginal means, save as txt file            \n",
    "            #anova.summary_frame().to_csv(f'{output_location}/marginal_means_{var}.tsv', sep='\\t')\n",
    "            #save anova summary to tsv\n",
    "            #use type 1 anova to test interaction term. If not significant, refit without the interaction term and use Type-II to test the main effects\n",
    "            table = sm.stats.anova_lm(anova, type=1)\n",
    "            #print table columns\n",
    "            #print(f'cols={table.columns}')\n",
    "            \n",
    "            #check if interaction term genotype:nitrate_concentration is significant\n",
    "            if table.loc['genotype:nitrate_concentration']['PR(>F)'] >= 0.05:\n",
    "                #print(table.loc['genotype:nitrate_concentration']['PR(>F)'])\n",
    "                #if not significant, refit without the interaction term and use Type-II to test the main effects\n",
    "                \n",
    "                anova = smf.ols(f'{var} ~ genotype+nitrate_concentration + plate', data=df).fit()\n",
    "                table_type2 = sm.stats.anova_lm(anova, type=2)\n",
    "                #run tukey posthocs \n",
    "                #first make new column with interactions\n",
    "                df_copy = df.copy()\n",
    "                \n",
    "                df.loc[:,'combination'] = df_copy['genotype'] +'/'+ df_copy['nitrate_concentration']\n",
    "                #remove nan\n",
    "                clean_df = df.filter(items=[var, 'combination']).dropna()\n",
    "                #remove unwanted combinations, only keep var/10mM vs col0/10mM and var/1mM vs col0/1mM\n",
    "                clean_df = clean_df[clean_df['combination'].isin(['col0/10mM',f'var/10mM','col0/1mM','var/1mM'])]\n",
    "                print(f'cleandf = {clean_df}')\n",
    "                # perform multiple pairwise comparison (Tukey HSD)\n",
    "                #posthoc = sm.stats.multipletests(table_type2['PR(>F)'], alpha=0.05, method='fdr_bh')\n",
    "\n",
    "\n",
    "                \n",
    "                m_comp = pairwise_tukeyhsd(endog=clean_df[var], groups=clean_df['combination'],alpha=0.05)\n",
    "                #convert to df\n",
    "                #m_comp_df = pd.DataFrame(data=m_comp.results_table.data[1:], columns=m_comp.results_table.data[0])\n",
    "                #m_comp_df = pd.DataFrame()\n",
    "                #write stats to file\n",
    "                with open(f'{output_location}/stats/marginal_means_{var}_{sample_name}.txt', 'w') as f:\n",
    "                \n",
    "                    f.write(f'anova_type_1:\\n{table}\\ngenotype:nitrate_concentration is not significant so use type 2 anova excluding interaction term\\nanova_type_2:\\n{table_type2}\\n{anova.summary()}\\nTukey_post_hocs:\\n{m_comp}')\n",
    "\n",
    "\n",
    "                #print(m_comp)\n",
    "                #get box pairs and p values for adding stats annotations\n",
    "                p_values = pd.DataFrame(data=m_comp._results_table.data[1:] , columns=m_comp._results_table.data[0])\n",
    "                # print(f'pvalues = {p_values}')\n",
    "                # print(p_values.columns)\n",
    "                \n",
    "                genotypes_unique = df['genotype'].unique()\n",
    "                length_samples = len(genotypes_unique)\n",
    "                \n",
    "                box_pair_p_values = {}\n",
    "                for x in range (0, (length_samples)):                        \n",
    "                    if genotypes_unique[x] != 'col0':\n",
    "                        #add to box_pair_p_values dictionary the box pair as the key and the p value as the value\n",
    "                        box_pair_p_values[(('1mM','col0'),('1mM',genotypes_unique[x]))] = p_values.loc[((p_values['group1'] == f'col0/1mM') & (p_values['group2'] == f'{genotypes_unique[x]}/1mM'))|((p_values['group1'] == f'{genotypes_unique[x]}/1mM') & (p_values['group2'] == f'col0/1mM')),'p-adj'].values[0]\n",
    "                        box_pair_p_values[(('10mM','col0'),('10mM',genotypes_unique[x]))] = p_values.loc[((p_values['group1'] == f'col0/10mM') & (p_values['group2'] == f'{genotypes_unique[x]}/10mM'))|((p_values['group1'] == f'{genotypes_unique[x]}/10mM') & (p_values['group2'] == f'col0/10mM')),'p-adj'].values[0]\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            if table.loc['genotype:nitrate_concentration']['PR(>F)'] < 0.05:\n",
    "                #if significant interaction effect, analyse nitrate concentrations separately using one-way ANOVA\n",
    "                #first split dataframe into separate dataframes for each nitrate concentration\n",
    "                print(f'{var}{sample_name} is significant for genotype*nitrate_concentration interaction')\n",
    "                df_low = df[df.nitrate_concentration == '1mM']\n",
    "                df_high = df[df.nitrate_concentration == '10mM']\n",
    "                anova_low_nitrate = smf.ols(f'{var} ~ genotype + plate', data=df_low).fit()\n",
    "                anova_high_nitrate = smf.ols(f'{var} ~ genotype + plate', data=df_high).fit()\n",
    "                table_low = sm.stats.anova_lm(anova_low_nitrate, type=2)\n",
    "                table_high = sm.stats.anova_lm(anova_high_nitrate, type=2)\n",
    "                #print(table_high)\n",
    "                #write stats to file\n",
    "                with open(f'{output_location}/stats/marginal_means_{var}_{sample_name}.txt', 'w') as f:\n",
    "                \n",
    "                    f.write(f'anova_type_1:\\n{table}\\ngenotype*nitrate_concentration is significant so analyse each nitrate concentration separately\\nanova_type_2_1mM_nitrate:\\n{table_low}\\nanova_type_2_10mM_nitrate:\\n{table_high} \\n{anova.summary()}')\n",
    "\n",
    "                \n",
    "\n",
    "            \n",
    "                #get p values\n",
    "                p_value_low_nitrate_df = pd.DataFrame(data=table_low)\n",
    "                p_value_high_nitrate_df = pd.DataFrame(data=table_high)\n",
    "                \n",
    "                #get box pairs and p values for adding stats annotations\n",
    "                genotypes_unique = df['genotype'].unique()\n",
    "                length_samples = len(genotypes_unique)\n",
    "                box_pair_p_values = {}\n",
    "                for x in range (0, (length_samples)):                        \n",
    "                    if genotypes_unique[x] != 'col0':                            \n",
    "                        box_pair_p_values[(('1mM','col0'),('1mM',genotypes_unique[x]))] = p_value_low_nitrate_df.loc['genotype','PR(>F)']\n",
    "                        box_pair_p_values[(('10mM','col0'),('10mM',genotypes_unique[x]))] = p_value_high_nitrate_df.loc['genotype','PR(>F)']\n",
    "                        \n",
    "\n",
    "            #PR(>F)\n",
    "            #make boxplots\n",
    "            #remove all string before the first underscore in the variable name, and return all subsequent string     \n",
    "\n",
    "            #split var string on _\n",
    "            no_log_var = var.split('_')[1:]\n",
    "            no_log_var = '_'.join(no_log_var)\n",
    "            #print(no_log_var)\n",
    "            #make boxplots\n",
    "            #first filter df\n",
    "            boxplot_df = df.filter(items=[no_log_var, 'nitrate_concentration','genotype']).dropna().copy()\n",
    "            #get column types\n",
    "            #print(boxplot_df.dtypes)\n",
    "            \n",
    "            boxplot(boxplot_df,no_log_var,y_label,sample_name,box_pair_p_values, f'{output_location}/boxplots')\n",
    "\n",
    "            # except ValueError:\n",
    "            #     print(f'{sample_name}_{var} is empty array, skipping')\n",
    "            #     print(df[df.sample_name == sample_name][var])\n",
    "            #     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to analyse data and make plots\n",
    "def analyse_data(df_plant,sample_name, output_location):\n",
    "    \"\"\"function to run anovas and make boxplots\"\"\"\n",
    "    #anova_PR <- lm(logPR ~ Genotype*NO3_Level + Plate, data = Roots1)\n",
    "    #change -inf values to NaN using .loc\n",
    "    df_plant.loc[df_plant['log_PR'] == -np.inf, 'log_PR'] = np.nan\n",
    "    df_plant.loc[df_plant['log_LR'] == -np.inf, 'log_LR'] = np.nan\n",
    "    df_plant.loc[df_plant['log_LRL'] == -np.inf, 'log_LRL'] = np.nan\n",
    "    df_plant.loc[df_plant['log_ALRL'] == -np.inf, 'log_ALRL'] = np.nan\n",
    "    df_plant.loc[df_plant['log_TRL'] == -np.inf, 'log_TRL'] = np.nan\n",
    "    df_plant.loc[df_plant['log_LRD'] == -np.inf, 'log_LRD'] = np.nan\n",
    "    df_plant.loc[df_plant['log_LRL_div_TRL'] == -np.inf, 'log_LRL_div_TRL'] = np.nan\n",
    "    df_plant.loc[df_plant['log_LR_2nd_order'] == -np.inf, 'log_LR_2nd_order'] = np.nan\n",
    "    df_plant.loc[df_plant['log_LRL_2nd_order'] == -np.inf, 'log_LRL_2nd_order'] = np.nan\n",
    "   \n",
    "\n",
    "    # anova_PR = smf.ols('PR ~ genotype*nitrate_concentration + plate', data=df_plant).fit()\n",
    "    #check anova assumptions\n",
    "    # print(anova_PR.summary())\n",
    "    # fig = sm.qqplot(anova_PR.resid, line='s')\n",
    "    #save figure\n",
    "    #make directory for the plots to be exported to\n",
    "    output_dir = f'{output_location}/qqplots'\n",
    "    \n",
    "        \n",
    "    # fig.savefig(f'{output_location}/qqplots/qqplot_PR.png')\n",
    "    #log_PR residuals look mainly normal from the qqplot, (points at the extreme ends can be discounted)\n",
    "    variables = ['PR','log_PR','LR','log_LR','LRL','log_LRL','ALRL','log_ALRL','TRL','log_TRL','LRD','log_LRD','LRL_div_TRL','log_LRL_div_TRL','LR_2nd_order','log_LR_2nd_order','LRL_2nd_order','log_LRL_2nd_order']\n",
    "    #variables_logs = ['log_PR','log_LR','log_LRL','log_ALRL','log_TRL','log_LRD','log_LRL_div_TRL','log_LR_2nd_order','log_LRL_2nd_order']\n",
    "    variables_logs_dict = {'log_PR':'Primary root length (cm)','log_LR':'Number of lateral roots','log_LRL':'Total lateral root length (cm)','log_ALRL':'Average lateral root length (cm)','log_TRL':'Total root length (cm)','log_LRD':'Lateral root density','log_LRL_div_TRL':'Ratio of lateral root length to\\ntotal root length (LRL/TRL)',}#'log_LR_2nd_order':'Number of second order lateral roots','log_LRL_2nd_order':'Second order lateral root length (cm)'\n",
    "    qqplots(df_plant,variables,sample_name, output_dir)\n",
    "    #I will only use log transformed data\n",
    "    #run anovas and calculate marginal effects for interaction genotype*nitrate_concentration\n",
    "    \n",
    "    marginal_effects(df_plant,variables_logs_dict, sample_name, output_location)\n",
    "    return df_plant\n",
    "\n",
    "\n",
    "\n",
    "    # ANOVA table using bioinfokit v1.0.3 or later (it uses wrapper script for anova_lm)\n",
    "\n",
    "    # res = stat()\n",
    "    # res.anova_stat(df=df_plant, res_var='PR', anova_model='PR ~ genotype*nitrate_concentration + plate')\n",
    "    # res.anova_summary\n",
    "    # #generate QQ-plot from standardized residuals\n",
    "    # # res.anova_std_residuals are standardized residuals obtained from ANOVA (check above)\n",
    "    # # sm.qqplot(res.anova_std_residuals, line='45')\n",
    "    # # plt.xlabel(\"Theoretical Quantiles\")\n",
    "    # # plt.ylabel(\"Standardized Residuals\")\n",
    "    # # plt.show()\n",
    "    # res.qq_plot(df=df_plant, res_var='PR', anova_model='PR ~ genotype*nitrate_concentration + plate')\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function\n",
    "def main(args):\n",
    "    #read in arguments\n",
    "    #input_dir = args.input\n",
    "    input_dir = f'../../data/CRISPR_library/images/rsa_output'\n",
    "    #output_dir = args.output\n",
    "    output_dir = f'../../data/CRISPR_library'\n",
    "    #make directory for the plots to be exported to\n",
    "    output_dir = f'{output_dir}/smartroot_plots'\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir(output_dir)\n",
    "        print(\"Directory \" , output_dir ,  \" created\") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , output_dir ,  \" already exists\")\n",
    "\n",
    "\n",
    "\n",
    "    output_dir2 = f'{output_dir}/stats'\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir(output_dir2)\n",
    "        print(\"Directory \" , output_dir2 ,  \" created\") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , output_dir2 ,  \" already exists\")\n",
    "    output_dir2 = f'{output_dir}/boxplots'\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir(output_dir2)\n",
    "        print(\"Directory \" , output_dir2 ,  \" created\") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , output_dir2 ,  \" already exists\")\n",
    "\n",
    "    output_dir2 = f'{output_dir}/qqplots'\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir(output_dir2)\n",
    "        print(\"Directory \" , output_dir2 ,  \" created\") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , output_dir2 ,  \" already exists\")\n",
    "\n",
    "    #read in and concatenate .csv files\n",
    "    df = concat_csv_recursive(input_dir, '*.csv')\n",
    "    #print(df.head())\n",
    "\n",
    "    \n",
    "    #sort data\n",
    "    df,df_plant = sort_data(df,output_dir)\n",
    "    #analyse dataframe and make plots\n",
    "    #analyse_data(output_dir)\n",
    "    #set matplotlib rc parameters\n",
    "    set_rc_params()\n",
    "    #first split into separate dataframes for each sample_name\n",
    "    #then analyse each dataframe and make plots\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    for sample_name in df_plant['sample_name'].unique():\n",
    "        #get dataframe for each sample_name\n",
    "        df_sample = df_plant[df_plant['sample_name'] == sample_name].copy()\n",
    "        #analyse dataframe and make plots\n",
    "        df_plants = analyse_data(df_sample,sample_name,output_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #analyse_data(df_plant, output_dir)\n",
    "    \n",
    "    #save dataframe to csv file\n",
    "    df.to_csv(f'{output_dir}/all_smartroot_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ../../data/CRISPR_library/smartroot_plots  already exists\n",
      "Directory  ../../data/CRISPR_library/smartroot_plots/stats  already exists\n",
      "Directory  ../../data/CRISPR_library/smartroot_plots/boxplots  already exists\n",
      "Directory  ../../data/CRISPR_library/smartroot_plots/qqplots  already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleandf =        log_PR combination\n",
      "507  1.435798  125-4/10mM\n",
      "503  1.375074  125-4/10mM\n",
      "511  1.411658  125-4/10mM\n",
      "516  1.410612  125-4/10mM\n",
      "520  1.357348  125-4/10mM\n",
      "..        ...         ...\n",
      "624  1.367768   125-4/1mM\n",
      "626  1.310063   125-4/1mM\n",
      "620  1.198822   125-4/1mM\n",
      "640  1.351422   125-4/1mM\n",
      "631  1.373874   125-4/1mM\n",
      "\n",
      "[91 rows x 2 columns]\n",
      "cleandf =        log_LR combination\n",
      "507  1.098612  125-4/10mM\n",
      "503  1.098612  125-4/10mM\n",
      "511  1.386294  125-4/10mM\n",
      "516  1.098612  125-4/10mM\n",
      "520  0.000000  125-4/10mM\n",
      "..        ...         ...\n",
      "624  0.000000   125-4/1mM\n",
      "626  1.386294   125-4/1mM\n",
      "620  1.098612   125-4/1mM\n",
      "640  1.945910   125-4/1mM\n",
      "631  2.079442   125-4/1mM\n",
      "\n",
      "[74 rows x 2 columns]\n",
      "cleandf =       log_LRL combination\n",
      "507  0.184337  125-4/10mM\n",
      "503 -0.417523  125-4/10mM\n",
      "511 -0.132048  125-4/10mM\n",
      "516 -0.652499  125-4/10mM\n",
      "520  0.090657  125-4/10mM\n",
      "..        ...         ...\n",
      "624 -0.264057   125-4/1mM\n",
      "626  0.508178   125-4/1mM\n",
      "620 -0.735285   125-4/1mM\n",
      "640  1.099312   125-4/1mM\n",
      "631  1.168772   125-4/1mM\n",
      "\n",
      "[74 rows x 2 columns]\n",
      "cleandf =      log_ALRL combination\n",
      "507 -0.914276  125-4/10mM\n",
      "503 -1.516135  125-4/10mM\n",
      "511 -1.518343  125-4/10mM\n",
      "516 -1.751111  125-4/10mM\n",
      "520  0.090657  125-4/10mM\n",
      "..        ...         ...\n",
      "624 -0.264057   125-4/1mM\n",
      "626 -0.878116   125-4/1mM\n",
      "620 -1.833898   125-4/1mM\n",
      "640 -0.846599   125-4/1mM\n",
      "631 -0.910669   125-4/1mM\n",
      "\n",
      "[74 rows x 2 columns]\n",
      "cleandf =       log_TRL combination\n",
      "507  1.687402  125-4/10mM\n",
      "503  1.529105  125-4/10mM\n",
      "511  1.605240  125-4/10mM\n",
      "516  1.530222  125-4/10mM\n",
      "520  1.605584  125-4/10mM\n",
      "..        ...         ...\n",
      "624  1.546393   125-4/1mM\n",
      "626  1.680580   125-4/1mM\n",
      "620  1.333837   125-4/1mM\n",
      "640  1.926438   125-4/1mM\n",
      "631  1.969720   125-4/1mM\n",
      "\n",
      "[74 rows x 2 columns]\n",
      "cleandf =       log_LRD combination\n",
      "507 -0.337186  125-4/10mM\n",
      "503 -0.276461  125-4/10mM\n",
      "511 -0.025364  125-4/10mM\n",
      "516 -0.311999  125-4/10mM\n",
      "520 -1.357348  125-4/10mM\n",
      "..        ...         ...\n",
      "624 -1.367768   125-4/1mM\n",
      "626  0.076231   125-4/1mM\n",
      "620 -0.100210   125-4/1mM\n",
      "640  0.594488   125-4/1mM\n",
      "631  0.705567   125-4/1mM\n",
      "\n",
      "[74 rows x 2 columns]\n",
      "cleandf =      log_LRL_div_TRL combination\n",
      "507        -1.503065  125-4/10mM\n",
      "503        -1.946628  125-4/10mM\n",
      "511        -1.737288  125-4/10mM\n",
      "516        -2.182721  125-4/10mM\n",
      "520        -1.514927  125-4/10mM\n",
      "..               ...         ...\n",
      "624        -1.810450   125-4/1mM\n",
      "626        -1.172402   125-4/1mM\n",
      "620        -2.069122   125-4/1mM\n",
      "640        -0.827126   125-4/1mM\n",
      "631        -0.800947   125-4/1mM\n",
      "\n",
      "[74 rows x 2 columns]\n",
      "130-4_log_LR_2nd_order is empty array, skipping\n",
      "130-4_log_LRL_2nd_order is empty array, skipping\n",
      "cleandf =         log_PR combination\n",
      "3556  0.896528   col0/10mM\n",
      "3550  1.455721  130-4/10mM\n",
      "3553  1.358738  130-4/10mM\n",
      "3554  1.260597   col0/10mM\n",
      "3563  1.319937   col0/10mM\n",
      "...        ...         ...\n",
      "3426  1.070348    col0/1mM\n",
      "3404  1.183633   130-4/1mM\n",
      "3400  1.440420   130-4/1mM\n",
      "3428  0.926165    col0/1mM\n",
      "3402  1.344662   130-4/1mM\n",
      "\n",
      "[79 rows x 2 columns]\n",
      "cleandf =         log_LR combination\n",
      "3556  0.000000   col0/10mM\n",
      "3550  0.000000  130-4/10mM\n",
      "3553  0.693147  130-4/10mM\n",
      "3565  0.000000   col0/10mM\n",
      "3548  0.000000  130-4/10mM\n",
      "...        ...         ...\n",
      "3408  1.098612   130-4/1mM\n",
      "3426  0.000000    col0/1mM\n",
      "3404  0.000000   130-4/1mM\n",
      "3400  0.693147   130-4/1mM\n",
      "3402  0.000000   130-4/1mM\n",
      "\n",
      "[62 rows x 2 columns]\n",
      "cleandf =        log_LRL combination\n",
      "3556  0.581130   col0/10mM\n",
      "3550 -2.598457  130-4/10mM\n",
      "3553 -0.896664  130-4/10mM\n",
      "3565 -2.621371   col0/10mM\n",
      "3548 -3.086024  130-4/10mM\n",
      "...        ...         ...\n",
      "3408  0.184218   130-4/1mM\n",
      "3426 -0.509004    col0/1mM\n",
      "3404 -0.372084   130-4/1mM\n",
      "3400  0.046418   130-4/1mM\n",
      "3402 -1.480245   130-4/1mM\n",
      "\n",
      "[62 rows x 2 columns]\n",
      "cleandf =       log_ALRL combination\n",
      "3556  0.581130   col0/10mM\n",
      "3550 -2.598457  130-4/10mM\n",
      "3553 -1.589812  130-4/10mM\n",
      "3565 -2.621371   col0/10mM\n",
      "3548 -3.086024  130-4/10mM\n",
      "...        ...         ...\n",
      "3408 -0.914394   130-4/1mM\n",
      "3426 -0.509004    col0/1mM\n",
      "3404 -0.372084   130-4/1mM\n",
      "3400 -0.646729   130-4/1mM\n",
      "3402 -1.480245   130-4/1mM\n",
      "\n",
      "[62 rows x 2 columns]\n",
      "cleandf =        log_TRL combination\n",
      "3556  1.444360   col0/10mM\n",
      "3550  1.472922  130-4/10mM\n",
      "3553  1.458430  130-4/10mM\n",
      "3565  1.296030   col0/10mM\n",
      "3548  1.519727  130-4/10mM\n",
      "...        ...         ...\n",
      "3408  1.523317   130-4/1mM\n",
      "3426  1.257747    col0/1mM\n",
      "3404  1.375111   130-4/1mM\n",
      "3400  1.662027   130-4/1mM\n",
      "3402  1.402283   130-4/1mM\n",
      "\n",
      "[62 rows x 2 columns]\n",
      "cleandf =        log_LRD combination\n",
      "3556 -0.896528   col0/10mM\n",
      "3550 -1.455721  130-4/10mM\n",
      "3553 -0.665590  130-4/10mM\n",
      "3565 -1.275937   col0/10mM\n",
      "3548 -1.509682  130-4/10mM\n",
      "...        ...         ...\n",
      "3408 -0.120782   130-4/1mM\n",
      "3426 -1.070348    col0/1mM\n",
      "3404 -1.183633   130-4/1mM\n",
      "3400 -0.747273   130-4/1mM\n",
      "3402 -1.344662   130-4/1mM\n",
      "\n",
      "[62 rows x 2 columns]\n",
      "cleandf =       log_LRL_div_TRL combination\n",
      "3556        -0.863230   col0/10mM\n",
      "3550        -4.071379  130-4/10mM\n",
      "3553        -2.355095  130-4/10mM\n",
      "3565        -3.917401   col0/10mM\n",
      "3548        -4.605750  130-4/10mM\n",
      "...               ...         ...\n",
      "3408        -1.339098   130-4/1mM\n",
      "3426        -1.766751    col0/1mM\n",
      "3404        -1.747195   130-4/1mM\n",
      "3400        -1.615609   130-4/1mM\n",
      "3402        -2.882528   130-4/1mM\n",
      "\n",
      "[62 rows x 2 columns]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     main(sys\u001b[39m.\u001b[39;49margv)\n",
      "\u001b[1;32m/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb Cell 12\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     df_sample \u001b[39m=\u001b[39m df_plant[df_plant[\u001b[39m'\u001b[39m\u001b[39msample_name\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m sample_name]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39m#analyse dataframe and make plots\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     df_plants \u001b[39m=\u001b[39m analyse_data(df_sample,sample_name,output_dir)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m#analyse_data(df_plant, output_dir)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39m#save dataframe to csv file\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00moutput_dir\u001b[39m}\u001b[39;00m\u001b[39m/all_smartroot_data.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb Cell 12\u001b[0m in \u001b[0;36manalyse_data\u001b[0;34m(df_plant, sample_name, output_location)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m qqplots(df_plant,variables,sample_name, output_dir)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m#I will only use log transformed data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m#run anovas and calculate marginal effects for interaction genotype*nitrate_concentration\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m marginal_effects(df_plant,variables_logs_dict, sample_name, output_location)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mreturn\u001b[39;00m df_plant\n",
      "\u001b[1;32m/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb Cell 12\u001b[0m in \u001b[0;36mmarginal_effects\u001b[0;34m(df, variables, sample_name, output_location)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcleandf = \u001b[39m\u001b[39m{\u001b[39;00mclean_df\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# perform multiple pairwise comparison (Tukey HSD)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m#posthoc = sm.stats.multipletests(table_type2['PR(>F)'], alpha=0.05, method='fdr_bh')\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m m_comp \u001b[39m=\u001b[39m pairwise_tukeyhsd(endog\u001b[39m=\u001b[39;49mclean_df[var], groups\u001b[39m=\u001b[39;49mclean_df[\u001b[39m'\u001b[39;49m\u001b[39mcombination\u001b[39;49m\u001b[39m'\u001b[39;49m],alpha\u001b[39m=\u001b[39;49m\u001b[39m0.05\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m#convert to df\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m#m_comp_df = pd.DataFrame(data=m_comp.results_table.data[1:], columns=m_comp.results_table.data[0])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m#m_comp_df = pd.DataFrame()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m#write stats to file\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/analyse_RSA.ipynb#X14sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00moutput_location\u001b[39m}\u001b[39;00m\u001b[39m/stats/marginal_means_\u001b[39m\u001b[39m{\u001b[39;00mvar\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00msample_name\u001b[39m}\u001b[39;00m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/statsmodels/stats/multicomp.py:44\u001b[0m, in \u001b[0;36mpairwise_tukeyhsd\u001b[0;34m(endog, groups, alpha)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpairwise_tukeyhsd\u001b[39m(endog, groups, alpha\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m    Calculate all pairwise comparisons with TukeyHSD confidence intervals\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39m    statsmodels.sandbox.stats.multicomp.TukeyHSDResults\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m MultiComparison(endog, groups)\u001b[39m.\u001b[39;49mtukeyhsd(alpha\u001b[39m=\u001b[39;49malpha)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/statsmodels/sandbox/stats/multicomp.py:996\u001b[0m, in \u001b[0;36mMultiComparison.tukeyhsd\u001b[0;34m(self, alpha)\u001b[0m\n\u001b[1;32m    993\u001b[0m var_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvar(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroupstats\u001b[39m.\u001b[39mgroupdemean(), ddof\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(gmeans))\n\u001b[1;32m    994\u001b[0m \u001b[39m# res contains: 0:(idx1, idx2), 1:reject, 2:meandiffs, 3: std_pairs,\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[39m# 4:confint, 5:q_crit, 6:df_total, 7:reject2, 8: pvals\u001b[39;00m\n\u001b[0;32m--> 996\u001b[0m res \u001b[39m=\u001b[39m tukeyhsd(gmeans, gnobs, var_, df\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, alpha\u001b[39m=\u001b[39;49malpha, q_crit\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    998\u001b[0m resarr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(lzip(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroupsunique[res[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]],\n\u001b[1;32m    999\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroupsunique[res[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]],\n\u001b[1;32m   1000\u001b[0m                        np\u001b[39m.\u001b[39mround(res[\u001b[39m2\u001b[39m], \u001b[39m4\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                          (\u001b[39m'\u001b[39m\u001b[39mupper\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mfloat\u001b[39m),\n\u001b[1;32m   1011\u001b[0m                          (\u001b[39m'\u001b[39m\u001b[39mreject\u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39mbool8)])\n\u001b[1;32m   1012\u001b[0m results_table \u001b[39m=\u001b[39m SimpleTable(resarr, headers\u001b[39m=\u001b[39mresarr\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mnames)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/statsmodels/sandbox/stats/multicomp.py:1306\u001b[0m, in \u001b[0;36mtukeyhsd\u001b[0;34m(mean_all, nobs_all, var_all, df, alpha, q_crit)\u001b[0m\n\u001b[1;32m   1303\u001b[0m \u001b[39mif\u001b[39;00m q_crit \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1304\u001b[0m     q_crit \u001b[39m=\u001b[39m get_tukeyQcrit2(n_means, df_total, alpha\u001b[39m=\u001b[39malpha)\n\u001b[0;32m-> 1306\u001b[0m pvalues \u001b[39m=\u001b[39m get_tukey_pvalue(n_means, df_total, st_range)\n\u001b[1;32m   1307\u001b[0m \u001b[39m# we need pvalues to be atleast_1d for iteration. see #6132\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m pvalues \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39matleast_1d(pvalues)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/statsmodels/sandbox/stats/multicomp.py:184\u001b[0m, in \u001b[0;36mget_tukey_pvalue\u001b[0;34m(k, df, q)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_tukey_pvalue\u001b[39m(k, df, q):\n\u001b[1;32m    171\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m    return adjusted p-values for Tukey's HSD\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m studentized_range\u001b[39m.\u001b[39;49msf(q, k, df)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/scipy/stats/_distn_infrastructure.py:2261\u001b[0m, in \u001b[0;36mrv_continuous.sf\u001b[0;34m(self, x, *args, **kwds)\u001b[0m\n\u001b[1;32m   2259\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many(cond):\n\u001b[1;32m   2260\u001b[0m     goodargs \u001b[39m=\u001b[39m argsreduce(cond, \u001b[39m*\u001b[39m((x,)\u001b[39m+\u001b[39margs))\n\u001b[0;32m-> 2261\u001b[0m     place(output, cond, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sf(\u001b[39m*\u001b[39;49mgoodargs))\n\u001b[1;32m   2262\u001b[0m \u001b[39mif\u001b[39;00m output\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2263\u001b[0m     \u001b[39mreturn\u001b[39;00m output[()]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/scipy/stats/_distn_infrastructure.py:1012\u001b[0m, in \u001b[0;36mrv_generic._sf\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sf\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs):\n\u001b[0;32m-> 1012\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1.0\u001b[39m\u001b[39m-\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cdf(x, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:9462\u001b[0m, in \u001b[0;36mstudentized_range_gen._cdf\u001b[0;34m(self, x, k, df)\u001b[0m\n\u001b[1;32m   9460\u001b[0m ufunc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrompyfunc(_single_cdf, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m   9461\u001b[0m \u001b[39m# clip p-values to ensure they are in [0, 1].\u001b[39;00m\n\u001b[0;32m-> 9462\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mclip(np\u001b[39m.\u001b[39mfloat64(ufunc(x, k, df)), \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:9458\u001b[0m, in \u001b[0;36mstudentized_range_gen._cdf.<locals>._single_cdf\u001b[0;34m(q, k, df)\u001b[0m\n\u001b[1;32m   9456\u001b[0m llc \u001b[39m=\u001b[39m LowLevelCallable\u001b[39m.\u001b[39mfrom_cython(_stats, cython_symbol, usr_data)\n\u001b[1;32m   9457\u001b[0m opts \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(epsabs\u001b[39m=\u001b[39m\u001b[39m1e-11\u001b[39m, epsrel\u001b[39m=\u001b[39m\u001b[39m1e-12\u001b[39m)\n\u001b[0;32m-> 9458\u001b[0m \u001b[39mreturn\u001b[39;00m integrate\u001b[39m.\u001b[39;49mnquad(llc, ranges\u001b[39m=\u001b[39;49mranges, opts\u001b[39m=\u001b[39;49mopts)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:1097\u001b[0m, in \u001b[0;36mnquad\u001b[0;34m(func, ranges, args, opts, full_output)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1096\u001b[0m     opts \u001b[39m=\u001b[39m [opt \u001b[39mif\u001b[39;00m callable(opt) \u001b[39melse\u001b[39;00m _OptFunc(opt) \u001b[39mfor\u001b[39;00m opt \u001b[39min\u001b[39;00m opts]\n\u001b[0;32m-> 1097\u001b[0m \u001b[39mreturn\u001b[39;00m _NQuad(func, ranges, opts, full_output)\u001b[39m.\u001b[39;49mintegrate(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:1151\u001b[0m, in \u001b[0;36m_NQuad.integrate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1150\u001b[0m     f \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintegrate, depth\u001b[39m=\u001b[39mdepth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m-> 1151\u001b[0m quad_r \u001b[39m=\u001b[39m quad(f, low, high, args\u001b[39m=\u001b[39;49margs, full_output\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfull_output,\n\u001b[1;32m   1152\u001b[0m               \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mopt)\n\u001b[1;32m   1153\u001b[0m value \u001b[39m=\u001b[39m quad_r[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m abserr \u001b[39m=\u001b[39m quad_r[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:411\u001b[0m, in \u001b[0;36mquad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points, weight, wvar, wopts, maxp1, limlst)\u001b[0m\n\u001b[1;32m    408\u001b[0m flip, a, b \u001b[39m=\u001b[39m b \u001b[39m<\u001b[39m a, \u001b[39mmin\u001b[39m(a, b), \u001b[39mmax\u001b[39m(a, b)\n\u001b[1;32m    410\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 411\u001b[0m     retval \u001b[39m=\u001b[39m _quad(func, a, b, args, full_output, epsabs, epsrel, limit,\n\u001b[1;32m    412\u001b[0m                    points)\n\u001b[1;32m    413\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    414\u001b[0m     \u001b[39mif\u001b[39;00m points \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:525\u001b[0m, in \u001b[0;36m_quad\u001b[0;34m(func, a, b, args, full_output, epsabs, epsrel, limit, points)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[39mreturn\u001b[39;00m _quadpack\u001b[39m.\u001b[39m_qagse(func,a,b,args,full_output,epsabs,epsrel,limit)\n\u001b[1;32m    524\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m         \u001b[39mreturn\u001b[39;00m _quadpack\u001b[39m.\u001b[39;49m_qagie(func,bound,infbounds,args,full_output,epsabs,epsrel,limit)\n\u001b[1;32m    526\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m     \u001b[39mif\u001b[39;00m infbounds \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/scipy/integrate/_quadpack_py.py:1151\u001b[0m, in \u001b[0;36m_NQuad.integrate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1150\u001b[0m     f \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintegrate, depth\u001b[39m=\u001b[39mdepth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m-> 1151\u001b[0m quad_r \u001b[39m=\u001b[39m quad(f, low, high, args\u001b[39m=\u001b[39;49margs, full_output\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfull_output,\n\u001b[1;32m   1152\u001b[0m               \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mopt)\n\u001b[1;32m   1153\u001b[0m value \u001b[39m=\u001b[39m quad_r[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1154\u001b[0m abserr \u001b[39m=\u001b[39m quad_r[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(sys.argv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('qpcr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c2acf9d6025fe51d3e4a4cb09a2ff19b54eaae2da571c8e6469319b5fd828be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
