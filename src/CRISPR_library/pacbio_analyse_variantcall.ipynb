{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alleles_frequency_table.zip can be unzipped to a tab-separated text file that shows all reads and alignments to references. The first column shows the aligned sequence of the sequenced read. The second column shows the aligned sequence of the reference sequence. Gaps in each of these columns represent insertions and deletions. The next column 'Reference_Name' shows the name of the reference that the read aligned to. The fourth column, 'Read_Status' shows whether the read was modified or unmodified. The fifth through seventh columns ('n_deleted', 'n_inserted', 'n_substituted') show the number of bases deleted, inserted, and substituted as compared to the reference sequence. The eighth column shows the number of reads having that sequence, and the ninth column shows the percentage of all reads having that sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #features to add:\n",
    "# Distance from TSS - get relative position of mutation in the guide site - done. Add distance from cut site metric. - done Then calculate distance from Araport TSS - done\n",
    "# for this: first create a bed file for all of the mutations (relative to whole Arabidopsis genome). Then do bedtools merge or intersect (or bedtools coverage (../data_sorting/./TFBS_coverage.sh)) with the mapped motif bed file (all TFBSs for all genes). Record each TFBS that overlaps the mutation\n",
    "# Overlapping TFBSs - subnetwork and all TFs\n",
    "\n",
    "# Include secondary mutations in case both deletion and substitution for example - done\n",
    "# Plant ID\n",
    "# How many biallelic or homozygous? How many wildtype?\n",
    "# More than 2 alleles for a gene - record alleles until 80% of reads accounted for\n",
    "# Prioiritse homozygous or biallelic\n",
    "# How many plants had mutations? How many guides produced mutations in each gene?\n",
    "#check window around cut site - at the moment I am including mutations 20bp either side, maybe cut the alignments down to 7bp either side before comparing them with find_indels_substitutions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use env pacbio_post_analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os\n",
    "import re \n",
    "from pyfaidx import Fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #code from https://github.com/pinellolab/CRISPResso2/blob/master/CRISPResso2/CRISPRessoCOREResources.pyx\n",
    "# #import cython\n",
    "\n",
    "# # cimport numpy as np\n",
    "# import re\n",
    "\n",
    "# # cdef extern from \"stdlib.h\":\n",
    "# #     ctypedef unsigned int size_t\n",
    "# #     size_t strlen(char* s)\n",
    "\n",
    "\n",
    "# # cdef extern from \"Python.h\":\n",
    "# #     ctypedef void PyObject\n",
    "# #     int _PyBytes_Resize(PyObject **, size_t)\n",
    "# #     char * PyBytes_AS_STRING(PyObject *)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code from https://github.com/pinellolab/CRISPResso2/blob/master/CRISPResso2/CRISPRessoCOREResources.pyx\n",
    "#I converted it to pure python\n",
    "def find_indels_substitutions(read_seq_al, ref_seq_al, _include_indx):\n",
    "    re_find_indels = re.compile(\"(-*-)\")\n",
    "\n",
    "    #ref_positions holds the indices for which positions map back to the original reference\n",
    "    # for example,\n",
    "    #     1 2 3 4 5 6 7 8\n",
    "    # ref A A T T G G C C\n",
    "    #\n",
    "    # and for a given alignment\n",
    "    # ref A A T T - G G C C\n",
    "    # aln A - T T T G G C C\n",
    "    #     1 2 3 4-4 5 6 7 8 <ref positions. Note that the negative values/indices represent places that don't map back to the original reference\n",
    "    ref_positions=[]\n",
    "    all_substitution_positions=[]\n",
    "    substitution_positions=[]\n",
    "    all_substitution_values=[]\n",
    "    substitution_values=[]\n",
    "\n",
    "    all_deletion_positions = []\n",
    "    deletion_positions = []\n",
    "    deletion_coordinates = []\n",
    "    deletion_sizes = []\n",
    "    #cdef int start_deletion = -1  # the -1 value indicates that there currently isn't a deletion\n",
    "    start_deletion = -1  # the -1 value indicates that there currently isn't a deletion\n",
    "\n",
    "    all_insertion_positions = []\n",
    "    all_insertion_left_positions = []\n",
    "    insertion_positions = []\n",
    "    insertion_coordinates = []\n",
    "    insertion_sizes = []\n",
    "    #cdef int start_insertion = -1  # the -1 value indicates that there currently isn't an insertion\n",
    "    start_insertion = -1  # the -1 value indicates that there currently isn't an insertion\n",
    "\n",
    "    #cdef size_t seq_len = len(ref_seq_al)\n",
    "    seq_len = len(ref_seq_al)\n",
    "    include_indx_set = set(_include_indx)\n",
    "    nucSet = set(['A', 'T', 'C', 'G', 'N'])\n",
    "    # cdef int idx = 0\n",
    "    # cdef int idx_c\n",
    "    # cdef int current_insertion_size = 0\n",
    "    idx = 0\n",
    "    #idx_c\n",
    "    current_insertion_size = 0\n",
    "    for idx_c, c in enumerate(ref_seq_al):\n",
    "        #print(idx_c)\n",
    "        if c != '-':\n",
    "            ref_positions.append(idx)\n",
    "            if ref_seq_al[idx_c]!=read_seq_al[idx_c] and read_seq_al[idx_c] != '-' and read_seq_al[idx_c] != 'N':\n",
    "                all_substitution_positions.append(idx)\n",
    "                all_substitution_values.append(read_seq_al[idx_c])\n",
    "                if idx in _include_indx:\n",
    "                    substitution_positions.append(idx)\n",
    "                    substitution_values.append(read_seq_al[idx_c])\n",
    "            if start_insertion != -1:  # this is the end of an insertion\n",
    "                all_insertion_left_positions.append(start_insertion)\n",
    "                all_insertion_positions.append(start_insertion)\n",
    "                all_insertion_positions.append(idx)\n",
    "                if start_insertion in include_indx_set and idx in include_indx_set:\n",
    "                    insertion_coordinates.append((start_insertion, idx))\n",
    "                    insertion_positions.append(start_insertion)\n",
    "                    insertion_positions.append(idx)\n",
    "                    insertion_sizes.append(current_insertion_size)\n",
    "                start_insertion = -1\n",
    "            current_insertion_size = 0\n",
    "            idx += 1\n",
    "        else:  # the current ref position is -\n",
    "            if idx == 0:\n",
    "                ref_positions.append(-1)\n",
    "            else:\n",
    "                ref_positions.append(-idx)\n",
    "            if idx > 0 and start_insertion == -1:  # this is the first index of an insertion\n",
    "                start_insertion = idx - 1\n",
    "            current_insertion_size += 1\n",
    "\n",
    "        if read_seq_al[idx_c] == '-' and start_deletion == -1:  # this is the first part of a deletion\n",
    "            if idx_c - 1 > 0:\n",
    "                start_deletion = ref_positions[idx_c]\n",
    "            else:\n",
    "                start_deletion = 0\n",
    "        elif read_seq_al[idx_c] != '-' and start_deletion != -1:  # this is the end of a deletion\n",
    "            end_deletion = ref_positions[idx_c]\n",
    "            all_deletion_positions.extend(range(start_deletion, end_deletion))\n",
    "            if include_indx_set.intersection(range(start_deletion, end_deletion)):\n",
    "                deletion_positions.extend(range(start_deletion, end_deletion))\n",
    "                deletion_coordinates.append((start_deletion, end_deletion))\n",
    "                deletion_sizes.append(end_deletion - start_deletion)\n",
    "            start_deletion = -1\n",
    "\n",
    "    if start_deletion != -1:\n",
    "        end_deletion = ref_positions[seq_len - 1]\n",
    "        all_deletion_positions.extend(range(start_deletion, end_deletion))\n",
    "        if include_indx_set.intersection(range(start_deletion, end_deletion)):\n",
    "            deletion_positions.extend(range(start_deletion, end_deletion))\n",
    "            deletion_coordinates.append((start_deletion, end_deletion))\n",
    "            deletion_sizes.append(end_deletion - start_deletion)\n",
    "\n",
    "    # cdef size_t substitution_n = len(substitution_positions)\n",
    "    # cdef size_t deletion_n = sum(deletion_sizes)\n",
    "    # cdef size_t insertion_n = sum(insertion_sizes)\n",
    "    substitution_n = len(all_substitution_positions)\n",
    "    deletion_n = len(all_deletion_positions)\n",
    "    insertion_n = len(all_insertion_positions)\n",
    "\n",
    "    return {\n",
    "        'all_insertion_positions': all_insertion_positions,\n",
    "        'all_insertion_left_positions': all_insertion_left_positions,\n",
    "        'insertion_positions': insertion_positions,\n",
    "        'insertion_coordinates': insertion_coordinates,\n",
    "        'insertion_sizes': insertion_sizes,\n",
    "        'insertion_n': insertion_n,\n",
    "\n",
    "        'all_deletion_positions': all_deletion_positions,\n",
    "        'deletion_positions': deletion_positions,\n",
    "        'deletion_coordinates': deletion_coordinates,\n",
    "        'deletion_sizes': deletion_sizes,\n",
    "        'deletion_n': deletion_n,\n",
    "\n",
    "        'all_substitution_positions': all_substitution_positions,\n",
    "        'substitution_positions': substitution_positions,\n",
    "        'all_substitution_values': np.array(all_substitution_values),\n",
    "        'substitution_values': np.array(substitution_values),\n",
    "        'substitution_n': substitution_n,\n",
    "\n",
    "        'ref_positions': ref_positions,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_guide_position_in_gene(gene,cut_site_reference_seq, guide_position):\n",
    "    \"\"\"function to find the relative promoter position of the current guide site position in the reference gene\"\"\"\n",
    "    fasta_location = reference_gene_dict[gene]\n",
    "    #read in fasta file\n",
    "    fasta = Fasta(\n",
    "        fasta_location\n",
    "    )\n",
    "    #get promoter sequence\n",
    "    prom_seq = str(fasta[f'{gene}_promoter'])\n",
    "    #print(fasta[f'{gene}_promoter'])\n",
    "    #find position of substring in string\n",
    "    start_location = prom_seq.index(cut_site_reference_seq)\n",
    "    site_promoter_position = start_location + guide_position\n",
    "    return site_promoter_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_promoter_genomic_positions(reference_promoter_bed,all_promoters_bed):\n",
    "    \"\"\"function to get the reference promoter genomic positions and to get the tSS genomic position\"\"\"\n",
    "     #read in reference_promoter_bed\n",
    "    reference_promoter_df = pd.read_table(\n",
    "        reference_promoter_bed, sep=\"\\t\", header=None\n",
    "    )\n",
    "    cols = [\n",
    "        \"chr\",\n",
    "        \"start\",\n",
    "        \"stop\",\n",
    "        \"promoter_name\",\n",
    "        \"score\",\n",
    "        \"strand\",\n",
    "        ]\n",
    "    reference_promoter_df.columns = cols\n",
    "\n",
    "    #read in all_promoters_bed\n",
    "    all_promoters_df = pd.read_table(\n",
    "        all_promoters_bed, sep=\"\\t\", header=None\n",
    "    )\n",
    "    cols2 = [\n",
    "        \"chr\",\n",
    "        \"start\",\n",
    "        \"stop\",\n",
    "        \"AGI\",\n",
    "        \"dot\",\n",
    "        \"strand\",\n",
    "        \"source\",\n",
    "        \"type\",\n",
    "        \"dot2\",\n",
    "        \"attributes\",\n",
    "    ]\n",
    "    all_promoters_df.columns = cols2\n",
    "\n",
    "    #AGIs dictionary of the four genes\n",
    "    AGI_dict = {'DREB26':'AT1G21910','NLP7':'AT4G24020','ARF18':'AT3G61830','ARF9':'AT4G23980'}\n",
    "    #make empty dict\n",
    "    reference_genomic_positions = {}\n",
    "    #get promoter genomic positions\n",
    "    for gene,AGI in AGI_dict.items():\n",
    "        promoter_genomic_pos_chromosome = int(reference_promoter_df[reference_promoter_df.promoter_name == f'{gene}_promoter'].chr)\n",
    "        promoter_genomic_pos_start = int(reference_promoter_df[reference_promoter_df.promoter_name == f'{gene}_promoter'].start)\n",
    "        promoter_genomic_pos_stop = int(reference_promoter_df[reference_promoter_df.promoter_name == f'{gene}_promoter'].stop)\n",
    "\n",
    "        #get TSS position\n",
    "        TSS_pos = int(all_promoters_df[all_promoters_df.AGI==AGI].stop)\n",
    "        #temp_dict = {gene:[AGI,promoter_genomic_pos_chromosome,promoter_genomic_pos_start,promoter_genomic_pos_stop,TSS_pos]}\n",
    "        #write to dict\n",
    "        reference_genomic_positions[gene]= [AGI,promoter_genomic_pos_chromosome,promoter_genomic_pos_start,promoter_genomic_pos_stop,TSS_pos]\n",
    "    return reference_genomic_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_genomic_position(reference_genomic_positions,gene,promoter_position):\n",
    "    \"\"\"get the genomic position of the cut site\"\"\"\n",
    "    positions_list = reference_genomic_positions[gene]\n",
    "    #first get genomic position of the cut site\n",
    "    promoter_genomic_pos_chromosome = positions_list[1]\n",
    "    promoter_genomic_pos_start = positions_list[2]\n",
    "    promoter_genomic_pos_stop = positions_list[3]\n",
    "    #get the genomic location of the input promoter position\n",
    "    #print(f'prom_position={promoter_position}, prom_genom_pos_start={promoter_genomic_pos_start}')\n",
    "    genomic_position = promoter_position+promoter_genomic_pos_start\n",
    "    #get position of cut site relative to TSS position\n",
    "    #get TSS position\n",
    "    TSS_pos = positions_list[4]\n",
    "    position_relative_to_TSS = genomic_position - TSS_pos\n",
    "\n",
    "    return position_relative_to_TSS,genomic_position, promoter_genomic_pos_chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlapping_TFBSs(mapped_motifs_bed):\n",
    "    \"\"\"function to find any overlapping TFBSs from FIMO mapped motif file\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_guide(root_dir,output,gene,reference_fasta,mapped_motifs_bed,reference_genomic_positions):\n",
    "    \"\"\"read in the Alleles_frequency_table txt files\"\"\"\n",
    "    #create the output file\n",
    "    cols = ['platename','library','first_reaction_primers','second_reaction_primers','guide','aligned_sequence','reference_sequence','mutation_type','read_number','read_percentage','insertion_positions','deletion_positions','substitution_positions','insertion_cut_site_distance','deletion_cut_site_distance','substitution_cut_site_distance','cut_site_promoter_position','insertion_positions_relative_to_TSS','insertion_genomic_positions','deletion_positions_relative_to_TSS','deletion_genomic_positions','substitution_positions_relative_to_TSS','substitution_genomic_positions']#'mutation_size',\n",
    "    output_df = pd.DataFrame(columns=cols)\n",
    "    for subdir, dirs, files in os.walk(root_dir):        \n",
    "            for filename in fnmatch.filter(files,f\"*Alleles_frequency_table_around_{gene}_*.txt\"):\n",
    "                #print (os.path.join(subdir, filename))\n",
    "                #read in as df\n",
    "                df = pd.read_table(os.path.join(subdir, filename), sep=\"\\t\", header=0)\n",
    "                #filter out rows with reads less than 30\n",
    "                filtered_reads = df[df['#Reads'] >= 30]\n",
    "                #save each row to df\n",
    "                for index, row in filtered_reads.iterrows():\n",
    "                    \n",
    "                    #check if aligned and reference are different\n",
    "                    Aligned_Sequence = row.Aligned_Sequence\n",
    "                    Reference_Sequence = row.Reference_Sequence\n",
    "                    \n",
    "\n",
    "                    #split filename on .\n",
    "                    partitioned_string = filename.partition('.')\n",
    "                    #get second PCR reaction primers\n",
    "                    second_reaction_primers = partitioned_string[0]\n",
    "                    #get guide name\n",
    "                    guide = re.search(f\"[_]+({gene}(.*))\",partitioned_string[2].partition('.')[0])[1]                 \n",
    "                    #get first reaction PCR primers and library number\n",
    "                    library_primers = re.search(\"_bc(.*)\",subdir)[0]\n",
    "                    both_primers = re.findall(\"SW(\\d*)\",library_primers)\n",
    "                    #if 2 found, create first_reaction_primers value\n",
    "                    if len(both_primers) == 2:\n",
    "                        first_reaction_primers = f'SW{both_primers[0]}_SW{both_primers[1]}'\n",
    "                    else:\n",
    "                        first_reaction_primers = 'NA'\n",
    "\n",
    "                    \n",
    "                    library = re.search(\"[^_bc]+(\\d*)\",library_primers)[0]\n",
    "                    read_number = row['#Reads']\n",
    "                    read_percentage = row['%Reads']\n",
    "                    \n",
    "                    \n",
    "                    #convert library number to different number (from 1017 to 1, 1018 to 2 etc)\n",
    "                    if int(library) == 1017:\n",
    "                        new_library = 1\n",
    "                    elif int(library) == 1018:\n",
    "                        new_library = 2\n",
    "                    elif int(library) == 1019:\n",
    "                        new_library = 3\n",
    "                    elif int(library) == 1020:\n",
    "                        new_library = 4\n",
    "                    elif int(library) == 1021:\n",
    "                        new_library = 5\n",
    "                    elif int(library) == 1022:\n",
    "                        new_library = 6\n",
    "                    #print(new_library)\n",
    "                    platename = f'p{new_library}{gene}'\n",
    "                    #distance_from_TSS =\n",
    "                    #sequence = \n",
    "\n",
    "                    #remove dashes from string\n",
    "                    # Aligned_Sequence_no_dashes = Aligned_Sequence.replace('-','')\n",
    "                    # Reference_Sequence_no_dashes = Reference_Sequence.replace('-','')\n",
    "                    # if Aligned_Sequence == Reference_Sequence:\n",
    "                    #     mutation_type = 'None'\n",
    "                    #     mutation_size = 'NA'\n",
    "                    # elif Aligned_Sequence != Reference_Sequence:\n",
    "                    #     #if insertion\n",
    "                    #     if len(Aligned_Sequence_no_dashes) > len(Reference_Sequence_no_dashes):\n",
    "                    #         mutation_type = 'insertion'\n",
    "                    #         mutation_size = len(Aligned_Sequence_no_dashes)-len(Reference_Sequence_no_dashes)\n",
    "                            \n",
    "                    #     #if deletion\n",
    "                    #     elif len(Reference_Sequence_no_dashes) > len(Aligned_Sequence_no_dashes):\n",
    "                    #         mutation_type = 'deletion'\n",
    "                    #         mutation_size = len(Reference_Sequence_no_dashes)-len(Aligned_Sequence_no_dashes)\n",
    "                    #     #if substition\n",
    "                    #     elif len(Reference_Sequence_no_dashes) == len(Aligned_Sequence_no_dashes):\n",
    "                    #         mutation_type = 'substitution'\n",
    "                    #         #mutation size is the Hamming distance between the two strings\n",
    "                    #         mutation_size = sum([1 for x, y in zip(Aligned_Sequence_no_dashes, Reference_Sequence_no_dashes) if x.lower() != y.lower()])\n",
    "                    \n",
    "                    #remove dashes from string\n",
    "                    Aligned_Sequence_no_dashes = Aligned_Sequence.replace('-','')\n",
    "                    Reference_Sequence_no_dashes = Reference_Sequence.replace('-','')\n",
    "                    if Aligned_Sequence == Reference_Sequence:\n",
    "                        mutation_type = 'None'\n",
    "                        mutation_size = 'NA'\n",
    "                        insertion_positions = 'NA'\n",
    "                        deletion_positions = 'NA'\n",
    "                        substitution_positions = 'NA'\n",
    "                    elif Aligned_Sequence != Reference_Sequence:\n",
    "                    #find insertions, mutations, deletions\n",
    "                        #get length of reference sequence for the index\n",
    "                       # print(Reference_Sequence)\n",
    "                       # print(len(Reference_Sequence))\n",
    "                        #print(range(1,1+len(Reference_Sequence)))\n",
    "                        ref_index = [range(0,len(Reference_Sequence),1)]\n",
    "                        indels = find_indels_substitutions(Aligned_Sequence, Reference_Sequence, ref_index)\n",
    "                        #print(indels)\n",
    "                        #as well as labelling mutation types, get relative position of the mutation/mutations in the 40bp guide window\n",
    "                        if indels['insertion_n'] != 0:\n",
    "                            insertion_positions = indels['all_insertion_positions']\n",
    "                            if indels['deletion_n'] != 0:\n",
    "                                deletion_positions = indels['all_deletion_positions']\n",
    "                                if indels['substitution_n']  != 0:\n",
    "                                    substitution_positions = indels['all_substitution_positions']\n",
    "                                    mutation_type = 'insertion+deletion+substitution'\n",
    "                                    \n",
    "                                elif indels['substitution_n']  == 0:\n",
    "                                    substitution_positions = 'NA'\n",
    "                                    mutation_type = 'insertion+deletion'\n",
    "                            elif indels['deletion_n'] == 0:\n",
    "                                deletion_positions = 'NA'\n",
    "                                if indels['substitution_n']  != 0:\n",
    "                                    substitution_positions = indels['all_substitution_positions']\n",
    "                                    mutation_type = 'insertion+substitution'\n",
    "                                elif indels['substitution_n']  == 0:\n",
    "                                    substitution_positions = 'NA'\n",
    "                                    mutation_type = 'insertion'\n",
    "                        elif indels['insertion_n'] == 0:\n",
    "                            insertion_positions = 'NA'\n",
    "                            if indels['deletion_n'] != 0:\n",
    "                                deletion_positions = indels['all_deletion_positions']\n",
    "                                if indels['substitution_n'] != 0:\n",
    "                                    substitution_positions = indels['all_substitution_positions']\n",
    "                                    mutation_type = 'deletion+substitution'\n",
    "                                elif indels['substitution_n']  == 0:\n",
    "                                    substitution_positions = 'NA'\n",
    "                                    mutation_type = 'deletion'\n",
    "                            elif indels['deletion_n'] == 0:\n",
    "                                deletion_positions = 'NA'\n",
    "                                if indels['substitution_n']  != 0:\n",
    "                                    substitution_positions = indels['all_substitution_positions']\n",
    "                                    mutation_type = 'substitution'\n",
    "                                elif indels['substitution_n']  == 0:\n",
    "                                    substitution_positions = 'NA'\n",
    "                                    mutation_type = 'None'\n",
    "                    #get length of reference sequence\n",
    "                    ref_length = len(Reference_Sequence_no_dashes)\n",
    "                    #print(ref_length)\n",
    "\n",
    "                    #get cut site position in whole promoter\n",
    "                    cut_site_promoter_position = find_guide_position_in_gene(gene,Reference_Sequence_no_dashes,ref_length//2)\n",
    "                    #get cut site genomic position in whole promoter\n",
    "                    cut_site_position_relative_to_TSS,cut_site_genomic_position, promoter_genomic_pos_chromosome = find_genomic_position(reference_genomic_positions,gene,cut_site_promoter_position)\n",
    "\n",
    "\n",
    "                    #add distance from guide cut site column to df\n",
    "                    \n",
    "                   # print(ref_length)\n",
    "                    if insertion_positions == 'NA':\n",
    "                        insertion_cut_site_distance = 'NA'\n",
    "                        insertion_positions_relative_to_TSS = 'NA'\n",
    "                        insertion_genomic_positions = 'NA'\n",
    "                    else:\n",
    "                        #make list of insertion_cut_site_distances (distance of insertion from cut site)\n",
    "                        insertion_cut_site_distance = [i - ref_length//2 for i in insertion_positions]\n",
    "                        #make list of insertion cut site genomic position and also the position relative to the Araport TSS\n",
    "                        insertion_positions_relative_to_TSS = []\n",
    "                        insertion_genomic_positions = []\n",
    "                        for i in insertion_positions:\n",
    "                            site_promoter_position = find_guide_position_in_gene(gene,Reference_Sequence_no_dashes,i)\n",
    "                            position_relative_to_TSS,genomic_position, promoter_genomic_pos_chromosome = find_genomic_position(reference_genomic_positions,gene,site_promoter_position)\n",
    "                            insertion_positions_relative_to_TSS.append(position_relative_to_TSS)\n",
    "                            insertion_genomic_positions.append(genomic_position)\n",
    "                            \n",
    "\n",
    "\n",
    "             \n",
    "                    if deletion_positions == 'NA':\n",
    "                        deletion_cut_site_distance = 'NA'\n",
    "                        deletion_positions_relative_to_TSS = 'NA'\n",
    "                        deletion_genomic_positions = 'NA'\n",
    "\n",
    "                    else:\n",
    "                        #make list of deletion positions (distance of deletion from cut site)\n",
    "                        deletion_cut_site_distance = [i - ref_length//2 for i in deletion_positions]\n",
    "                        #make list of deletion cut site genomic position and also the position relative to the Araport TSS\n",
    "                        deletion_positions_relative_to_TSS = []\n",
    "                        deletion_genomic_positions = []\n",
    "                        for i in deletion_positions:\n",
    "                            site_promoter_position = find_guide_position_in_gene(gene,Reference_Sequence_no_dashes,i)\n",
    "                            position_relative_to_TSS,genomic_position, promoter_genomic_pos_chromosome = find_genomic_position(reference_genomic_positions,gene,site_promoter_position)\n",
    "                            deletion_positions_relative_to_TSS.append(position_relative_to_TSS)\n",
    "                            deletion_genomic_positions.append(genomic_position)\n",
    "\n",
    "                    if substitution_positions == 'NA':\n",
    "                        substitution_cut_site_distance = 'NA'\n",
    "                        substitution_positions_relative_to_TSS = 'NA'\n",
    "                        substitution_genomic_positions = 'NA'\n",
    "                    else:\n",
    "                        #make list of substitution positions (distance of substitution from cut site)\n",
    "                        substitution_cut_site_distance = [i - ref_length//2 for i in substitution_positions]\n",
    "                        #make list of substitution cut site genomic position and also the position relative to the Araport TSS\n",
    "                        substitution_positions_relative_to_TSS = []\n",
    "                        substitution_genomic_positions = []\n",
    "                        for i in substitution_positions:\n",
    "                            site_promoter_position = find_guide_position_in_gene(gene,Reference_Sequence_no_dashes,i)\n",
    "                            position_relative_to_TSS,genomic_position, promoter_genomic_pos_chromosome = find_genomic_position(reference_genomic_positions,gene,site_promoter_position)\n",
    "                            substitution_positions_relative_to_TSS.append(position_relative_to_TSS)\n",
    "                            substitution_genomic_positions.append(genomic_position)\n",
    "                            \n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    \n",
    "    #                     return {\n",
    "    #     'all_insertion_positions': all_insertion_positions,\n",
    "    #     'all_insertion_left_positions': all_insertion_left_positions,\n",
    "    #     'insertion_positions': insertion_positions,\n",
    "    #     'insertion_coordinates': insertion_coordinates,\n",
    "    #     'insertion_sizes': insertion_sizes,\n",
    "    #     'insertion_n': insertion_n,\n",
    "\n",
    "    #     'all_deletion_positions': all_deletion_positions,\n",
    "    #     'deletion_positions': deletion_positions,\n",
    "    #     'deletion_coordinates': deletion_coordinates,\n",
    "    #     'deletion_sizes': deletion_sizes,\n",
    "    #     'deletion_n': deletion_n,\n",
    "\n",
    "    #     'all_substitution_positions': all_substitution_positions,\n",
    "    #     'substitution_positions': substitution_positions,\n",
    "    #     'all_substitution_values': np.array(all_substitution_values),\n",
    "    #     'substitution_values': np.array(substitution_values),\n",
    "    #     'substitution_n': substitution_n,\n",
    "\n",
    "    #     'ref_positions': ref_positions,\n",
    "    # }\n",
    "                    \n",
    "                    #append list of values to output_df\n",
    "                    list = [platename,library,first_reaction_primers,second_reaction_primers,guide,Aligned_Sequence,Reference_Sequence,mutation_type,read_number,read_percentage,insertion_positions,deletion_positions,substitution_positions,insertion_cut_site_distance,deletion_cut_site_distance,substitution_cut_site_distance,cut_site_promoter_position,insertion_positions_relative_to_TSS,insertion_genomic_positions,deletion_positions_relative_to_TSS,deletion_genomic_positions,substitution_positions_relative_to_TSS,substitution_genomic_positions,]#mutation_size\n",
    "                    output_df.loc[len(output_df)] = list\n",
    "\n",
    "                    \n",
    "\n",
    "                    \n",
    "\n",
    "                    \n",
    "                    #temp_df.columns = cols\n",
    "                    #temp_df['long_sample_name'] = filename\n",
    "                    \n",
    "                    # temp_df = temp_df.assign(platename=platename,\n",
    "                    # new_library=new_library,\n",
    "                    # first_reaction_primers=first_reaction_primers,\n",
    "                    # second_reaction_primers=second_reaction_primers,\n",
    "                    # guide=guide,\n",
    "                    # aligned_sequence=Aligned_Sequence,\n",
    "                    # reference_sequence=Reference_Sequence,\n",
    "                    # mutation_type=mutation_type,\n",
    "                    # mutation_size=mutation_size)\n",
    "                    # temp_df['platename'] = platename\n",
    "                    # temp_df['library'] = new_library\n",
    "                    # temp_df['first_reaction_primers'] = first_reaction_primers\n",
    "                    # temp_df['second_reaction_primers'] = second_reaction_primers\n",
    "                    # temp_df['guide'] = guide\n",
    "                    # temp_df['aligned_sequence'] = Aligned_Sequence\n",
    "                    # temp_df['reference_sequence'] = Reference_Sequence\n",
    "                    # temp_df['mutation_type'] = mutation_type\n",
    "                    # temp_df['mutation_size'] = mutation_size\n",
    "                    #append to final df\n",
    "                    #output_df = pd.concat([temp_df,output_df],ignore_index=True)\n",
    "                  #  p#d.concat(temp_df,output_df)\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    #write out the output_df\n",
    "    output_df.to_csv(f'{output}{gene}.tsv', sep=\"\\t\", index=False, header=1)\n",
    "    \n",
    "\n",
    "\n",
    "                    \n",
    "                #print(filtered_reads)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/Variant_call'\n",
    "ARF9_root = f'{folder}/ARF9_sgRNAs/test'\n",
    "ARF18_root = f'{folder}/ARF18_sgRNAs/7bp_window_noplots'\n",
    "DREB26_root = f'{folder}/DREB26_sgRNAs/7bp_window_noplots'\n",
    "NLP7_root = f'{folder}/NLP7_sgRNAs/7bp_window_noplots'\n",
    "output = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/Variant_call/'\n",
    "#dictionary of reference fasta file locations\n",
    "reference_folder = '../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/References'\n",
    "reference_gene_dict = {'ARF9':f'{reference_folder}/ARF9_promoter.fa','ARF18':f'{reference_folder}/ARF18_promoter.fa','DREB26':f'{reference_folder}/DREB26_promoter.fa','NLP7':f'{reference_folder}/NLP7_promoter.fa'}\n",
    "#reference_fasta = f'{reference_folder}/genes_longest_region.fa'\n",
    "reference_promoter_bed = f'{reference_folder}/genes_longest_region.bed'\n",
    "#promoters bed file when 3' end is the TSS (used the bed file from promoter architecture non-overlapping_includingbidirectional_all_genes_newannotation project FIMO folder)\n",
    "all_promoters_bed = f'{reference_folder}/promoters.bed'\n",
    "#mapped motif bed file of TFBSs scanned with FIMO\n",
    "mapped_motifs_bed = '../../data/output/non-overlapping_includingbidirectional_all_genes_newannotation_3KB/FIMO/promoters_5UTR_motifs_mapped_q0_05.bed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get reference promoter genomic positions along with TSS position\n",
    "#in format [AGI,promoter_genomic_pos_chromosome,promoter_genomic_pos_start,promoter_genomic_pos_stop,TSS_pos]\n",
    "reference_genomic_positions = get_reference_promoter_genomic_positions(reference_promoter_bed,all_promoters_bed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all_insertion_positions': [19, 20], 'all_insertion_left_positions': [19], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 2, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, -20, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]}\n",
      "{'all_insertion_positions': [19, 20], 'all_insertion_left_positions': [19], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 2, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, -20, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]}\n",
      "{'all_insertion_positions': [19, 20], 'all_insertion_left_positions': [19], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 2, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, -20, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]}\n",
      "{'all_insertion_positions': [19, 20], 'all_insertion_left_positions': [19], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 2, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, -20, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]}\n",
      "{'all_insertion_positions': [0, 1], 'all_insertion_left_positions': [0], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 2, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, -1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]}\n",
      "{'all_insertion_positions': [0, 1], 'all_insertion_left_positions': [0], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 2, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, -1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]}\n",
      "{'all_insertion_positions': [], 'all_insertion_left_positions': [], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 0, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, -39]}\n",
      "{'all_insertion_positions': [], 'all_insertion_left_positions': [], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 0, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, -39]}\n",
      "{'all_insertion_positions': [22, 23], 'all_insertion_left_positions': [22], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 2, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, -23, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]}\n",
      "{'all_insertion_positions': [22, 23], 'all_insertion_left_positions': [22], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 2, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, -23, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]}\n",
      "{'all_insertion_positions': [1, 2], 'all_insertion_left_positions': [1], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 2, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, 1, -2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]}\n",
      "{'all_insertion_positions': [1, 2], 'all_insertion_left_positions': [1], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 2, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, 1, -2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]}\n",
      "{'all_insertion_positions': [19, 20], 'all_insertion_left_positions': [19], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 2, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, -20, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]}\n",
      "{'all_insertion_positions': [19, 20], 'all_insertion_left_positions': [19], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 2, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, -20, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]}\n",
      "{'all_insertion_positions': [0, 1], 'all_insertion_left_positions': [0], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 2, 'all_deletion_positions': [14, 15, 16], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 3, 'all_substitution_positions': [23], 'substitution_positions': [], 'all_substitution_values': array(['A'], dtype='<U1'), 'substitution_values': array([], dtype=float64), 'substitution_n': 1, 'ref_positions': [0, -1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]}\n",
      "{'all_insertion_positions': [], 'all_insertion_left_positions': [], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 0, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, -39]}\n",
      "{'all_insertion_positions': [22, 23], 'all_insertion_left_positions': [22], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 2, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, -23, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]}\n",
      "{'all_insertion_positions': [1, 2], 'all_insertion_left_positions': [1], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 2, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [], 'substitution_positions': [], 'all_substitution_values': array([], dtype=float64), 'substitution_values': array([], dtype=float64), 'substitution_n': 0, 'ref_positions': [0, 1, -2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]}\n",
      "{'all_insertion_positions': [], 'all_insertion_left_positions': [], 'insertion_positions': [], 'insertion_coordinates': [], 'insertion_sizes': [], 'insertion_n': 0, 'all_deletion_positions': [], 'deletion_positions': [], 'deletion_coordinates': [], 'deletion_sizes': [], 'deletion_n': 0, 'all_substitution_positions': [0, 25], 'substitution_positions': [], 'all_substitution_values': array(['T', 'C'], dtype='<U1'), 'substitution_values': array([], dtype=float64), 'substitution_n': 2, 'ref_positions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]}\n"
     ]
    }
   ],
   "source": [
    "check_guide(ARF9_root,output,'ARF9',reference_fasta,mapped_motifs_bed,reference_genomic_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b4317e48e5151a18b46d6908ccba584a1473587b38c50b55f51e0e363cb7dde"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pacbio_post_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
