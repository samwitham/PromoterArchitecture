{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alleles_frequency_table.zip can be unzipped to a tab-separated text file that shows all reads and alignments to references. The first column shows the aligned sequence of the sequenced read. The second column shows the aligned sequence of the reference sequence. Gaps in each of these columns represent insertions and deletions. The next column 'Reference_Name' shows the name of the reference that the read aligned to. The fourth column, 'Read_Status' shows whether the read was modified or unmodified. The fifth through seventh columns ('n_deleted', 'n_inserted', 'n_substituted') show the number of bases deleted, inserted, and substituted as compared to the reference sequence. The eighth column shows the number of reads having that sequence, and the ninth column shows the percentage of all reads having that sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #features to add:\n",
    "# Distance from TSS - get relative position of mutation in the guide site - done. Add distance from cut site metric. - done Then calculate distance from Araport TSS - done\n",
    "# for this: first create a bed file for all of the mutations (relative to whole Arabidopsis genome). Then do bedtools merge or intersect (or bedtools coverage (../data_sorting/./TFBS_coverage.sh)) with the mapped motif bed file (all TFBSs for all genes). Record each TFBS that overlaps the mutation\n",
    "# Overlapping TFBSs - subnetwork and all TFs\n",
    "\n",
    "# Include secondary mutations in case both deletion and substitution for example - done\n",
    "# Plant ID\n",
    "# How many biallelic or homozygous? How many wildtype?\n",
    "# More than 2 alleles for a gene - record alleles until 80% of reads accounted for\n",
    "# Prioiritse homozygous or biallelic\n",
    "# How many plants had mutations? How many guides produced mutations in each gene?\n",
    "#check window around cut site - at the moment I am including mutations 20bp either side, maybe cut the alignments down to 7bp either side before comparing them with find_indels_substitutions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use conda env pacbio_post_analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os\n",
    "import re \n",
    "from pyfaidx import Fasta\n",
    "import io\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #code from https://github.com/pinellolab/CRISPResso2/blob/master/CRISPResso2/CRISPRessoCOREResources.pyx\n",
    "# #import cython\n",
    "\n",
    "# # cimport numpy as np\n",
    "# import re\n",
    "\n",
    "# # cdef extern from \"stdlib.h\":\n",
    "# #     ctypedef unsigned int size_t\n",
    "# #     size_t strlen(char* s)\n",
    "\n",
    "\n",
    "# # cdef extern from \"Python.h\":\n",
    "# #     ctypedef void PyObject\n",
    "# #     int _PyBytes_Resize(PyObject **, size_t)\n",
    "# #     char * PyBytes_AS_STRING(PyObject *)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code from https://github.com/pinellolab/CRISPResso2/blob/master/CRISPResso2/CRISPRessoCOREResources.pyx\n",
    "#I converted it to pure python\n",
    "def find_indels_substitutions(read_seq_al, ref_seq_al, _include_indx):\n",
    "    re_find_indels = re.compile(\"(-*-)\")\n",
    "\n",
    "    #ref_positions holds the indices for which positions map back to the original reference\n",
    "    # for example,\n",
    "    #     1 2 3 4 5 6 7 8\n",
    "    # ref A A T T G G C C\n",
    "    #\n",
    "    # and for a given alignment\n",
    "    # ref A A T T - G G C C\n",
    "    # aln A - T T T G G C C\n",
    "    #     1 2 3 4-4 5 6 7 8 <ref positions. Note that the negative values/indices represent places that don't map back to the original reference\n",
    "    ref_positions=[]\n",
    "    all_substitution_positions=[]\n",
    "    substitution_positions=[]\n",
    "    all_substitution_values=[]\n",
    "    substitution_values=[]\n",
    "\n",
    "    all_deletion_positions = []\n",
    "    deletion_positions = []\n",
    "    deletion_coordinates = []\n",
    "    deletion_sizes = []\n",
    "    #cdef int start_deletion = -1  # the -1 value indicates that there currently isn't a deletion\n",
    "    start_deletion = -1  # the -1 value indicates that there currently isn't a deletion\n",
    "\n",
    "    all_insertion_positions = []\n",
    "    all_insertion_left_positions = []\n",
    "    insertion_positions = []\n",
    "    insertion_coordinates = []\n",
    "    insertion_sizes = []\n",
    "    #cdef int start_insertion = -1  # the -1 value indicates that there currently isn't an insertion\n",
    "    start_insertion = -1  # the -1 value indicates that there currently isn't an insertion\n",
    "\n",
    "    #cdef size_t seq_len = len(ref_seq_al)\n",
    "    seq_len = len(ref_seq_al)\n",
    "    include_indx_set = set(_include_indx)\n",
    "    nucSet = set(['A', 'T', 'C', 'G', 'N'])\n",
    "    # cdef int idx = 0\n",
    "    # cdef int idx_c\n",
    "    # cdef int current_insertion_size = 0\n",
    "    idx = 0\n",
    "    #idx_c\n",
    "    current_insertion_size = 0\n",
    "    for idx_c, c in enumerate(ref_seq_al):\n",
    "        #print(idx_c)\n",
    "        if c != '-':\n",
    "            ref_positions.append(idx)\n",
    "            if ref_seq_al[idx_c]!=read_seq_al[idx_c] and read_seq_al[idx_c] != '-' and read_seq_al[idx_c] != 'N':\n",
    "                all_substitution_positions.append(idx)\n",
    "                all_substitution_values.append(read_seq_al[idx_c])\n",
    "                if idx in _include_indx:\n",
    "                    substitution_positions.append(idx)\n",
    "                    substitution_values.append(read_seq_al[idx_c])\n",
    "            if start_insertion != -1:  # this is the end of an insertion\n",
    "                all_insertion_left_positions.append(start_insertion)\n",
    "                all_insertion_positions.append(start_insertion)\n",
    "                all_insertion_positions.append(idx)\n",
    "                if start_insertion in include_indx_set and idx in include_indx_set:\n",
    "                    insertion_coordinates.append((start_insertion, idx))\n",
    "                    insertion_positions.append(start_insertion)\n",
    "                    insertion_positions.append(idx)\n",
    "                    insertion_sizes.append(current_insertion_size)\n",
    "                start_insertion = -1\n",
    "            current_insertion_size = 0\n",
    "            idx += 1\n",
    "        else:  # the current ref position is -\n",
    "            if idx == 0:\n",
    "                ref_positions.append(-1)\n",
    "            else:\n",
    "                ref_positions.append(-idx)\n",
    "            if idx > 0 and start_insertion == -1:  # this is the first index of an insertion\n",
    "                start_insertion = idx - 1\n",
    "            current_insertion_size += 1\n",
    "\n",
    "        if read_seq_al[idx_c] == '-' and start_deletion == -1:  # this is the first part of a deletion\n",
    "            if idx_c - 1 > 0:\n",
    "                start_deletion = ref_positions[idx_c]\n",
    "            else:\n",
    "                start_deletion = 0\n",
    "        elif read_seq_al[idx_c] != '-' and start_deletion != -1:  # this is the end of a deletion\n",
    "            end_deletion = ref_positions[idx_c]\n",
    "            all_deletion_positions.extend(range(start_deletion, end_deletion))\n",
    "            if include_indx_set.intersection(range(start_deletion, end_deletion)):\n",
    "                deletion_positions.extend(range(start_deletion, end_deletion))\n",
    "                deletion_coordinates.append((start_deletion, end_deletion))\n",
    "                deletion_sizes.append(end_deletion - start_deletion)\n",
    "            start_deletion = -1\n",
    "\n",
    "    if start_deletion != -1:\n",
    "        end_deletion = ref_positions[seq_len - 1]\n",
    "        all_deletion_positions.extend(range(start_deletion, end_deletion))\n",
    "        if include_indx_set.intersection(range(start_deletion, end_deletion)):\n",
    "            deletion_positions.extend(range(start_deletion, end_deletion))\n",
    "            deletion_coordinates.append((start_deletion, end_deletion))\n",
    "            deletion_sizes.append(end_deletion - start_deletion)\n",
    "\n",
    "    # cdef size_t substitution_n = len(substitution_positions)\n",
    "    # cdef size_t deletion_n = sum(deletion_sizes)\n",
    "    # cdef size_t insertion_n = sum(insertion_sizes)\n",
    "    substitution_n = len(all_substitution_positions)\n",
    "    deletion_n = len(all_deletion_positions)\n",
    "    insertion_n = len(all_insertion_positions)\n",
    "\n",
    "    return {\n",
    "        'all_insertion_positions': all_insertion_positions,\n",
    "        'all_insertion_left_positions': all_insertion_left_positions,\n",
    "        'insertion_positions': insertion_positions,\n",
    "        'insertion_coordinates': insertion_coordinates,\n",
    "        'insertion_sizes': insertion_sizes,\n",
    "        'insertion_n': insertion_n,\n",
    "\n",
    "        'all_deletion_positions': all_deletion_positions,\n",
    "        'deletion_positions': deletion_positions,\n",
    "        'deletion_coordinates': deletion_coordinates,\n",
    "        'deletion_sizes': deletion_sizes,\n",
    "        'deletion_n': deletion_n,\n",
    "\n",
    "        'all_substitution_positions': all_substitution_positions,\n",
    "        'substitution_positions': substitution_positions,\n",
    "        'all_substitution_values': np.array(all_substitution_values),\n",
    "        'substitution_values': np.array(substitution_values),\n",
    "        'substitution_n': substitution_n,\n",
    "\n",
    "        'ref_positions': ref_positions,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_guide_position_in_gene(gene,cut_site_reference_seq, guide_position):\n",
    "    \"\"\"function to find the relative promoter position of the current guide site position in the reference gene\"\"\"\n",
    "    fasta_location = reference_gene_dict[gene]\n",
    "    #read in fasta file\n",
    "    fasta = Fasta(\n",
    "        fasta_location\n",
    "    )\n",
    "    #get promoter sequence\n",
    "    prom_seq = str(fasta[f'{gene}_promoter'])\n",
    "    #print(fasta[f'{gene}_promoter'])\n",
    "    #find position of substring in string\n",
    "    #remove 'N's from sequence\n",
    "    cut_site_reference_seq = cut_site_reference_seq.replace('N', '')\n",
    "    start_location = prom_seq.index(cut_site_reference_seq)\n",
    "    site_promoter_position = start_location + guide_position\n",
    "    return site_promoter_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_promoter_genomic_positions(reference_promoter_bed,all_promoters_bed):\n",
    "    \"\"\"function to get the reference promoter genomic positions and to get the tSS genomic position\"\"\"\n",
    "     #read in reference_promoter_bed\n",
    "    reference_promoter_df = pd.read_table(\n",
    "        reference_promoter_bed, sep=\"\\t\", header=None\n",
    "    )\n",
    "    cols = [\n",
    "        \"chr\",\n",
    "        \"start\",\n",
    "        \"stop\",\n",
    "        \"promoter_name\",\n",
    "        \"score\",\n",
    "        \"strand\",\n",
    "        ]\n",
    "    reference_promoter_df.columns = cols\n",
    "\n",
    "    #read in all_promoters_bed\n",
    "    all_promoters_df = pd.read_table(\n",
    "        all_promoters_bed, sep=\"\\t\", header=None\n",
    "    )\n",
    "    cols2 = [\n",
    "        \"chr\",\n",
    "        \"start\",\n",
    "        \"stop\",\n",
    "        \"AGI\",\n",
    "        \"dot\",\n",
    "        \"strand\",\n",
    "        \"source\",\n",
    "        \"type\",\n",
    "        \"dot2\",\n",
    "        \"attributes\",\n",
    "    ]\n",
    "    all_promoters_df.columns = cols2\n",
    "\n",
    "    #AGIs dictionary of the four genes\n",
    "    AGI_dict = {'DREB26':'AT1G21910','NLP7':'AT4G24020','ARF18':'AT3G61830','ARF9':'AT4G23980'}\n",
    "    #make empty dict\n",
    "    reference_genomic_positions = {}\n",
    "    #get promoter genomic positions\n",
    "    for gene,AGI in AGI_dict.items():\n",
    "        promoter_genomic_pos_chromosome = int(reference_promoter_df[reference_promoter_df.promoter_name == f'{gene}_promoter'].chr)\n",
    "        promoter_genomic_pos_start = int(reference_promoter_df[reference_promoter_df.promoter_name == f'{gene}_promoter'].start)\n",
    "        promoter_genomic_pos_stop = int(reference_promoter_df[reference_promoter_df.promoter_name == f'{gene}_promoter'].stop)\n",
    "\n",
    "        #get TSS position\n",
    "        TSS_pos = int(all_promoters_df[all_promoters_df.AGI==AGI].stop)\n",
    "        #temp_dict = {gene:[AGI,promoter_genomic_pos_chromosome,promoter_genomic_pos_start,promoter_genomic_pos_stop,TSS_pos]}\n",
    "        #write to dict\n",
    "        reference_genomic_positions[gene]= [AGI,promoter_genomic_pos_chromosome,promoter_genomic_pos_start,promoter_genomic_pos_stop,TSS_pos]\n",
    "    return reference_genomic_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_genomic_position(reference_genomic_positions,gene,promoter_position):\n",
    "    \"\"\"get the genomic position of the cut site\"\"\"\n",
    "    positions_list = reference_genomic_positions[gene]\n",
    "    #first get genomic position of the cut site\n",
    "    promoter_genomic_pos_chromosome = positions_list[1]\n",
    "    promoter_genomic_pos_start = positions_list[2]\n",
    "    promoter_genomic_pos_stop = positions_list[3]\n",
    "    #get the genomic location of the input promoter position\n",
    "    #print(f'prom_position={promoter_position}, prom_genom_pos_start={promoter_genomic_pos_start}')\n",
    "    genomic_position = promoter_position+promoter_genomic_pos_start\n",
    "    #get position of cut site relative to TSS position\n",
    "    #get TSS position\n",
    "    TSS_pos = positions_list[4]\n",
    "    position_relative_to_TSS = genomic_position - TSS_pos\n",
    "\n",
    "    return position_relative_to_TSS,genomic_position, promoter_genomic_pos_chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def merge_bedfiles(bedfile, mapped_motifs_bed, output_file):\n",
    "#     \"\"\"perform bedtools intersect on the two dfs\"\"\"\n",
    "#     df = BedTool(bedfile)\n",
    "#     motifs = mapped_motifs_bed\n",
    "#     # -wao =Write the original A and B entries plus the number of base pairs of overlap between the two features.\n",
    "#     # However, A features w/o overlap are also reported with a NULL B feature and overlap = 0\n",
    "#     intersect = df.intersect(motifs, wao=True)\n",
    "#     # Write to output_file\n",
    "#     with open(output_file, \"w\") as output:\n",
    "#         # Each line in the file contains bed entry a and bed entry b that it overlaps plus the number of bp in the overlap so 19 columns\n",
    "#         output.write(str(intersect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlapping_TFBSs(mutations_df,mapped_motifs_bed):\n",
    "    \"\"\"function to find any overlapping TFBSs from FIMO mapped motif file\"\"\"\n",
    "    #import required moule within new conda env\n",
    "    from pybedtools import BedTool\n",
    "    import pandas as pd\n",
    "    #import numpy as np\n",
    "    import io\n",
    "    #read in mapped motifs bed file\n",
    "    mapped_motifs = pd.read_table(mapped_motifs_bed, sep=\"\\t\", header=None)\n",
    "    if len(mapped_motifs.columns) == 24:\n",
    "        cols = [\n",
    "            \"chr\",\n",
    "            \"start\",\n",
    "            \"stop\",\n",
    "            \"promoter_AGI\",\n",
    "            \"dot1\",\n",
    "            \"strand\",\n",
    "            \"source\",\n",
    "            \"type\",\n",
    "            \"dot2\",\n",
    "            \"attributes\",\n",
    "            \"motif_chr\",\n",
    "            \"motif_start\",\n",
    "            \"motif_stop\",\n",
    "            \"name_rep\",\n",
    "            \"score\",\n",
    "            \"motif_strand\",\n",
    "            \"promoter_AGI2\",\n",
    "            \"p-value\",\n",
    "            \"q-value\",\n",
    "            \"matched_sequence\",\n",
    "            \"TF_name\",\n",
    "            \"TF_family\",\n",
    "            \"TF_AGI\",\n",
    "            \"bp_overlap\",\n",
    "        ]\n",
    "        mapped_motifs.columns = cols\n",
    "        # filter columns\n",
    "        mapped_motifs = mapped_motifs[\n",
    "            [\n",
    "                \"motif_chr\",\n",
    "                \"motif_start\",\n",
    "                \"motif_stop\",\n",
    "                \"name_rep\",\n",
    "                \"score\",\n",
    "                \"motif_strand\",\n",
    "                \"promoter_AGI2\",\n",
    "                \"p-value\",\n",
    "                \"q-value\",\n",
    "                \"matched_sequence\",\n",
    "                \"TF_name\",\n",
    "                \"TF_family\",\n",
    "                \"TF_AGI\",\n",
    "            ]\n",
    "        ]\n",
    "        # rename columns\n",
    "        cols = [\n",
    "            \"chr\",\n",
    "            \"start\",\n",
    "            \"stop\",\n",
    "            \"name_rep\",\n",
    "            \"score\",\n",
    "            \"strand\",\n",
    "            \"promoter_AGI\",\n",
    "            \"p-value\",\n",
    "            \"q-value\",\n",
    "            \"matched_sequence\",\n",
    "            \"TF_name\",\n",
    "            \"TF_family\",\n",
    "            \"TF_AGI\",\n",
    "        ]\n",
    "        mapped_motifs.columns = cols\n",
    "\n",
    "    elif len(mapped_motifs.columns) == 13:\n",
    "        cols = [\n",
    "            \"chr\",\n",
    "            \"start\",\n",
    "            \"stop\",\n",
    "            \"name_rep\",\n",
    "            \"score\",\n",
    "            \"strand\",\n",
    "            \"promoter_AGI\",\n",
    "            \"p-value\",\n",
    "            \"q-value\",\n",
    "            \"matched_sequence\",\n",
    "            \"TF_name\",\n",
    "            \"TF_family\",\n",
    "            \"TF_AGI\",\n",
    "        ]\n",
    "        mapped_motifs.columns = cols\n",
    "\n",
    "    elif len(mapped_motifs.columns) == 17:\n",
    "        cols = [\n",
    "            \"chr\",\n",
    "            \"start\",\n",
    "            \"stop\",\n",
    "            \"name_rep\",\n",
    "            \"score\",\n",
    "            \"strand\",\n",
    "            \"promoter_AGI\",\n",
    "            \"p-value\",\n",
    "            \"q-value\",\n",
    "            \"matched_sequence\",\n",
    "            \"TF_name\",\n",
    "            \"TF_family\",\n",
    "            \"TF_AGI\",\n",
    "            \"chr_openchrom\",\n",
    "            \"start_openchrom\",\n",
    "            \"stop_openchrom\",\n",
    "            \"bp_overlap\",\n",
    "        ]\n",
    "        mapped_motifs.columns = cols\n",
    "\n",
    "    #for each guide containing mutations, create a temporary bed file containing each mutation and then do bedtools intersect to find which overlap TFBs\n",
    "    #then add the TFBS names into a new column for that row\n",
    "    \n",
    "\n",
    "\n",
    "    for index,row in mutations_df.iterrows():\n",
    "            \n",
    "            if row.mutation_type == 'None':\n",
    "                pass\n",
    "            else:\n",
    "                #create temporary df in bed format\n",
    "                \n",
    "                cols = [\"chr\",\n",
    "                \"start\",\n",
    "                \"stop\",\n",
    "                \"mutation_type\",]\n",
    "                temp_df = pd.DataFrame(columns=cols)\n",
    "                chr = row.chr\n",
    "                if row.insertion_genomic_positions != \"NA\":\n",
    "                    #print(\"Index:\", index)\n",
    "                    #print(row.insertion_genomic_positions)\n",
    "                    #convert genomic positions from string to list\n",
    "                    # Convert string to list if more than one\n",
    "                    insertion_genomic_positions = row.insertion_genomic_positions.strip('][').split(', ')\n",
    "                    \n",
    "                    for gen_pos in insertion_genomic_positions:\n",
    "\n",
    "                        #get index\n",
    "                        if len(insertion_genomic_positions) > 1:\n",
    "                            index = insertion_genomic_positions.index(gen_pos)\n",
    "                        else:\n",
    "                            index = 'NA'\n",
    "                        start = int(gen_pos)\n",
    "                        stop = start + 1\n",
    "                        mutation_type = \"insertion\"\n",
    "                        #add to temp_df\n",
    "                        list = [chr,start,stop,mutation_type]\n",
    "                        temp_df.loc[len(temp_df)] = list\n",
    "\n",
    "                if row.deletion_genomic_positions != \"NA\":\n",
    "                    # Convert string to list\n",
    "                    deletion_genomic_positions = row.deletion_genomic_positions.strip('][').split(', ')\n",
    "\n",
    "                    for gen_pos in deletion_genomic_positions:\n",
    "\n",
    "                        #get index\n",
    "                        if len(deletion_genomic_positions) > 1:\n",
    "                            index = deletion_genomic_positions.index(gen_pos)\n",
    "                        else:\n",
    "                            index = 'NA'\n",
    "\n",
    "                        start = int(gen_pos)\n",
    "                        stop = start + 1\n",
    "                        mutation_type = \"deletion\"\n",
    "                        #add to temp_df\n",
    "                        list = [chr,start,stop,mutation_type]\n",
    "                        temp_df.loc[len(temp_df)] = list\n",
    "\n",
    "                if row.substitution_genomic_positions != \"NA\":\n",
    "                    # Convert string to list\n",
    "                    substitution_genomic_positions = row.substitution_genomic_positions.strip('][').split(', ')\n",
    "                    for gen_pos in insertion_genomic_positions:\n",
    "                        #get index\n",
    "                        if len(substitution_genomic_positions) > 1:\n",
    "                            index = substitution_genomic_positions.index(gen_pos)\n",
    "                        else:\n",
    "                            index = 'NA'\n",
    "                        start = int(gen_pos)\n",
    "                        stop = start + 1\n",
    "                        mutation_type = \"substitution\"\n",
    "                        #add to temp_df\n",
    "                        list = [chr,start,stop,mutation_type]\n",
    "                        temp_df.loc[len(temp_df)] = list\n",
    "                #now do bedtools intersect to find which TFBSs overlap with which mutations\n",
    "                # write to buffer\n",
    "                df_buffer = io.StringIO()\n",
    "            \n",
    "                merge_bedfiles(temp_df, mapped_motifs_bed, df_buffer)\n",
    "                #go back to beginning of the buffer\n",
    "                df_buffer.seek(0)\n",
    "                print(df_buffer)      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #source different conda env containing pybedtools as currently it's incompatible with the current conda env\n",
    "# #subprocess.run('source activate PromoterArchitecturePipeline && \"find_overlapping_TFBSs(output_df_merged,mapped_motifs_bed)\" && source deactivate', shell=True)\n",
    "# os.system(\"source activate PromoterArchitecturePipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_overlapping_TFBSs(output_df_merged,mapped_motifs_bed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_guide(root_dir,output,gene,reference_fasta,mapped_motifs_bed,reference_genomic_positions,plantIDs):\n",
    "    \"\"\"read in the Alleles_frequency_table txt files\"\"\"\n",
    "    #create the output file\n",
    "    cols = ['chr','platename','library','first_reaction_primers','second_reaction_primers','guide','aligned_sequence','reference_sequence','mutation_type','read_number','read_percentage','insertion_positions','deletion_positions','substitution_positions','insertion_cut_site_distance','deletion_cut_site_distance','substitution_cut_site_distance','cut_site_promoter_position','insertion_positions_relative_to_TSS','insertion_genomic_positions','deletion_positions_relative_to_TSS','deletion_genomic_positions','substitution_positions_relative_to_TSS','substitution_genomic_positions']#'mutation_size',\n",
    "    output_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    #read in plant IDs table\n",
    "    plant_ID_cols=['plant_ID','F_primer','R_primer','barcode_no','platename']\n",
    "    plantID_df = pd.read_table(plantIDs,sep='\\t',header=0)\n",
    "    plantID_df.columns = plant_ID_cols\n",
    "    for subdir, dirs, files in os.walk(root_dir):        \n",
    "            for filename in fnmatch.filter(files,f\"*Alleles_frequency_table_around_{gene}_*.txt\"):\n",
    "                #print (os.path.join(subdir, filename))\n",
    "                #read in as df\n",
    "                df = pd.read_table(os.path.join(subdir, filename), sep=\"\\t\", header=0)\n",
    "                #filter out rows with reads less than 10\n",
    "                filtered_reads = df[df['#Reads'] >= 10]\n",
    "                #save each row to df\n",
    "                for index, row in filtered_reads.iterrows():\n",
    "                    \n",
    "                    #check if aligned and reference are different\n",
    "                    Aligned_Sequence = row.Aligned_Sequence\n",
    "                    Reference_Sequence = row.Reference_Sequence\n",
    "                    \n",
    "\n",
    "                    #split filename on .\n",
    "                    partitioned_string = filename.partition('.')\n",
    "                    #get second PCR reaction primers\n",
    "                    second_reaction_primers = partitioned_string[0]\n",
    "                    #get guide name\n",
    "                    guide = re.search(f\"[_]+({gene}(.*))\",partitioned_string[2].partition('.')[0])[1]                 \n",
    "                    #get first reaction PCR primers and library number\n",
    "                    library_primers = re.search(\"_bc(.*)\",subdir)[0]\n",
    "                    both_primers = re.findall(\"SW(\\d*)\",library_primers)\n",
    "                    #if 2 found, create first_reaction_primers value\n",
    "                    if len(both_primers) == 2:\n",
    "                        first_reaction_primers = f'SW{both_primers[0]}_SW{both_primers[1]}'\n",
    "                    else:\n",
    "                        first_reaction_primers = 'NA'\n",
    "\n",
    "                    \n",
    "                    library = re.search(\"[^_bc]+(\\d*)\",library_primers)[0]\n",
    "                    read_number = row['#Reads']\n",
    "                    read_percentage = row['%Reads']\n",
    "                    \n",
    "                    \n",
    "                    #convert library number to different number (from 1017 to 1, 1018 to 2 etc)\n",
    "                    if int(library) == 1017:\n",
    "                        new_library = 1\n",
    "                    elif int(library) == 1018:\n",
    "                        new_library = 2\n",
    "                    elif int(library) == 1019:\n",
    "                        new_library = 3\n",
    "                    elif int(library) == 1020:\n",
    "                        new_library = 4\n",
    "                    elif int(library) == 1021:\n",
    "                        new_library = 5\n",
    "                    elif int(library) == 1022:\n",
    "                        new_library = 6\n",
    "                    #print(new_library)\n",
    "                    platename = f'p{new_library}{gene}'\n",
    "                    #distance_from_TSS =\n",
    "                    #sequence = \n",
    "\n",
    "                    #remove dashes from string\n",
    "                    # Aligned_Sequence_no_dashes = Aligned_Sequence.replace('-','')\n",
    "                    # Reference_Sequence_no_dashes = Reference_Sequence.replace('-','')\n",
    "                    # if Aligned_Sequence == Reference_Sequence:\n",
    "                    #     mutation_type = 'None'\n",
    "                    #     mutation_size = 'NA'\n",
    "                    # elif Aligned_Sequence != Reference_Sequence:\n",
    "                    #     #if insertion\n",
    "                    #     if len(Aligned_Sequence_no_dashes) > len(Reference_Sequence_no_dashes):\n",
    "                    #         mutation_type = 'insertion'\n",
    "                    #         mutation_size = len(Aligned_Sequence_no_dashes)-len(Reference_Sequence_no_dashes)\n",
    "                            \n",
    "                    #     #if deletion\n",
    "                    #     elif len(Reference_Sequence_no_dashes) > len(Aligned_Sequence_no_dashes):\n",
    "                    #         mutation_type = 'deletion'\n",
    "                    #         mutation_size = len(Reference_Sequence_no_dashes)-len(Aligned_Sequence_no_dashes)\n",
    "                    #     #if substition\n",
    "                    #     elif len(Reference_Sequence_no_dashes) == len(Aligned_Sequence_no_dashes):\n",
    "                    #         mutation_type = 'substitution'\n",
    "                    #         #mutation size is the Hamming distance between the two strings\n",
    "                    #         mutation_size = sum([1 for x, y in zip(Aligned_Sequence_no_dashes, Reference_Sequence_no_dashes) if x.lower() != y.lower()])\n",
    "                    \n",
    "                    #remove dashes from string\n",
    "                    Aligned_Sequence_no_dashes = Aligned_Sequence.replace('-','')\n",
    "                    Reference_Sequence_no_dashes = Reference_Sequence.replace('-','')\n",
    "                    if Aligned_Sequence == Reference_Sequence:\n",
    "                        mutation_type = 'None'\n",
    "                        mutation_size = 'NA'\n",
    "                        insertion_positions = 'NA'\n",
    "                        deletion_positions = 'NA'\n",
    "                        substitution_positions = 'NA'\n",
    "                    elif Aligned_Sequence != Reference_Sequence:\n",
    "                    #find insertions, mutations, deletions\n",
    "                        #get length of reference sequence for the index\n",
    "                       # print(Reference_Sequence)\n",
    "                       # print(len(Reference_Sequence))\n",
    "                        #print(range(1,1+len(Reference_Sequence)))\n",
    "                        #add 'N's to each end of the sequences so that edge case deletions/insertions aren't ignored\n",
    "                        Aligned_Sequence_Ns = 'N'+Aligned_Sequence+'N'\n",
    "                        Reference_Sequence_Ns = 'N'+Reference_Sequence+'N'\n",
    "                        ref_index = [range(0,len(Reference_Sequence_Ns),1)]\n",
    "                        indels = find_indels_substitutions(Aligned_Sequence_Ns, Reference_Sequence_Ns, ref_index)\n",
    "                        #NEED TO SUBTRACT ONE TO ALL POSITIONS BECAUSE USED AN ADDED 'N' BEFORE REFERENCE SEQUENCE WHEN FINDING INDELS\n",
    "\n",
    "                        #print(indels)\n",
    "                        #as well as labelling mutation types, get relative position of the mutation/mutations in the 40bp guide window\n",
    "                        if indels['insertion_n'] != 0:\n",
    "                            #NEED TO SUBTRACT ONE TO ALL POSITIONS BECAUSE USED AN ADDED 'N' BEFORE REFERENCE SEQUENCE WHEN FINDING INDELS\n",
    "                            insertion_positions = [x-1 for x in indels['all_insertion_positions']]\n",
    "                            if indels['deletion_n'] != 0:\n",
    "                                deletion_positions = [x-1 for x in indels['all_deletion_positions']]\n",
    "                                if indels['substitution_n']  != 0:\n",
    "                                    substitution_positions = [x-1 for x in indels['all_substitution_positions']]\n",
    "                                    mutation_type = 'insertion+deletion+substitution'\n",
    "                                    \n",
    "                                elif indels['substitution_n']  == 0:\n",
    "                                    substitution_positions = 'NA'\n",
    "                                    mutation_type = 'insertion+deletion'\n",
    "                            elif indels['deletion_n'] == 0:\n",
    "                                deletion_positions = 'NA'\n",
    "                                if indels['substitution_n']  != 0:\n",
    "                                    substitution_positions = [x-1 for x in indels['all_substitution_positions']]\n",
    "                                    mutation_type = 'insertion+substitution'\n",
    "                                elif indels['substitution_n']  == 0:\n",
    "                                    substitution_positions = 'NA'\n",
    "                                    mutation_type = 'insertion'\n",
    "                        elif indels['insertion_n'] == 0:\n",
    "                            insertion_positions = 'NA'\n",
    "                            if indels['deletion_n'] != 0:\n",
    "                                deletion_positions = [x-1 for x in indels['all_deletion_positions']]\n",
    "                                if indels['substitution_n'] != 0:\n",
    "                                    substitution_positions = [x-1 for x in indels['all_substitution_positions']]\n",
    "                                    mutation_type = 'deletion+substitution'\n",
    "                                elif indels['substitution_n']  == 0:\n",
    "                                    substitution_positions = 'NA'\n",
    "                                    mutation_type = 'deletion'\n",
    "                            elif indels['deletion_n'] == 0:\n",
    "                                deletion_positions = 'NA'\n",
    "                                if indels['substitution_n']  != 0:\n",
    "                                    substitution_positions = [x-1 for x in indels['all_substitution_positions']]\n",
    "                                    mutation_type = 'substitution'\n",
    "                                elif indels['substitution_n']  == 0:\n",
    "                                    substitution_positions = 'NA'\n",
    "                                    mutation_type = 'None'\n",
    "                    #get length of reference sequence\n",
    "                    ref_length = len(Reference_Sequence_no_dashes)\n",
    "                    #print(ref_length)                    \n",
    "                    # if ref_length < 40:\n",
    "                        \n",
    "                    #     print(Reference_Sequence_no_dashes)\n",
    "                    #     print(row)\n",
    "\n",
    "                    #get cut site position in whole promoter\n",
    "                    cut_site_promoter_position = find_guide_position_in_gene(gene,Reference_Sequence_no_dashes,ref_length//2)\n",
    "                    #get cut site genomic position in whole promoter\n",
    "                    cut_site_position_relative_to_TSS,cut_site_genomic_position, promoter_genomic_pos_chromosome = find_genomic_position(reference_genomic_positions,gene,cut_site_promoter_position)\n",
    "                    #add plant ID\n",
    "                    \n",
    "\n",
    "\n",
    "                    #add distance from guide cut site column to df\n",
    "                    \n",
    "                   # print(ref_length)\n",
    "                    if insertion_positions == 'NA':\n",
    "                        insertion_cut_site_distance = 'NA'\n",
    "                        insertion_positions_relative_to_TSS = 'NA'\n",
    "                        insertion_genomic_positions = 'NA'\n",
    "                    else:\n",
    "                        #make list of insertion_cut_site_distances (distance of insertion from cut site)\n",
    "                        insertion_cut_site_distance = [i - ref_length//2 for i in insertion_positions]\n",
    "                        #make list of insertion cut site genomic position and also the position relative to the Araport TSS\n",
    "                        insertion_positions_relative_to_TSS = []\n",
    "                        insertion_genomic_positions = []\n",
    "                        for i in insertion_positions:\n",
    "                            site_promoter_position = find_guide_position_in_gene(gene,Reference_Sequence_no_dashes,i)\n",
    "                            position_relative_to_TSS,genomic_position, promoter_genomic_pos_chromosome = find_genomic_position(reference_genomic_positions,gene,site_promoter_position)\n",
    "                            insertion_positions_relative_to_TSS.append(position_relative_to_TSS)\n",
    "                            insertion_genomic_positions.append(genomic_position)\n",
    "                            \n",
    "\n",
    "\n",
    "             \n",
    "                    if deletion_positions == 'NA':\n",
    "                        deletion_cut_site_distance = 'NA'\n",
    "                        deletion_positions_relative_to_TSS = 'NA'\n",
    "                        deletion_genomic_positions = 'NA'\n",
    "\n",
    "                    else:\n",
    "                        #make list of deletion positions (distance of deletion from cut site)\n",
    "                        deletion_cut_site_distance = [i - ref_length//2 for i in deletion_positions]\n",
    "                        #make list of deletion cut site genomic position and also the position relative to the Araport TSS\n",
    "                        deletion_positions_relative_to_TSS = []\n",
    "                        deletion_genomic_positions = []\n",
    "                        for i in deletion_positions:\n",
    "                            site_promoter_position = find_guide_position_in_gene(gene,Reference_Sequence_no_dashes,i)\n",
    "                            position_relative_to_TSS,genomic_position, promoter_genomic_pos_chromosome = find_genomic_position(reference_genomic_positions,gene,site_promoter_position)\n",
    "                            deletion_positions_relative_to_TSS.append(position_relative_to_TSS)\n",
    "                            deletion_genomic_positions.append(genomic_position)\n",
    "\n",
    "                    if substitution_positions == 'NA':\n",
    "                        substitution_cut_site_distance = 'NA'\n",
    "                        substitution_positions_relative_to_TSS = 'NA'\n",
    "                        substitution_genomic_positions = 'NA'\n",
    "                    else:\n",
    "                        #make list of substitution positions (distance of substitution from cut site)\n",
    "                        substitution_cut_site_distance = [i - ref_length//2 for i in substitution_positions]\n",
    "                        #make list of substitution cut site genomic position and also the position relative to the Araport TSS\n",
    "                        substitution_positions_relative_to_TSS = []\n",
    "                        substitution_genomic_positions = []\n",
    "                        for i in substitution_positions:\n",
    "                            site_promoter_position = find_guide_position_in_gene(gene,Reference_Sequence_no_dashes,i)\n",
    "                            position_relative_to_TSS,genomic_position, promoter_genomic_pos_chromosome = find_genomic_position(reference_genomic_positions,gene,site_promoter_position)\n",
    "                            substitution_positions_relative_to_TSS.append(position_relative_to_TSS)\n",
    "                            substitution_genomic_positions.append(genomic_position)\n",
    "                            \n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "                    \n",
    "    #                     return {\n",
    "    #     'all_insertion_positions': all_insertion_positions,\n",
    "    #     'all_insertion_left_positions': all_insertion_left_positions,\n",
    "    #     'insertion_positions': insertion_positions,\n",
    "    #     'insertion_coordinates': insertion_coordinates,\n",
    "    #     'insertion_sizes': insertion_sizes,\n",
    "    #     'insertion_n': insertion_n,\n",
    "\n",
    "    #     'all_deletion_positions': all_deletion_positions,\n",
    "    #     'deletion_positions': deletion_positions,\n",
    "    #     'deletion_coordinates': deletion_coordinates,\n",
    "    #     'deletion_sizes': deletion_sizes,\n",
    "    #     'deletion_n': deletion_n,\n",
    "\n",
    "    #     'all_substitution_positions': all_substitution_positions,\n",
    "    #     'substitution_positions': substitution_positions,\n",
    "    #     'all_substitution_values': np.array(all_substitution_values),\n",
    "    #     'substitution_values': np.array(substitution_values),\n",
    "    #     'substitution_n': substitution_n,\n",
    "\n",
    "    #     'ref_positions': ref_positions,\n",
    "    # }\n",
    "                    \n",
    "                    #append list of values to output_df\n",
    "                    list = [promoter_genomic_pos_chromosome,platename,library,first_reaction_primers,second_reaction_primers,guide,Aligned_Sequence,Reference_Sequence,mutation_type,read_number,read_percentage,insertion_positions,deletion_positions,substitution_positions,insertion_cut_site_distance,deletion_cut_site_distance,substitution_cut_site_distance,cut_site_promoter_position,insertion_positions_relative_to_TSS,insertion_genomic_positions,deletion_positions_relative_to_TSS,deletion_genomic_positions,substitution_positions_relative_to_TSS,substitution_genomic_positions,]#mutation_size\n",
    "                    output_df.loc[len(output_df)] = list\n",
    "\n",
    "                    \n",
    "\n",
    "                    \n",
    "\n",
    "                    \n",
    "\n",
    "                    \n",
    "                    #temp_df.columns = cols\n",
    "                    #temp_df['long_sample_name'] = filename\n",
    "                    \n",
    "                    # temp_df = temp_df.assign(platename=platename,\n",
    "                    # new_library=new_library,\n",
    "                    # first_reaction_primers=first_reaction_primers,\n",
    "                    # second_reaction_primers=second_reaction_primers,\n",
    "                    # guide=guide,\n",
    "                    # aligned_sequence=Aligned_Sequence,\n",
    "                    # reference_sequence=Reference_Sequence,\n",
    "                    # mutation_type=mutation_type,\n",
    "                    # mutation_size=mutation_size)\n",
    "                    # temp_df['platename'] = platename\n",
    "                    # temp_df['library'] = new_library\n",
    "                    # temp_df['first_reaction_primers'] = first_reaction_primers\n",
    "                    # temp_df['second_reaction_primers'] = second_reaction_primers\n",
    "                    # temp_df['guide'] = guide\n",
    "                    # temp_df['aligned_sequence'] = Aligned_Sequence\n",
    "                    # temp_df['reference_sequence'] = Reference_Sequence\n",
    "                    # temp_df['mutation_type'] = mutation_type\n",
    "                    # temp_df['mutation_size'] = mutation_size\n",
    "                    #append to final df\n",
    "                    #output_df = pd.concat([temp_df,output_df],ignore_index=True)\n",
    "                  #  p#d.concat(temp_df,output_df)\n",
    "\n",
    "    #merge plant id forward and reverse first reaction primers into one column to match the output df format\n",
    "    ## Keep only the numbers before the hyphen.\n",
    "    plantID_df.F_primer = plantID_df.F_primer.str.split('-').str[0]\n",
    "    plantID_df.R_primer = plantID_df.R_primer.str.split('-').str[0]\n",
    "    #merge the two columns\n",
    "    plantID_df['first_reaction_primers'] = plantID_df.F_primer + '_' + plantID_df.R_primer\n",
    "   # print(plantID_df)\n",
    "    plantID_df = plantID_df[['plant_ID','first_reaction_primers','platename']]\n",
    "   # print(plantID_df)\n",
    "\n",
    "    #add plant IDs\n",
    "    output_df_new = pd.merge(output_df,plantID_df, how = 'left', on = ['first_reaction_primers','platename'])\n",
    "\n",
    "    #add guide number column that's an integer for sorting on\n",
    "    output_df_new['guide_number'] = output_df_new.guide.str.split('guide').str[1].astype(int)\n",
    "\n",
    "    #write out the output_df\n",
    "    output_df_new.to_csv(f'{output}{gene}_includingduplicates.tsv', sep=\"\\t\", index=False, header=1)\n",
    "    #find duplicate values\n",
    "    #columns to group by\n",
    "    columns = ['chr','plant_ID','platename','library','first_reaction_primers','second_reaction_primers','guide','guide_number','aligned_sequence','reference_sequence','mutation_type','insertion_positions','deletion_positions','substitution_positions','insertion_cut_site_distance','deletion_cut_site_distance','substitution_cut_site_distance','cut_site_promoter_position','insertion_positions_relative_to_TSS','insertion_genomic_positions','deletion_positions_relative_to_TSS','deletion_genomic_positions','substitution_positions_relative_to_TSS','substitution_genomic_positions']\n",
    "\n",
    "    #make columns containing lists string for now so can use groupby\n",
    "    to_string = ['insertion_positions','deletion_positions','substitution_positions','insertion_cut_site_distance','deletion_cut_site_distance','substitution_cut_site_distance','insertion_positions_relative_to_TSS','insertion_genomic_positions','deletion_positions_relative_to_TSS','deletion_genomic_positions','substitution_positions_relative_to_TSS','substitution_genomic_positions']\n",
    "    output_df_new[to_string] = output_df_new[to_string].astype(str)\n",
    "    \n",
    "    col_order = ['chr','plant_ID','platename','library','first_reaction_primers','second_reaction_primers','guide','guide_number','aligned_sequence','reference_sequence','mutation_type','read_number','read_percentage','insertion_positions','deletion_positions','substitution_positions','insertion_cut_site_distance','deletion_cut_site_distance','substitution_cut_site_distance','cut_site_promoter_position','insertion_positions_relative_to_TSS','insertion_genomic_positions','deletion_positions_relative_to_TSS','deletion_genomic_positions','substitution_positions_relative_to_TSS','substitution_genomic_positions']\n",
    "\n",
    "    #merge duplicate values, adding the sum of the read_number and read_percentage\n",
    "    output_df_merged = output_df_new.groupby(columns, sort=False, as_index=False).agg({\"read_number\":\"sum\",\"read_percentage\":\"sum\"})\n",
    "    #put columns back in the original order\n",
    "    output_df_merged = output_df_merged[col_order]\n",
    "\n",
    "    #sort by platename, plant ID then by guide number\n",
    "    output_df_merged.sort_values(['platename','plant_ID','guide_number'], ascending=True, inplace = True)\n",
    "    # Delete the added column\n",
    "    #output_df_merged.drop('guide_number', axis=1, inplace = True)\n",
    "    #print(output_df[output_df.duplicated(cols, keep= \"first\")])\n",
    "    #write out the output_df\n",
    "    output_df_merged.to_csv(f'{output}{gene}_merged.tsv', sep=\"\\t\", index=False, header=1)\n",
    "\n",
    "    #return output_df_merged\n",
    "\n",
    "    \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/Variant_call'\n",
    "ARF9_root = f'{folder}/ARF9_sgRNAs/test'\n",
    "ARF18_root = f'{folder}/ARF18_sgRNAs/7bp_window_noplots'\n",
    "DREB26_root = f'{folder}/DREB26_sgRNAs/7bp_window_noplots'\n",
    "NLP7_root = f'{folder}/NLP7_sgRNAs/7bp_window_noplots'\n",
    "output = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/Variant_call/'\n",
    "#dictionary of reference fasta file locations\n",
    "reference_folder = '../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/References'\n",
    "reference_gene_dict = {'ARF9':f'{reference_folder}/ARF9_promoter.fa','ARF18':f'{reference_folder}/ARF18_promoter.fa','DREB26':f'{reference_folder}/DREB26_promoter.fa','NLP7':f'{reference_folder}/NLP7_promoter.fa'}\n",
    "reference_fasta = f'{reference_folder}/genes_longest_region.fa'\n",
    "reference_promoter_bed = f'{reference_folder}/genes_longest_region.bed'\n",
    "#promoters bed file when 3' end is the TSS (used the bed file from promoter architecture non-overlapping_includingbidirectional_all_genes_newannotation project FIMO folder)\n",
    "all_promoters_bed = f'{reference_folder}/promoters.bed'\n",
    "#mapped motif bed file of TFBSs scanned with FIMO\n",
    "mapped_motifs_bed = '../../data/output/non-overlapping_includingbidirectional_all_genes_newannotation_3KB/FIMO/promoters_5UTR_motifs_mapped_q0_05.bed'\n",
    "plant_IDs = f'{reference_folder}/plant_IDs.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get reference promoter genomic positions along with TSS position\n",
    "#in format [AGI,promoter_genomic_pos_chromosome,promoter_genomic_pos_start,promoter_genomic_pos_stop,TSS_pos]\n",
    "reference_genomic_positions = get_reference_promoter_genomic_positions(reference_promoter_bed,all_promoters_bed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_guide(ARF9_root,output,'ARF9',reference_fasta,mapped_motifs_bed,reference_genomic_positions,plant_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_guide(ARF9_root,output,'ARF18',reference_fasta,mapped_motifs_bed,reference_genomic_positions,plant_IDs)\n",
    "check_guide(ARF9_root,output,'DREB26',reference_fasta,mapped_motifs_bed,reference_genomic_positions,plant_IDs)\n",
    "check_guide(ARF9_root,output,'NLP7',reference_fasta,mapped_motifs_bed,reference_genomic_positions,plant_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #source different conda env containing pybedtools as currently it's incompatible with the current conda env\n",
    "# subprocess.run('source activate PromoterArchitecturePipeline && \"enter command here\" && source deactivate', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b4317e48e5151a18b46d6908ccba584a1473587b38c50b55f51e0e363cb7dde"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
