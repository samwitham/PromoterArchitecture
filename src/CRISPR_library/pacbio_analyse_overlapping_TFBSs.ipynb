{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alleles_frequency_table.zip can be unzipped to a tab-separated text file that shows all reads and alignments to references. The first column shows the aligned sequence of the sequenced read. The second column shows the aligned sequence of the reference sequence. Gaps in each of these columns represent insertions and deletions. The next column 'Reference_Name' shows the name of the reference that the read aligned to. The fourth column, 'Read_Status' shows whether the read was modified or unmodified. The fifth through seventh columns ('n_deleted', 'n_inserted', 'n_substituted') show the number of bases deleted, inserted, and substituted as compared to the reference sequence. The eighth column shows the number of reads having that sequence, and the ninth column shows the percentage of all reads having that sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #features to add:\n",
    "# Distance from TSS - get relative position of mutation in the guide site - done. Add distance from cut site metric. - done Then calculate distance from Araport TSS - done\n",
    "# for this: first create a bed file for all of the mutations (relative to whole Arabidopsis genome). Then do bedtools merge or intersect (or bedtools coverage (../data_sorting/./TFBS_coverage.sh)) with the mapped motif bed file (all TFBSs for all genes). Record each TFBS that overlaps the mutation\n",
    "# Overlapping TFBSs - subnet\n",
    "# work and all TFs\n",
    "\n",
    "# Include secondary mutations in case both deletion and substitution for example - done\n",
    "# Plant ID\n",
    "# How many biallelic or homozygous? How many wildtype?\n",
    "# More than 2 alleles for a gene - record alleles until 80% of reads accounted for\n",
    "# Prioritise homozygous or biallelic\n",
    "# How many plants had mutations? How many guides produced mutations in each gene?\n",
    "#check window around cut site - at the moment I am including mutations 20bp either side, maybe cut the alignments down to 7bp either side before comparing them with find_indels_substitutions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use env pybedtools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "from pybedtools import BedTool\n",
    "from collections import defaultdict\n",
    "#chunks\n",
    "from more_itertools import sliced\n",
    "import multiprocessing as mp\n",
    "\n",
    "import time\n",
    "import os\n",
    "#import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_files(mutations_file,mapped_motifs,guide_pairs):\n",
    "    \"\"\"read in the files\"\"\"\n",
    "    #read in mapped motifs bed file\n",
    "    mapped_motifs = pd.read_table(mapped_motifs_bed, sep=\"\\t\", header=None)\n",
    "    if len(mapped_motifs.columns) == 24:\n",
    "        cols = [\n",
    "            \"chr\",\n",
    "            \"start\",\n",
    "            \"stop\",\n",
    "            \"promoter_AGI\",\n",
    "            \"dot1\",\n",
    "            \"strand\",\n",
    "            \"source\",\n",
    "            \"type\",\n",
    "            \"dot2\",\n",
    "            \"attributes\",\n",
    "            \"motif_chr\",\n",
    "            \"motif_start\",\n",
    "            \"motif_stop\",\n",
    "            \"name_rep\",\n",
    "            \"score\",\n",
    "            \"motif_strand\",\n",
    "            \"promoter_AGI2\",\n",
    "            \"p-value\",\n",
    "            \"q-value\",\n",
    "            \"matched_sequence\",\n",
    "            \"TF_name\",\n",
    "            \"TF_family\",\n",
    "            \"TF_AGI\",\n",
    "            \"bp_overlap\",\n",
    "        ]\n",
    "        mapped_motifs.columns = cols\n",
    "        # filter columns\n",
    "        mapped_motifs = mapped_motifs[\n",
    "            [\n",
    "                \"motif_chr\",\n",
    "                \"motif_start\",\n",
    "                \"motif_stop\",\n",
    "                \"name_rep\",\n",
    "                \"score\",\n",
    "                \"motif_strand\",\n",
    "                \"promoter_AGI2\",\n",
    "                \"p-value\",\n",
    "                \"q-value\",\n",
    "                \"matched_sequence\",\n",
    "                \"TF_name\",\n",
    "                \"TF_family\",\n",
    "                \"TF_AGI\",\n",
    "            ]\n",
    "        ]\n",
    "        #rename columns\n",
    "        cols = [\n",
    "            \"motif_chr\",\n",
    "            \"motif_start\",\n",
    "            \"motif_stop\",\n",
    "            \"name_rep\",\n",
    "            \"score\",\n",
    "            \"motif_strand\",\n",
    "            \"promoter_AGI\",\n",
    "            \"p-value\",\n",
    "            \"q-value\",\n",
    "            \"matched_sequence\",\n",
    "            \"TF_name\",\n",
    "            \"TF_family\",\n",
    "            \"TF_AGI\",\n",
    "        ]\n",
    "        mapped_motifs.columns = cols\n",
    "\n",
    "    elif len(mapped_motifs.columns) == 13:\n",
    "        cols = [\n",
    "            \"motif_chr\",\n",
    "            \"motif_start\",\n",
    "            \"motif_stop\",\n",
    "            \"name_rep\",\n",
    "            \"score\",\n",
    "            \"motif_strand\",\n",
    "            \"promoter_AGI\",\n",
    "            \"p-value\",\n",
    "            \"q-value\",\n",
    "            \"matched_sequence\",\n",
    "            \"TF_name\",\n",
    "            \"TF_family\",\n",
    "            \"TF_AGI\",\n",
    "        ]\n",
    "        mapped_motifs.columns = cols\n",
    "\n",
    "    elif len(mapped_motifs.columns) == 17:\n",
    "        cols = [\n",
    "            \"motif_chr\",\n",
    "            \"motif_start\",\n",
    "            \"motif_stop\",\n",
    "            \"name_rep\",\n",
    "            \"score\",\n",
    "            \"motif_strand\",\n",
    "            \"promoter_AGI\",\n",
    "            \"p-value\",\n",
    "            \"q-value\",\n",
    "            \"matched_sequence\",\n",
    "            \"TF_name\",\n",
    "            \"TF_family\",\n",
    "            \"TF_AGI\",\n",
    "            \"chr_openchrom\",\n",
    "            \"start_openchrom\",\n",
    "            \"stop_openchrom\",\n",
    "            \"bp_overlap\",\n",
    "        ]\n",
    "        mapped_motifs.columns = cols\n",
    "\n",
    "    mutations_df = pd.read_table(mutations_file,sep='\\t',header=0)\n",
    "    guide_pairs_df = pd.read_csv(guide_pairs,header=0)\n",
    "    #only keep first 2 columns\n",
    "    guide_cols = ['guide1','guide2']\n",
    "    guide_pairs_df = guide_pairs_df[guide_cols]\n",
    "    return mutations_df,mapped_motifs,guide_pairs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_bedfiles(bedfile, mapped_motifs_bed, output_buffer):\n",
    "    \"\"\"perform bedtools intersect on the two dfs\"\"\"\n",
    "    df = BedTool(bedfile)\n",
    "    motifs = BedTool(mapped_motifs_bed)\n",
    "    # -wao =Write the original A and B entries plus the number of base pairs of overlap between the two features.\n",
    "    # However, A features w/o overlap are also reported with a NULL B feature and overlap = 0\n",
    "    intersect = df.intersect(motifs, wao=True)\n",
    "    # Write to output_file\n",
    "    # Each line in the file contains bed entry a and bed entry b that it overlaps plus the number of bp in the overlap so 19 columns\n",
    "    output_buffer.write(str(intersect))\n",
    "    #go back to beginning of buffer\n",
    "    output_buffer.seek(0)\n",
    "    mapped_motifs_bed.seek(0)\n",
    "    return output_buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlapping_TFBSs(mutations_df_chunk,mapped_motifs_bed,mapped_motifs_bed_columns):\n",
    "    \"\"\"function to find any overlapping TFBSs from FIMO mapped motif file\"\"\"\n",
    "    #go back to start of buffer\n",
    "    mapped_motifs_bed.seek(0)\n",
    "    #find mutations within\n",
    "    for mutations_df_index,mutations_df_row in mutations_df_chunk.iterrows():\n",
    "            \n",
    "        if mutations_df_row.mutation_type == 'None':\n",
    "            pass\n",
    "        else:\n",
    "            #create temporary df in bed format\n",
    "            \n",
    "            cols = [\"chr\",\n",
    "            \"start\",\n",
    "            \"stop\",\n",
    "            \"mutation_type\",'mutation_count']\n",
    "            temp_df = pd.DataFrame(columns=cols)\n",
    "            chr = mutations_df_row.chr\n",
    "            #if not NaN\n",
    "            if pd.notna(mutations_df_row.insertion_genomic_positions) and mutations_df_row.insertion_genomic_positions != 'nan':\n",
    "                #print(mutations_df_row)\n",
    "                #print(\"Index:\", index)\n",
    "                #print(row.insertion_genomic_positions)\n",
    "                #convert genomic positions from string to list\n",
    "                # Convert string to list if more than one\n",
    "                insertion_genomic_positions = mutations_df_row.insertion_genomic_positions.strip('][').split(', ')\n",
    "                #count which mutation number currently on to be added to the temporary bed file\n",
    "                count = 0\n",
    "                for gen_pos in insertion_genomic_positions:\n",
    "                    count += 1\n",
    "                    #get index\n",
    "                    # if len(insertion_genomic_positions) > 1:\n",
    "                    #     index = insertion_genomic_positions.index(gen_pos)\n",
    "                    # else:\n",
    "                    #     index = 'nan'\n",
    "                    start = int(gen_pos)\n",
    "                    stop = start + 1\n",
    "                    mutation_type = \"insertion\"\n",
    "                    #add to temp_df\n",
    "                    temp_list = [chr,start,stop,mutation_type,count]\n",
    "                    temp_df.loc[len(temp_df)] = temp_list\n",
    "            if pd.notna(mutations_df_row.deletion_genomic_positions) and mutations_df_row.deletion_genomic_positions != 'nan':\n",
    "                # Convert string to list\n",
    "                deletion_genomic_positions = mutations_df_row.deletion_genomic_positions.strip('][').split(', ')\n",
    "                #count which mutation number currently on to be added to the temporary bed file\n",
    "                count = 0\n",
    "                for gen_pos in deletion_genomic_positions:\n",
    "                    count += 1\n",
    "                    #get index\n",
    "                    # if len(deletion_genomic_positions) > 1:\n",
    "                    #     index = deletion_genomic_positions.index(gen_pos)\n",
    "                    # else:\n",
    "                    #     index = 'nan'\n",
    "                    start = int(gen_pos)\n",
    "                    stop = start + 1\n",
    "                    mutation_type = \"deletion\"\n",
    "                    #add to temp_df\n",
    "                    temp_list = [chr,start,stop,mutation_type,count]\n",
    "                    temp_df.loc[len(temp_df)] = temp_list\n",
    "            if pd.notna(mutations_df_row.substitution_genomic_positions) and mutations_df_row.substitution_genomic_positions != 'nan':\n",
    "                # Convert string to list\n",
    "                substitution_genomic_positions = mutations_df_row.substitution_genomic_positions.strip('][').split(', ')\n",
    "                #count which mutation number currently on to be added to the temporary bed file\n",
    "                count = 0\n",
    "                for gen_pos in substitution_genomic_positions:\n",
    "                    count += 1\n",
    "                    #get index\n",
    "                    # if len(substitution_genomic_positions) > 1:\n",
    "                    #     index = substitution_genomic_positions.index(gen_pos)\n",
    "                    # else:\n",
    "                    #     index = 'nan'\n",
    "                    start = int(gen_pos)\n",
    "                    stop = start + 1\n",
    "                    mutation_type = \"substitution\"\n",
    "                    #add to temp_df\n",
    "                    temp_list = [chr,start,stop,mutation_type,count]\n",
    "                    temp_df.loc[len(temp_df)] = temp_list\n",
    "            #now do bedtools intersect to find which TFBSs overlap with which mutations\n",
    "            #sort by chr then start\n",
    "            temp_df = temp_df.sort_values([\"chr\", \"start\"]).reset_index(drop=True)\n",
    "            # write to buffer\n",
    "            temp_df_buffer = io.StringIO()\n",
    "            temp_df.to_csv(temp_df_buffer, sep=\"\\t\", index=False, header=None)\n",
    "            temp_df_buffer.seek(0)\n",
    "            \n",
    "            output_buffer = io.StringIO()\n",
    "        \n",
    "            output_buffer = merge_bedfiles(temp_df_buffer, mapped_motifs_bed, output_buffer)\n",
    "            \n",
    "            #remove temp_df_buffer stream\n",
    "\n",
    "\n",
    "            #read in output buffer as df\n",
    "            output_df = pd.read_table(output_buffer, sep='\\t')\n",
    "            \n",
    "            #get column names and rename columns\n",
    "            output_df_cols = cols+mapped_motifs_bed_columns+['bp_overlap']\n",
    "            output_df.columns = output_df_cols\n",
    "            #for each mutation type get list of overlapping TFBSs. Add these to a dictionary column in the mutations_df_chunk\n",
    "            #create defaultdicts with lists as values so that non-existing keys can be added to in one go\n",
    "            insertion_overlapping_TFBS_family = defaultdict(list)\n",
    "            insertion_overlapping_TFBS_AGI = defaultdict(list)\n",
    "            #insertion_overlapping_TFBS_total = defaultdict(list)\n",
    "            deletion_overlapping_TFBS_family = defaultdict(list)\n",
    "            deletion_overlapping_TFBS_AGI = defaultdict(list)\n",
    "            #deletion_overlapping_TFBS_total = defaultdict(list)\n",
    "            substitution_overlapping_TFBS_family = defaultdict(list)\n",
    "            substitution_overlapping_TFBS_AGI = defaultdict(list)\n",
    "            #substitution_overlapping_TFBS_total = defaultdict(list)\n",
    "            \n",
    "\n",
    "            for index,row in output_df.iterrows():\n",
    "                # empty number that will increase for each insertion\n",
    "               # insertion_overlapping_TFBS_count = int()\n",
    "               #if mutation and has a 1bp overlap\n",
    "               #if no TF_AGI then pass\n",
    "                if row.TF_AGI == '.':\n",
    "                    pass\n",
    "                elif row.mutation_type == 'insertion' and row.bp_overlap > 0:\n",
    "                    #add insertion TFBS family information to dictionary for the correct mutation number\n",
    "                    #print(row)\n",
    "                    insertion_overlapping_TFBS_family[f'insertion{row.mutation_count}'] += [row.TF_family]\n",
    "                    #add insertion TFBS AGI information to dictionary for the correct mutation number\n",
    "                    insertion_overlapping_TFBS_AGI[f'insertion{row.mutation_count}'] += [row.TF_AGI]\n",
    "                    #add total number of TFBSs overlapping each insertion\n",
    "                 #   insertion_overlapping_TFBS_total[f'insertion{row.mutation_count}'] += 1\n",
    "                elif row.mutation_type == 'deletion' and row.bp_overlap > 0:\n",
    "                    #add deletion TFBS family information to dictionary for the correct mutation number\n",
    "                    deletion_overlapping_TFBS_family[f'deletion{row.mutation_count}'] += [row.TF_family]\n",
    "                    #add deletion TFBS AGI information to dictionary for the correct mutation number\n",
    "                    deletion_overlapping_TFBS_AGI[f'deletion{row.mutation_count}'] += [row.TF_AGI]\n",
    "                    #add total number of TFBSs overlapping each insertion\n",
    "                   # deletion_overlapping_TFBS_total[f'deletion{row.mutation_count}'] += 1\n",
    "                elif row.mutation_type == 'substitution' and row.bp_overlap > 0:\n",
    "                    #add substitution TFBS family information to dictionary for the correct mutation number\n",
    "                    substitution_overlapping_TFBS_family[f'substitution{row.mutation_count}'] += [row.TF_family]\n",
    "                    #add substitution TFBS AGI information to dictionary for the correct mutation number\n",
    "                    substitution_overlapping_TFBS_AGI[f'substitution{row.mutation_count}'] += [row.TF_AGI]\n",
    "                    #add total number of TFBSs overlapping each insertion\n",
    "                 #   substitution_overlapping_TFBS_total[f'substitution{row.mutation_count}'] += 1\n",
    "            # #calculate total unique TFBS for each insertion, deletion and subsitution\n",
    "            # insertion_overlapping_TFBS_total_unique = []\n",
    "            # for insertion,AGI in insertion_overlapping_TFBS_AGI.items():\n",
    "            #     insertion_overlapping_TFBS_total_unique += np.unique(AGI).astype(list)\n",
    "            # deletion_overlapping_TFBS_total_unique = []\n",
    "            # for deletion,AGI in deletion_overlapping_TFBS_AGI.items():\n",
    "            #     print(f'AGIunique={np.unique(AGI).astype(list)}')\n",
    "            #     print(f'total={deletion_overlapping_TFBS_total_unique}')\n",
    "            #     print(f'AGI={AGI}')\n",
    "            #     deletion_overlapping_TFBS_total_unique += np.unique(AGI).astype(list)\n",
    "            #     print(f'newtotal={deletion_overlapping_TFBS_total_unique}')\n",
    "            # substitution_overlapping_TFBS_total_unique = []\n",
    "            # for substitution,AGI in substitution_overlapping_TFBS_AGI.items():\n",
    "            #     substitution_overlapping_TFBS_total_unique += np.unique(AGI).astype(list)\n",
    "                \n",
    "            #add values to mutations_df row\n",
    "            #print(f'insertion_overlapping_TFBS_family={dict(insertion_overlapping_TFBS_family)}')\n",
    "            #print(mutations_df_row)\n",
    "            #first make overlapping TFBS families and AGIs unique\n",
    "            insertion_overlapping_TFBS_family = dict(insertion_overlapping_TFBS_family)\n",
    "            insertion_overlapping_TFBS_AGI = dict(insertion_overlapping_TFBS_AGI)\n",
    "            deletion_overlapping_TFBS_family = dict(deletion_overlapping_TFBS_family)\n",
    "            deletion_overlapping_TFBS_AGI = dict(deletion_overlapping_TFBS_AGI)\n",
    "            substitution_overlapping_TFBS_family = dict(substitution_overlapping_TFBS_family)\n",
    "            substitution_overlapping_TFBS_AGI = dict(substitution_overlapping_TFBS_AGI)\n",
    "            #if empty dictionary, change to nan\n",
    "            if insertion_overlapping_TFBS_family == {}:\n",
    "                insertion_overlapping_TFBS_family = np.nan\n",
    "            else:\n",
    "                #keep only unique TFBS families\n",
    "                for k,v in insertion_overlapping_TFBS_family.items():\n",
    "                    #print(np.unique(v).astype(list))\n",
    "                    insertion_overlapping_TFBS_family[k] = np.unique(v).tolist()\n",
    "\n",
    "            if insertion_overlapping_TFBS_AGI == {}:\n",
    "                insertion_overlapping_TFBS_AGI = np.nan\n",
    "            else:\n",
    "                #keep only unique TFBS AGIs\n",
    "                for k,v in insertion_overlapping_TFBS_AGI.items():\n",
    "                    #print(np.unique(v).astype(list))\n",
    "                    insertion_overlapping_TFBS_AGI[k] = np.unique(v).tolist()\n",
    "\n",
    "            if deletion_overlapping_TFBS_family == {}:\n",
    "                deletion_overlapping_TFBS_family = 'nan'\n",
    "            else:\n",
    "                #keep only unique TFBS families\n",
    "                for k,v in deletion_overlapping_TFBS_family.items():\n",
    "                    #print(np.unique(v).astype(list))\n",
    "                    deletion_overlapping_TFBS_family[k] = np.unique(v).tolist()\n",
    "\n",
    "            if deletion_overlapping_TFBS_AGI == {}:\n",
    "                deletion_overlapping_TFBS_AGI = np.nan\n",
    "            else:\n",
    "                #keep only unique TFBS AGIs\n",
    "                for k,v in deletion_overlapping_TFBS_AGI.items():\n",
    "                    #print(np.unique(v).astype(list))\n",
    "                    deletion_overlapping_TFBS_AGI[k] = np.unique(v).tolist()\n",
    "            \n",
    "            if substitution_overlapping_TFBS_family == {}:\n",
    "                substitution_overlapping_TFBS_family = np.nan\n",
    "            else:\n",
    "                #keep only unique TFBS families\n",
    "                for k,v in substitution_overlapping_TFBS_family.items():\n",
    "                    #print(np.unique(v).astype(list))\n",
    "                    substitution_overlapping_TFBS_family[k] = np.unique(v).tolist()\n",
    "                    \n",
    "            if substitution_overlapping_TFBS_AGI == {}:\n",
    "                substitution_overlapping_TFBS_AGI = np.nan\n",
    "            else:\n",
    "                #keep only unique TFBS AGIs\n",
    "                for k,v in substitution_overlapping_TFBS_AGI.items():\n",
    "                    #print(np.unique(v).astype(list))\n",
    "                    substitution_overlapping_TFBS_AGI[k] = np.unique(v).tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            mutations_df_chunk.loc[mutations_df_index, \"insertion_overlapping_TFBS_family\"] = str(insertion_overlapping_TFBS_family)\n",
    "            mutations_df_chunk.loc[mutations_df_index, \"insertion_overlapping_TFBS_AGI\"]= str(insertion_overlapping_TFBS_AGI)\n",
    "            mutations_df_chunk.loc[mutations_df_index, \"deletion_overlapping_TFBS_family\"]= str(deletion_overlapping_TFBS_family)\n",
    "            mutations_df_chunk.loc[mutations_df_index, \"deletion_overlapping_TFBS_AGI\"]= str(deletion_overlapping_TFBS_AGI)\n",
    "            mutations_df_chunk.loc[mutations_df_index, \"substitution_overlapping_TFBS_family\"]= str(substitution_overlapping_TFBS_family)\n",
    "            mutations_df_chunk.loc[mutations_df_index, \"substitution_overlapping_TFBS_AGI\"]= str(substitution_overlapping_TFBS_AGI)\n",
    "            # row.insertion_overlapping_TFBS_total_unique= insertion_overlapping_TFBS_total_unique\n",
    "            # row.deletion_overlapping_TFBS_total_unique= deletion_overlapping_TFBS_total_unique\n",
    "            # row.substitution_overlapping_TFBS_total_unique= substitution_overlapping_TFBS_total_unique\n",
    "\n",
    "            #go back to start of buffer\n",
    "            mapped_motifs_bed.seek(0)\n",
    "\n",
    "    return mutations_df_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_overlapping_TFBSs(mutations_df_chunk,mapped_motifs_bed,mapped_motifs_bed_columns):\n",
    "#     \"\"\"function to find any overlapping TFBSs from FIMO mapped motif file\"\"\"\n",
    "#     #go back to start of buffer\n",
    "#     mapped_motifs_bed.seek(0)\n",
    "#     #find mutations within\n",
    "#     for mutations_df_index,mutations_df_row in mutations_df_chunk.iterrows():\n",
    "            \n",
    "#         if mutations_df_row.mutation_type == 'None':\n",
    "#             pass\n",
    "#         else:\n",
    "#             #create temporary df in bed format\n",
    "            \n",
    "#             cols = [\"chr\",\n",
    "#             \"start\",\n",
    "#             \"stop\",\n",
    "#             \"mutation_type\",'mutation_count']\n",
    "#             temp_df = pd.DataFrame(columns=cols)\n",
    "#             chr = mutations_df_row.chr\n",
    "#             #if not NaN\n",
    "#             if pd.notna(mutations_df_row.insertion_genomic_positions) and mutations_df_row.insertion_genomic_positions != 'nan':\n",
    "#                 print(mutations_df_row)\n",
    "#                 #print(\"Index:\", index)\n",
    "#                 #print(row.insertion_genomic_positions)\n",
    "#                 #convert genomic positions from string to list\n",
    "#                 # Convert string to list if more than one\n",
    "#                 insertion_genomic_positions = mutations_df_row.insertion_genomic_positions.strip('][').split(', ')\n",
    "#                 #count which mutation number currently on to be added to the temporary bed file\n",
    "#                 count = 0\n",
    "#                 for gen_pos in insertion_genomic_positions:\n",
    "#                     count += 1\n",
    "#                     #get index\n",
    "#                     # if len(insertion_genomic_positions) > 1:\n",
    "#                     #     index = insertion_genomic_positions.index(gen_pos)\n",
    "#                     # else:\n",
    "#                     #     index = 'nan'\n",
    "#                     start = int(gen_pos)\n",
    "#                     stop = start + 1\n",
    "#                     mutation_type = \"insertion\"\n",
    "#                     #add to temp_df\n",
    "#                     temp_list = [chr,start,stop,mutation_type,count]\n",
    "#                     temp_df.loc[len(temp_df)] = temp_list\n",
    "#             if pd.notna(mutations_df_row.deletion_genomic_positions) and mutations_df_row.deletion_genomic_positions != 'nan':\n",
    "#                 # Convert string to list\n",
    "#                 deletion_genomic_positions = mutations_df_row.deletion_genomic_positions.strip('][').split(', ')\n",
    "#                 #count which mutation number currently on to be added to the temporary bed file\n",
    "#                 count = 0\n",
    "#                 for gen_pos in deletion_genomic_positions:\n",
    "#                     count += 1\n",
    "#                     #get index\n",
    "#                     # if len(deletion_genomic_positions) > 1:\n",
    "#                     #     index = deletion_genomic_positions.index(gen_pos)\n",
    "#                     # else:\n",
    "#                     #     index = 'nan'\n",
    "#                     start = int(gen_pos)\n",
    "#                     stop = start + 1\n",
    "#                     mutation_type = \"deletion\"\n",
    "#                     #add to temp_df\n",
    "#                     temp_list = [chr,start,stop,mutation_type,count]\n",
    "#                     temp_df.loc[len(temp_df)] = temp_list\n",
    "#             if pd.notna(mutations_df_row.substitution_genomic_positions) and mutations_df_row.substitution_genomic_positions != 'nan':\n",
    "#                 # Convert string to list\n",
    "#                 substitution_genomic_positions = mutations_df_row.substitution_genomic_positions.strip('][').split(', ')\n",
    "#                 #count which mutation number currently on to be added to the temporary bed file\n",
    "#                 count = 0\n",
    "#                 for gen_pos in substitution_genomic_positions:\n",
    "#                     count += 1\n",
    "#                     #get index\n",
    "#                     # if len(substitution_genomic_positions) > 1:\n",
    "#                     #     index = substitution_genomic_positions.index(gen_pos)\n",
    "#                     # else:\n",
    "#                     #     index = 'nan'\n",
    "#                     start = int(gen_pos)\n",
    "#                     stop = start + 1\n",
    "#                     mutation_type = \"substitution\"\n",
    "#                     #add to temp_df\n",
    "#                     temp_list = [chr,start,stop,mutation_type,count]\n",
    "#                     temp_df.loc[len(temp_df)] = temp_list\n",
    "#             #now do bedtools intersect to find which TFBSs overlap with which mutations\n",
    "#             #sort by chr then start\n",
    "#             temp_df = temp_df.sort_values([\"chr\", \"start\"]).reset_index(drop=True)\n",
    "#             # write to buffer\n",
    "#             temp_df_buffer = io.StringIO()\n",
    "#             temp_df.to_csv(temp_df_buffer, sep=\"\\t\", index=False, header=None)\n",
    "#             temp_df_buffer.seek(0)\n",
    "            \n",
    "#             output_buffer = io.StringIO()\n",
    "        \n",
    "#             output_buffer = merge_bedfiles(temp_df_buffer, mapped_motifs_bed, output_buffer)\n",
    "            \n",
    "#             #remove temp_df_buffer stream\n",
    "\n",
    "\n",
    "#             #read in output buffer as df\n",
    "#             output_df = pd.read_table(output_buffer, sep='\\t')\n",
    "            \n",
    "#             #get column names and rename columns\n",
    "#             output_df_cols = cols+mapped_motifs_bed_columns+['bp_overlap']\n",
    "#             output_df.columns = output_df_cols\n",
    "#             #for each mutation type get list of overlapping TFBSs. Add these to a dictionary column in the mutations_df_chunk\n",
    "#             #create defaultdicts with lists as values so that non-existing keys can be added to in one go\n",
    "#             insertion_overlapping_TFBS_family = defaultdict(list)\n",
    "#             insertion_overlapping_TFBS_AGI = defaultdict(list)\n",
    "#             #insertion_overlapping_TFBS_total = defaultdict(list)\n",
    "#             deletion_overlapping_TFBS_family = defaultdict(list)\n",
    "#             deletion_overlapping_TFBS_AGI = defaultdict(list)\n",
    "#             #deletion_overlapping_TFBS_total = defaultdict(list)\n",
    "#             substitution_overlapping_TFBS_family = defaultdict(list)\n",
    "#             substitution_overlapping_TFBS_AGI = defaultdict(list)\n",
    "#             #substitution_overlapping_TFBS_total = defaultdict(list)\n",
    "            \n",
    "\n",
    "#             for index,row in output_df.iterrows():\n",
    "#                 # empty number that will increase for each insertion\n",
    "#                # insertion_overlapping_TFBS_count = int()\n",
    "#                #if mutation and has a 1bp overlap\n",
    "#                #if no TF_AGI then pass\n",
    "#                 if row.TF_AGI == '.':\n",
    "#                     pass\n",
    "#                 elif row.mutation_type == 'insertion' and row.bp_overlap > 0:\n",
    "#                     #add insertion TFBS family information to dictionary for the correct mutation number\n",
    "#                     #print(row)\n",
    "#                     insertion_overlapping_TFBS_family[f'insertion{row.mutation_count}'] += [row.TF_family]\n",
    "#                     #add insertion TFBS AGI information to dictionary for the correct mutation number\n",
    "#                     insertion_overlapping_TFBS_AGI[f'insertion{row.mutation_count}'] += [row.TF_AGI]\n",
    "#                     #add total number of TFBSs overlapping each insertion\n",
    "#                  #   insertion_overlapping_TFBS_total[f'insertion{row.mutation_count}'] += 1\n",
    "#                 elif row.mutation_type == 'deletion' and row.bp_overlap > 0:\n",
    "#                     #add deletion TFBS family information to dictionary for the correct mutation number\n",
    "#                     deletion_overlapping_TFBS_family[f'deletion{row.mutation_count}'] += [row.TF_family]\n",
    "#                     #add deletion TFBS AGI information to dictionary for the correct mutation number\n",
    "#                     deletion_overlapping_TFBS_AGI[f'deletion{row.mutation_count}'] += [row.TF_AGI]\n",
    "#                     #add total number of TFBSs overlapping each insertion\n",
    "#                    # deletion_overlapping_TFBS_total[f'deletion{row.mutation_count}'] += 1\n",
    "#                 elif row.mutation_type == 'substitution' and row.bp_overlap > 0:\n",
    "#                     #add substitution TFBS family information to dictionary for the correct mutation number\n",
    "#                     substitution_overlapping_TFBS_family[f'substitution{row.mutation_count}'] += [row.TF_family]\n",
    "#                     #add substitution TFBS AGI information to dictionary for the correct mutation number\n",
    "#                     substitution_overlapping_TFBS_AGI[f'substitution{row.mutation_count}'] += [row.TF_AGI]\n",
    "#                     #add total number of TFBSs overlapping each insertion\n",
    "#                  #   substitution_overlapping_TFBS_total[f'substitution{row.mutation_count}'] += 1\n",
    "#             # #calculate total unique TFBS for each insertion, deletion and subsitution\n",
    "#             # insertion_overlapping_TFBS_total_unique = []\n",
    "#             # for insertion,AGI in insertion_overlapping_TFBS_AGI.items():\n",
    "#             #     insertion_overlapping_TFBS_total_unique += np.unique(AGI).astype(list)\n",
    "#             # deletion_overlapping_TFBS_total_unique = []\n",
    "#             # for deletion,AGI in deletion_overlapping_TFBS_AGI.items():\n",
    "#             #     print(f'AGIunique={np.unique(AGI).astype(list)}')\n",
    "#             #     print(f'total={deletion_overlapping_TFBS_total_unique}')\n",
    "#             #     print(f'AGI={AGI}')\n",
    "#             #     deletion_overlapping_TFBS_total_unique += np.unique(AGI).astype(list)\n",
    "#             #     print(f'newtotal={deletion_overlapping_TFBS_total_unique}')\n",
    "#             # substitution_overlapping_TFBS_total_unique = []\n",
    "#             # for substitution,AGI in substitution_overlapping_TFBS_AGI.items():\n",
    "#             #     substitution_overlapping_TFBS_total_unique += np.unique(AGI).astype(list)\n",
    "                \n",
    "#             #add values to mutations_df row\n",
    "#             #print(f'insertion_overlapping_TFBS_family={dict(insertion_overlapping_TFBS_family)}')\n",
    "#             #print(mutations_df_row)\n",
    "#             #first make overlapping TFBS families and AGIs unique\n",
    "#             insertion_overlapping_TFBS_family = dict(insertion_overlapping_TFBS_family)\n",
    "#             insertion_overlapping_TFBS_AGI = dict(insertion_overlapping_TFBS_AGI)\n",
    "#             deletion_overlapping_TFBS_family = dict(deletion_overlapping_TFBS_family)\n",
    "#             deletion_overlapping_TFBS_AGI = dict(deletion_overlapping_TFBS_AGI)\n",
    "#             substitution_overlapping_TFBS_family = dict(substitution_overlapping_TFBS_family)\n",
    "#             substitution_overlapping_TFBS_AGI = dict(substitution_overlapping_TFBS_AGI)\n",
    "#             #if empty dictionary, change to nan\n",
    "#             if insertion_overlapping_TFBS_family == {}:\n",
    "#                 insertion_overlapping_TFBS_family = np.nan\n",
    "#             else:\n",
    "#                 #keep only unique TFBS families\n",
    "#                 for k,v in insertion_overlapping_TFBS_family.items():\n",
    "#                     #print(np.unique(v).astype(list))\n",
    "#                     insertion_overlapping_TFBS_family[k] = np.unique(v).tolist()\n",
    "\n",
    "#             if insertion_overlapping_TFBS_AGI == {}:\n",
    "#                 insertion_overlapping_TFBS_AGI = np.nan\n",
    "#             else:\n",
    "#                 #keep only unique TFBS AGIs\n",
    "#                 for k,v in insertion_overlapping_TFBS_AGI.items():\n",
    "#                     #print(np.unique(v).astype(list))\n",
    "#                     insertion_overlapping_TFBS_AGI[k] = np.unique(v).tolist()\n",
    "\n",
    "#             if deletion_overlapping_TFBS_family == {}:\n",
    "#                 deletion_overlapping_TFBS_family = 'nan'\n",
    "#             else:\n",
    "#                 #keep only unique TFBS families\n",
    "#                 for k,v in deletion_overlapping_TFBS_family.items():\n",
    "#                     #print(np.unique(v).astype(list))\n",
    "#                     deletion_overlapping_TFBS_family[k] = np.unique(v).tolist()\n",
    "\n",
    "#             if deletion_overlapping_TFBS_AGI == {}:\n",
    "#                 deletion_overlapping_TFBS_AGI = np.nan\n",
    "#             else:\n",
    "#                 #keep only unique TFBS AGIs\n",
    "#                 for k,v in deletion_overlapping_TFBS_AGI.items():\n",
    "#                     #print(np.unique(v).astype(list))\n",
    "#                     deletion_overlapping_TFBS_AGI[k] = np.unique(v).tolist()\n",
    "            \n",
    "#             if substitution_overlapping_TFBS_family == {}:\n",
    "#                 substitution_overlapping_TFBS_family = np.nan\n",
    "#             else:\n",
    "#                 #keep only unique TFBS families\n",
    "#                 for k,v in substitution_overlapping_TFBS_family.items():\n",
    "#                     #print(np.unique(v).astype(list))\n",
    "#                     substitution_overlapping_TFBS_family[k] = np.unique(v).tolist()\n",
    "                    \n",
    "#             if substitution_overlapping_TFBS_AGI == {}:\n",
    "#                 substitution_overlapping_TFBS_AGI = np.nan\n",
    "#             else:\n",
    "#                 #keep only unique TFBS AGIs\n",
    "#                 for k,v in substitution_overlapping_TFBS_AGI.items():\n",
    "#                     #print(np.unique(v).astype(list))\n",
    "#                     substitution_overlapping_TFBS_AGI[k] = np.unique(v).tolist()\n",
    "\n",
    "\n",
    "#             # def write_values(mutations_df_chunk, mutations_df_index, col_name, value):\n",
    "#             #     \"\"\"function to map_partitions with dask to allow loc\"\"\"\n",
    "#             #     #make copy of mutations_df_chunk\n",
    "#             #     #mutations_df_chunk = mutations_df_chunk.copy()\n",
    "#             #     #df.at can only access a single value at a time.\n",
    "#             #     #df.loc can select multiple rows and/or columns.\n",
    "#             #     #mutations_df_chunk.loc[mutations_df_index, col_name] = str(value)\n",
    "#             #     #find correct row from index\n",
    "#             #     mutations_df_chunk[col_name] = mutations_df_chunk[col_name].mask(mutations_df_chunk[mutations_df_chunk.index==mutations_df_index],str(value))\n",
    "#             #     return mutations_df_chunk\n",
    "#             #write values\n",
    "#             # mutations_df_chunk = write_values(mutations_df_chunk, mutations_df_index, 'insertion_overlapping_TFBS_family', insertion_overlapping_TFBS_family)\n",
    "#             # mutations_df_chunk = write_values(mutations_df_chunk, mutations_df_index, 'insertion_overlapping_TFBS_AGI', insertion_overlapping_TFBS_AGI)\n",
    "#             # mutations_df_chunk = write_values(mutations_df_chunk, mutations_df_index, 'deletion_overlapping_TFBS_family', deletion_overlapping_TFBS_family)\n",
    "#             # mutations_df_chunk = write_values(mutations_df_chunk, mutations_df_index, 'deletion_overlapping_TFBS_AGI', deletion_overlapping_TFBS_AGI)\n",
    "#             # mutations_df_chunk = write_values(mutations_df_chunk, mutations_df_index, 'substitution_overlapping_TFBS_family', substitution_overlapping_TFBS_family)\n",
    "#             # mutations_df_chunk = write_values(mutations_df_chunk, mutations_df_index, 'substitution_overlapping_TFBS_AGI', substitution_overlapping_TFBS_AGI)\n",
    "#             mutations_df_chunk[\"insertion_overlapping_TFBS_family\"] = mutations_df_chunk[\"insertion_overlapping_TFBS_family\"].mask(mutations_df_chunk[mutations_df_chunk['index_col']==mutations_df_index],str(insertion_overlapping_TFBS_family))\n",
    "#             #make copy of mutations_df_chunk\n",
    "#             #mutations_df_chunk.loc[mutations_df_index, \"insertion_overlapping_TFBS_family\"] = str(insertion_overlapping_TFBS_family)\n",
    "#            # print(mutations_df_chunk.query('column in @mutations_df_index'))\n",
    "#            # mutations_df_chunk[\"insertion_overlapping_TFBS_family\"] = mutations_df_chunk[\"insertion_overlapping_TFBS_family\"].mask(mutations_df_chunk.query('@mutations_df_index'),str(insertion_overlapping_TFBS_family))\n",
    "#             #mutations_df_chunk.loc[mutations_df_index, \"insertion_overlapping_TFBS_AGI\"]= str(insertion_overlapping_TFBS_AGI)\n",
    "#             #mutations_df_chunk[\"insertion_overlapping_TFBS_AGI\"] = mutations_df_chunk[\"insertion_overlapping_TFBS_AGI\"].mask(mutations_df_chunk.query('@mutations_df_index'),str(insertion_overlapping_TFBS_AGI))\n",
    "#             #mutations_df_chunk.loc[mutations_df_index, \"deletion_overlapping_TFBS_family\"]= str(deletion_overlapping_TFBS_family)\n",
    "#             #mutations_df_chunk[\"deletion_overlapping_TFBS_family\"] = mutations_df_chunk[\"deletion_overlapping_TFBS_family\"].mask(mutations_df_chunk.query('@mutations_df_index'),str(deletion_overlapping_TFBS_family))\n",
    "#             #mutations_df_chunk.loc[mutations_df_index, \"deletion_overlapping_TFBS_AGI\"]= str(deletion_overlapping_TFBS_AGI)\n",
    "#             #mutations_df_chunk[\"deletion_overlapping_TFBS_AGI\"] = mutations_df_chunk[\"deletion_overlapping_TFBS_AGI\"].mask(mutations_df_chunk.query('@mutations_df_index'),str(deletion_overlapping_TFBS_AGI))\n",
    "#           #  mutations_df_chunk.loc[mutations_df_index, \"substitution_overlapping_TFBS_family\"]= str(substitution_overlapping_TFBS_family)\n",
    "#             #mutations_df_chunk[\"substitution_overlapping_TFBS_family\"] = mutations_df_chunk[\"substitution_overlapping_TFBS_family\"].mask(mutations_df_chunk.query('@mutations_df_index'),str(substitution_overlapping_TFBS_family))\n",
    "#            # mutations_df_chunk.loc[mutations_df_index, \"substitution_overlapping_TFBS_AGI\"]= str(substitution_overlapping_TFBS_AGI)\n",
    "#             #mutations_df_chunk[\"substitution_overlapping_TFBS_AGI\"] = mutations_df_chunk[\"substitution_overlapping_TFBS_AGI\"].mask(mutations_df_chunk.query('@mutations_df_index'),str(substitution_overlapping_TFBS_AGI))\n",
    "#             # row.insertion_overlapping_TFBS_total_unique= insertion_overlapping_TFBS_total_unique\n",
    "#             # row.deletion_overlapping_TFBS_total_unique= deletion_overlapping_TFBS_total_unique\n",
    "#             # row.substitution_overlapping_TFBS_total_unique= substitution_overlapping_TFBS_total_unique\n",
    "\n",
    "#             #go back to start of buffer\n",
    "#             mapped_motifs_bed.seek(0)\n",
    "\n",
    "#     return mutations_df_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkify(mutations_df,mapped_motifs_df,output_folder,gene):\n",
    "    \"\"\"function to prepare dfs and slice mutations_df into chunks to reduce memory before running find_overlapping_TFBSs() \"\"\"\n",
    "   \n",
    "\n",
    "    #for each guide containing mutations, create a temporary bed file containing each mutation and then do bedtools intersect to find which overlap TFBs\n",
    "    #then add the TFBS names into a new column for that row\n",
    "\n",
    "    #get column names from mapped_motifs_df\n",
    "    mapped_motifs_bed_columns = list(mapped_motifs_df.columns)\n",
    "\n",
    "\n",
    "    #turn mapped_motifs_df into a buffer\n",
    "    mapped_motifs_bed = io.StringIO()\n",
    "    mapped_motifs_df.to_csv(mapped_motifs_bed, sep=\"\\t\", index=False, header=None)\n",
    "    #go back to start of buffer\n",
    "    mapped_motifs_bed.seek(0)\n",
    "\n",
    "    #add columns to mutations_df\n",
    "    new_columns = ['insertion_overlapping_TFBS_family',\n",
    "    'insertion_overlapping_TFBS_AGI',\n",
    "    'deletion_overlapping_TFBS_family',\n",
    "    'deletion_overlapping_TFBS_AGI',\n",
    "    'substitution_overlapping_TFBS_family',\n",
    "    'substitution_overlapping_TFBS_AGI',\n",
    "                  ]\n",
    "    #first make a new df that will merge into mutations_df\n",
    "    temp_new_df = pd.DataFrame(columns=new_columns)\n",
    "    mutations_df = pd.concat([mutations_df,temp_new_df], axis=1)\n",
    "    #print(mutations_df)\n",
    "\n",
    "    #first make certain columns string\n",
    "    #make columns containing lists string for now so can use groupby\n",
    "    to_string = ['insertion_positions','deletion_positions','substitution_positions','insertion_cut_site_distance','deletion_cut_site_distance','substitution_cut_site_distance','insertion_positions_relative_to_TSS','insertion_genomic_positions','deletion_positions_relative_to_TSS','deletion_genomic_positions','substitution_positions_relative_to_TSS','substitution_genomic_positions']\n",
    "    mutations_df[to_string] = mutations_df[to_string].astype(str)\n",
    "\n",
    "\n",
    "    # chunksize = 5\n",
    "    # def df_chunking(df,mapped_motifs_bed,mapped_motifs_bed_columns, chunksize):\n",
    "    #     \"\"\"Splits df into chunks, drops data of original df inplace\"\"\"\n",
    "    #     count = 0 # Counter for chunks\n",
    "    #     #create list of chunks\n",
    "    #     chunks = []\n",
    "    #     while len(df):\n",
    "    #         count += 1\n",
    "    #         print('Preparing chunk {}'.format(count))\n",
    "    #         # Return df chunk\n",
    "    #         chunk = df.iloc[:chunksize].copy()\n",
    "    #         #go back to start of buffer\n",
    "    #         mapped_motifs_bed.seek(0)\n",
    "    #         new_chunk = find_overlapping_TFBSs(chunk,mapped_motifs_bed,mapped_motifs_bed_columns)\n",
    "    #         #append chunk to list\n",
    "    #         chunks.append(new_chunk)\n",
    "    #         # Delete data in place because it is no longer needed\n",
    "    #         df.drop(df.index[:chunksize], inplace=True)\n",
    "    #     return chunks\n",
    "\n",
    "    # chunks = df_chunking(mutations_df,mapped_motifs_bed,mapped_motifs_bed_columns, chunksize)\n",
    "  \n",
    "#     # Job parameters\n",
    "#     n_jobs = 4  # Poolsize\n",
    "#     chunksize = 5  # Maximum size of Frame Chunk\n",
    "#     # Preparation\n",
    "#    # df = pd.DataFrame(np.random.rand(*size))\n",
    "#     ctx = mp.get_context('spawn')\n",
    "#     pool = ctx.Pool(n_jobs)\n",
    "#     #pool = mp.Pool(n_jobs)\n",
    "#     print('Starting MP')\n",
    "#     # Execute the wait and print function in parallel\n",
    "#     #create list of chunks\n",
    "#     # chunks = []\n",
    "#     #mutations_df = pd.concat(pool.imap(find_overlapping_TFBSs(df,mapped_motifs_bed,mapped_motifs_bed_columns), df_chunking(df, chunksize)))\n",
    "#     # mutations_df = pd.concat(pool.starmap(lambda mutations_df: find_overlapping_TFBSs(mutations_df,mapped_motifs_bed,mapped_motifs_bed_columns), df_chunking(mutations_df, chunksize)))\n",
    "#     #mutations_df = pd.concat(pool.starmap(find_overlapping_TFBSs,[(mutations_df,mapped_motifs_bed,mapped_motifs_bed_columns)], df_chunking(mutations_df, chunksize)))\n",
    "#     mutations_df = pd.concat(pool.starmap(df_chunking,[(mutations_df, chunksize)]))\n",
    "#     # p.starmap(print_name, [('Thomas', 'Scott'), ('Ali', 'Khan')])\n",
    "#     #concatenate the chunks\n",
    "#    # mutations_df = pd.concat(p.map(Simulation, range(10))\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "#     print('DONE')\n",
    "\n",
    "    #convert mutations_df into chunks to reduce memory load\n",
    "    CHUNK_SIZE = 5\n",
    "\n",
    "    index_slices = sliced(range(len(mutations_df)), CHUNK_SIZE)\n",
    "    #create list of chunks\n",
    "    chunks = []\n",
    "    for index_slice in index_slices:\n",
    "        #go back to start of buffer\n",
    "        mapped_motifs_bed.seek(0)\n",
    "        chunk = mutations_df.iloc[index_slice] # your dataframe chunk ready for use\n",
    "        new_chunk = find_overlapping_TFBSs(chunk,mapped_motifs_bed,mapped_motifs_bed_columns)\n",
    "\n",
    "        \n",
    "        chunks.append(new_chunk)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    #concatenate chunks into mutations_df\n",
    "    mutations_df = pd.concat(chunks)            \n",
    "    #write out mutations_df\n",
    "    mutations_df.to_csv(f'{output_folder}{gene}_TFBSoverlapping.tsv', sep=\"\\t\", index=False, header=1)\n",
    "                     \n",
    "    return mutations_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chunkify(mutations_df,mapped_motifs_df,output_folder,gene,threads):\n",
    "#     \"\"\"function to prepare dfs and slice mutations_df into chunks to reduce memory before running find_overlapping_TFBSs() \"\"\"\n",
    "   \n",
    "\n",
    "#     #for each guide containing mutations, create a temporary bed file containing each mutation and then do bedtools intersect to find which overlap TFBs\n",
    "#     #then add the TFBS names into a new column for that row\n",
    "\n",
    "#     #get column names from mapped_motifs_df\n",
    "#     mapped_motifs_bed_columns = list(mapped_motifs_df.columns)\n",
    "\n",
    "\n",
    "#     #turn mapped_motifs_df into a buffer\n",
    "#     mapped_motifs_bed = io.StringIO()\n",
    "#     mapped_motifs_df.to_csv(mapped_motifs_bed, sep=\"\\t\", index=False, header=None)\n",
    "#     #go back to start of buffer\n",
    "#     mapped_motifs_bed.seek(0)\n",
    "\n",
    "#     #add columns to mutations_df\n",
    "#     new_columns = ['insertion_overlapping_TFBS_family',\n",
    "#     'insertion_overlapping_TFBS_AGI',\n",
    "#     'deletion_overlapping_TFBS_family',\n",
    "#     'deletion_overlapping_TFBS_AGI',\n",
    "#     'substitution_overlapping_TFBS_family',\n",
    "#     'substitution_overlapping_TFBS_AGI',\n",
    "#                   ]\n",
    "#     #first make a new df that will merge into mutations_df\n",
    "#     temp_new_df = pd.DataFrame(columns=new_columns)\n",
    "#     mutations_df = pd.concat([mutations_df,temp_new_df], axis=1)\n",
    "#     #print(mutations_df)\n",
    "\n",
    "#     #first make certain columns string\n",
    "#     #make columns containing lists string for now so can use groupby\n",
    "#     to_string = ['insertion_positions','deletion_positions','substitution_positions','insertion_cut_site_distance','deletion_cut_site_distance','substitution_cut_site_distance','insertion_positions_relative_to_TSS','insertion_genomic_positions','deletion_positions_relative_to_TSS','deletion_genomic_positions','substitution_positions_relative_to_TSS','substitution_genomic_positions']\n",
    "#     mutations_df[to_string] = mutations_df[to_string].astype(str)\n",
    "#     #add index column for dask\n",
    "#     mutations_df['index_col']=mutations_df.index\n",
    "#     #save mutations_df as a temporary tsv\n",
    "#     mutations_df.to_csv(f'{output_folder}{gene}_temp.tsv', sep=\"\\t\", index=False, header=1)\n",
    "\n",
    "\n",
    "#     # Load the data with Dask instead of Pandas to allow chunking and multithreading.\n",
    "#     dask_df = dd.read_table(\n",
    "#         f'{output_folder}{gene}_temp.tsv', sep=\"\\t\",header=0,\n",
    "#         blocksize=5 * 1024 * 1024, # 5MB chunks\n",
    "        \n",
    "#     )\n",
    "\n",
    "#     # Setup the calculation graph; unlike Pandas code,\n",
    "#     # no work is done at this point:\n",
    "\n",
    "#     mutations_df = find_overlapping_TFBSs(dask_df,mapped_motifs_bed,mapped_motifs_bed_columns)\n",
    "\n",
    "#     # Actually run the computation, using n threads:\n",
    "#     #mutations_df = dd.map_partitions(lambda dask_df: find_overlapping_TFBSs(dask_df,mapped_motifs_bed,mapped_motifs_bed_columns)).compute(num_workers=threads)\n",
    "#     mutations_df = mutations_df.compute(num_workers=threads)\n",
    "#     # Sort using normal Pandas DataFrame, since Dask's Pandas emulation doesn't implement this method:\n",
    "#     mutations_df.sort_values(['platename','plant_ID','guide_number'], ascending=True, inplace = True)\n",
    "           \n",
    "#     #write out mutations_df\n",
    "#     mutations_df.to_csv(f'{output_folder}{gene}_TFBSoverlapping.tsv', sep=\"\\t\", index=False, header=1)\n",
    "                     \n",
    "#     return mutations_df      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#written in dask format rather than pandas\n",
    "def genotype_plant_lines(mutations_df,output_folder,gene):\n",
    "    \"\"\"function to decide whether each plant line is -homozygous \n",
    "    -biallelic - each mutated at same location/site twice\n",
    "    -chimeric - different mutations in different cells or tissues - dont analyse if chimeric - 1 small region, if more than 2 mutations then probably chimeric - ie.    probably still has tDNA\n",
    "    Multiple guide sites - eg. multiple agro strains in each plant. Check for paired guides and whether guides that arent meant to be paired are paired.\n",
    "    \"\"\"\n",
    "    #homozygouslines are those with no duplicated guides in each plant line\n",
    "    mutations_df.loc[~mutations_df.duplicated(['plant_ID','guide']),'genotype'] = 'homozygous'\n",
    "    #mutations_df['genotype'] = mutations_df['genotype'].mask(~mutations_df.duplicated(['plant_ID','guide']), 'homozygous')\n",
    "    #biallelic\n",
    "    #N = 2\n",
    "    #mutations_df_copy = mutations_df[mutations_df.duplicated(['plant_ID','guide']) | mutations_df['count'].ge(N)]\n",
    "    #if 70% of reads or more are the same then mark as homozygous\n",
    "    mutations_df.loc[mutations_df.read_percentage >= 70, 'genotype'] = 'homozygous'\n",
    "    #if 10% of reads or less are that mutation, mark genotype as 'nan\n",
    "    mutations_df.loc[mutations_df.read_percentage <=10, 'genotype'] = 'nan'\n",
    "    #if between 10 and 70% of reads, mark genotype as heterozygous\n",
    "    mutations_df.loc[(mutations_df.read_percentage > 10) & (mutations_df.read_percentage < 70), 'genotype'] = 'heterozygous'\n",
    "\n",
    "    #create a count column\n",
    "    mutations_df['number_of_different_alleles'] = int()\n",
    "    #create non wild type count column\n",
    "    mutations_df['number_of_different_non_wt_alleles'] = int()\n",
    "    \n",
    "    #create a sum_of_count column\n",
    "    #mutations_df['sum_of_count'] = int()\n",
    "    #count how many duplicates there are for heterozygous lines.\n",
    "    mutations_df.loc[mutations_df.genotype == 'heterozygous','number_of_different_alleles'] = mutations_df[mutations_df.genotype == 'heterozygous'].groupby(['plant_ID','guide'])['number_of_different_alleles'].transform('count')\n",
    "    #make non wild type count\n",
    "    mutations_df.loc[(mutations_df.genotype == 'heterozygous')&~(mutations_df.mutation_type == 'None'),'number_of_different_non_wt_alleles'] = mutations_df[(mutations_df.genotype == 'heterozygous')&~(mutations_df.mutation_type == 'None')].groupby(['plant_ID','guide'])['number_of_different_non_wt_alleles'].transform('count')\n",
    "    #make count numeric\n",
    "    #mutations_df['count'] = mutations_df['count'].astype(int)\n",
    "    #print(mutations_df.dtypes)\n",
    "    #if heterozygous count is 1 then homozygous\n",
    "    mutations_df.loc[(mutations_df.genotype == 'heterozygous') & (mutations_df.number_of_different_alleles == 1),'genotype'] = 'homozygous'\n",
    "    #print(mutations_df.loc[(mutations_df.genotype == 'heterozygous') & (mutations_df.count == 1)])\n",
    "    #\n",
    "    #if homozygous then count is 1\n",
    "    mutations_df.loc[mutations_df.genotype == 'homozygous','number_of_different_alleles'] = 1\n",
    "\n",
    "    #if mutation_type is None, count is 0\n",
    "    #create mask for wildtype\n",
    "    # wt_mask = (mutations_df['mutation_type']=='None')\n",
    "    # mutations_df.loc[wt_mask, 'count'] = 0\n",
    "\n",
    "    #get the sum of the counts for each set of duplicates( wild type is 0, each mutation is counted as 1)\n",
    "    # sort=False, as_index=False\n",
    "\n",
    "   # mutations_df['sum_of_count'] = mutations_df.groupby(['plant_ID','guide'])['sum_of_count'].agg({\"count\":\"sum\"})\n",
    "    #print(mutations_df.groupby(['plant_ID','guide'],sort=False, as_index=False)['count'].agg({\"sum_of_count\":\"sum\"}))\n",
    "   # print(mutations_df.groupby(['plant_ID','guide'])['count'].transform('count'))\n",
    "\n",
    "\n",
    "\n",
    "    #if number_of_different_alleles is two and no wild type is present in either of the groups of reads then biallelic\n",
    "    mutations_df.loc[(mutations_df['number_of_different_non_wt_alleles']==2)&~(mutations_df.mutation_type == 'None'),'genotype'] = 'biallelic'\n",
    "    \n",
    "    #if number_of_different_alleles more than two then chimeric\n",
    "    mutations_df.loc[mutations_df['number_of_different_alleles']>2,'genotype'] = 'chimeric'\n",
    "\n",
    "    # reset count column\n",
    "    #filtered['count'] = filtered.groupby(['plant_ID','guide'])[['plant_ID','guide']].transform('count')\n",
    "\n",
    "    #df1.loc[df['count'] < N, 'count'] = 1\n",
    "    #mutations_df[mutations_df.duplicated('plant_ID','guide')]\n",
    "    #add plant\n",
    "    #print(mutations_df_copy)\n",
    "    #change column order\n",
    "    mutations_df = mutations_df[['chr', 'plant_ID', 'platename', 'library', 'first_reaction_primers',\n",
    "       'second_reaction_primers', 'guide', 'guide_number', 'aligned_sequence',\n",
    "       'reference_sequence', 'mutation_type','genotype', 'read_number', 'read_percentage',\n",
    "       'insertion_positions', 'deletion_positions', 'substitution_positions',\n",
    "       'insertion_cut_site_distance', 'deletion_cut_site_distance',\n",
    "       'substitution_cut_site_distance', 'cut_site_promoter_position',\n",
    "       'insertion_positions_relative_to_TSS', 'insertion_genomic_positions',\n",
    "       'deletion_positions_relative_to_TSS', 'deletion_genomic_positions',\n",
    "       'substitution_positions_relative_to_TSS',\n",
    "       'substitution_genomic_positions', 'insertion_overlapping_TFBS_family',\n",
    "       'insertion_overlapping_TFBS_AGI', 'deletion_overlapping_TFBS_family',\n",
    "       'deletion_overlapping_TFBS_AGI', 'substitution_overlapping_TFBS_family',\n",
    "       'substitution_overlapping_TFBS_AGI','number_of_different_alleles','number_of_different_non_wt_alleles'\n",
    "       ]]\n",
    "    #remove genotype 'nan'\n",
    "    mutations_df = mutations_df[~(mutations_df.genotype == 'nan')]\n",
    "    \n",
    "   \n",
    "   \n",
    "    #save df\n",
    "    mutations_df.to_csv(f'{output_folder}{gene}_TFBSoverlapping_categorised.tsv', sep=\"\\t\", index=False, header=1)\n",
    "\n",
    "    return mutations_df\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise_guide_pairs(mutations_df_genotyped, guide_pairs_df):\n",
    "    \"\"\"function to check which guide pairs where delivered to each plant line and to check whether mutations at more than one guide site are within the other guide pair\"\"\"\n",
    "    #first get unique guides based on 2 columns in guide_pairs_df    \n",
    "    unique_guides = pd.concat([guide_pairs_df['guide1'],guide_pairs_df['guide2']]).unique()\n",
    "    #for guides in unique guides list, add dictionary value of all other potential guides that it is paired with\n",
    "    #create defaultdict with lists as values so that non-existing keys can be added to in one go\n",
    "    guide_dict = defaultdict(list)\n",
    "    for guide in unique_guides:\n",
    "        #check for instances of that guide in the first column\n",
    "        filtered_col_1 = guide_pairs_df[guide_pairs_df.guide1==guide]['guide2'].to_list()\n",
    "        #then do the same for the second column\n",
    "        filtered_col_2 = guide_pairs_df[guide_pairs_df.guide2==guide]['guide1'].to_list()\n",
    "        #create list of unique values\n",
    "        list_of_unique = np.unique((filtered_col_1 + filtered_col_2)).astype(list)\n",
    "        #append each value in list to dict\n",
    "        for val in list_of_unique:\n",
    "            guide_dict[guide] += [val]\n",
    "        \n",
    "        \n",
    "        \n",
    "    #turn into normal dict\n",
    "    guide_dict = dict(guide_dict)\n",
    "\n",
    "    #mutations_df_genotyped df, filter out non mutated guides. Then create a dictionary of guides which were mutated. Then compare the guide pairs in guide_dict to the mutated guides.\n",
    "    #make a new df with one plant line per row, detailing how many guides sites were mutated, which guide sites where mutated and then if more than 1 guide site is mutated, if more than 3 guide pairs then flag that more than one agro strain and tDNA was inserted. If 2 mutated guide sites, flag whether the guides were guide pairs or whether the mutations were at sites not in a pair. If not in a pair then flag that plant line as having more than one agro strain and tDNA was inserted\n",
    "    #add any additional metrics for overall lines\n",
    "    #finally, merge this df with the mutations_df_genotyped (applying the same value in each column within each plant line)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_motifs_bed = '../../data/output/non-overlapping_includingbidirectional_all_genes_newannotation_3KB/FIMO/promoters_5UTR_motifs_mapped_q0_05.bed'\n",
    "mutations_ARF9 = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/Variant_call/ARF9_merged.tsv'\n",
    "mutations_ARF18 = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/Variant_call/ARF18_merged.tsv'\n",
    "mutations_DREB26 = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/Variant_call/DREB26_merged.tsv'\n",
    "mutations_NLP7 = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/Variant_call/NLP7_merged.tsv'\n",
    "output_folder = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/Variant_call/'\n",
    "guide_pairs = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/References/all_guide_pairs.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in files\n",
    "mutations_ARF9_df,mapped_motifs_df,guide_pairs_df =  read_in_files(mutations_ARF9, mapped_motifs_bed, guide_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>plant_ID</th>\n",
       "      <th>platename</th>\n",
       "      <th>library</th>\n",
       "      <th>first_reaction_primers</th>\n",
       "      <th>second_reaction_primers</th>\n",
       "      <th>guide</th>\n",
       "      <th>guide_number</th>\n",
       "      <th>aligned_sequence</th>\n",
       "      <th>reference_sequence</th>\n",
       "      <th>...</th>\n",
       "      <th>insertion_cut_site_distance</th>\n",
       "      <th>deletion_cut_site_distance</th>\n",
       "      <th>substitution_cut_site_distance</th>\n",
       "      <th>cut_site_promoter_position</th>\n",
       "      <th>insertion_positions_relative_to_TSS</th>\n",
       "      <th>insertion_genomic_positions</th>\n",
       "      <th>deletion_positions_relative_to_TSS</th>\n",
       "      <th>deletion_genomic_positions</th>\n",
       "      <th>substitution_positions_relative_to_TSS</th>\n",
       "      <th>substitution_genomic_positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>plntEPSWT20057-1</td>\n",
       "      <td>p1ARF9</td>\n",
       "      <td>1017</td>\n",
       "      <td>SW346_SW442</td>\n",
       "      <td>ARF9_1F_8R</td>\n",
       "      <td>ARF9_guide1</td>\n",
       "      <td>1</td>\n",
       "      <td>TAGGTTACAGTTACAGAGCAGGAAGGATTGCGTTGCGTTG</td>\n",
       "      <td>GAGGTTACAGTTACAGAGCAGGAAGGATTGCGTTGCGTTA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-20, 19]</td>\n",
       "      <td>1236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[198, 237]</td>\n",
       "      <td>[12451340, 12451379]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>plntEPSWT20057-1</td>\n",
       "      <td>p1ARF9</td>\n",
       "      <td>1017</td>\n",
       "      <td>SW346_SW442</td>\n",
       "      <td>ARF9_1F_8R</td>\n",
       "      <td>ARF9_guide1</td>\n",
       "      <td>1</td>\n",
       "      <td>GAGGTTACAGTTACAGAGCAGGAAGGATTGCGTTGCGTTA</td>\n",
       "      <td>GAGGTTACAGTTACAGAGCAGGAAGGATTGCGTTGCGTTA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>plntEPSWT20057-1</td>\n",
       "      <td>p1ARF9</td>\n",
       "      <td>1017</td>\n",
       "      <td>SW346_SW442</td>\n",
       "      <td>ARF9_1F_8R</td>\n",
       "      <td>ARF9_guide2</td>\n",
       "      <td>2</td>\n",
       "      <td>TAGAGAGGTTACAGTTACAGAGCAGGAAGGATTGCGTTG-</td>\n",
       "      <td>TAGAGAGGTTACAGTTACAGAGCAGGAAGGATTGCGTTGC</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[19]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[233]</td>\n",
       "      <td>[12451375]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>plntEPSWT20057-1</td>\n",
       "      <td>p1ARF9</td>\n",
       "      <td>1017</td>\n",
       "      <td>SW346_SW442</td>\n",
       "      <td>ARF9_1F_8R</td>\n",
       "      <td>ARF9_guide2</td>\n",
       "      <td>2</td>\n",
       "      <td>TAGAGAGGTTACAGTTACAGAGCAGGAAGGATTGCGTTGC</td>\n",
       "      <td>TAGAGAGGTTACAGTTACAGAGCAGGAAGGATTGCGTTGC</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>plntEPSWT20057-1</td>\n",
       "      <td>p1ARF9</td>\n",
       "      <td>1017</td>\n",
       "      <td>SW346_SW442</td>\n",
       "      <td>ARF9_1F_8R</td>\n",
       "      <td>ARF9_guide3</td>\n",
       "      <td>3</td>\n",
       "      <td>-TTTTACGGGAGAGAAATTAGAGAGGTTACAGTTACAGAG</td>\n",
       "      <td>GTTTTACGGGAGAGAAATTAGAGAGGTTACAGTTACAGAG</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-21, -20]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[175, 176]</td>\n",
       "      <td>[12451317, 12451318]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>4</td>\n",
       "      <td>plntEPSWT20067-8</td>\n",
       "      <td>p1ARF9</td>\n",
       "      <td>1017</td>\n",
       "      <td>SW357_SW453</td>\n",
       "      <td>ARF9_1F_5R</td>\n",
       "      <td>ARF9_guide28</td>\n",
       "      <td>28</td>\n",
       "      <td>TAATCCAAGTCTAGCCAGTATTGTTGCCTGCATAAGAGCA</td>\n",
       "      <td>TAATCCAAGTCTAGCCAGTATTGTTGCCTGCATAAGAGCA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>4</td>\n",
       "      <td>plntEPSWT20067-8</td>\n",
       "      <td>p1ARF9</td>\n",
       "      <td>1017</td>\n",
       "      <td>SW357_SW453</td>\n",
       "      <td>ARF9_1F_5R</td>\n",
       "      <td>ARF9_guide29</td>\n",
       "      <td>29</td>\n",
       "      <td>GCTTCGTCTCTAATCCAAGTCTAGCCAGTATTGTTGCCTG</td>\n",
       "      <td>GCTTCGTCTCTAATCCAAGTCTAGCCAGTATTGTTGCCTG</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>4</td>\n",
       "      <td>plntEPSWT20067-8</td>\n",
       "      <td>p1ARF9</td>\n",
       "      <td>1017</td>\n",
       "      <td>SW357_SW453</td>\n",
       "      <td>ARF9_1F_8R</td>\n",
       "      <td>ARF9_guide29</td>\n",
       "      <td>29</td>\n",
       "      <td>GCTTCGTCTCTAATCCAAGTCTAGCCAGTATTGTTGCCTG</td>\n",
       "      <td>GCTTCGTCTCTAATCCAAGTCTAGCCAGTATTGTTGCCTG</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>4</td>\n",
       "      <td>plntEPSWT20067-8</td>\n",
       "      <td>p1ARF9</td>\n",
       "      <td>1017</td>\n",
       "      <td>SW357_SW453</td>\n",
       "      <td>ARF9_1F_8R</td>\n",
       "      <td>ARF9_guide30</td>\n",
       "      <td>30</td>\n",
       "      <td>AAATGTAATTTATCCAAAGAAGGAGGTCAAAGCTGCTTCG</td>\n",
       "      <td>AAATGTAATTTATCCAAAGAAGGAGGTCAAAGCTGCTTCG</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>4</td>\n",
       "      <td>plntEPSWT20067-8</td>\n",
       "      <td>p1ARF9</td>\n",
       "      <td>1017</td>\n",
       "      <td>SW357_SW453</td>\n",
       "      <td>ARF9_1F_5R</td>\n",
       "      <td>ARF9_guide30</td>\n",
       "      <td>30</td>\n",
       "      <td>AAATGTAATTTATCCAAAGAAGGAGGTCAAAGCTGCTTCG</td>\n",
       "      <td>AAATGTAATTTATCCAAAGAAGGAGGTCAAAGCTGCTTCG</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chr          plant_ID platename  library first_reaction_primers  \\\n",
       "0      4  plntEPSWT20057-1    p1ARF9     1017            SW346_SW442   \n",
       "1      4  plntEPSWT20057-1    p1ARF9     1017            SW346_SW442   \n",
       "2      4  plntEPSWT20057-1    p1ARF9     1017            SW346_SW442   \n",
       "3      4  plntEPSWT20057-1    p1ARF9     1017            SW346_SW442   \n",
       "4      4  plntEPSWT20057-1    p1ARF9     1017            SW346_SW442   \n",
       "..   ...               ...       ...      ...                    ...   \n",
       "401    4  plntEPSWT20067-8    p1ARF9     1017            SW357_SW453   \n",
       "402    4  plntEPSWT20067-8    p1ARF9     1017            SW357_SW453   \n",
       "403    4  plntEPSWT20067-8    p1ARF9     1017            SW357_SW453   \n",
       "404    4  plntEPSWT20067-8    p1ARF9     1017            SW357_SW453   \n",
       "405    4  plntEPSWT20067-8    p1ARF9     1017            SW357_SW453   \n",
       "\n",
       "    second_reaction_primers         guide  guide_number  \\\n",
       "0                ARF9_1F_8R   ARF9_guide1             1   \n",
       "1                ARF9_1F_8R   ARF9_guide1             1   \n",
       "2                ARF9_1F_8R   ARF9_guide2             2   \n",
       "3                ARF9_1F_8R   ARF9_guide2             2   \n",
       "4                ARF9_1F_8R   ARF9_guide3             3   \n",
       "..                      ...           ...           ...   \n",
       "401              ARF9_1F_5R  ARF9_guide28            28   \n",
       "402              ARF9_1F_5R  ARF9_guide29            29   \n",
       "403              ARF9_1F_8R  ARF9_guide29            29   \n",
       "404              ARF9_1F_8R  ARF9_guide30            30   \n",
       "405              ARF9_1F_5R  ARF9_guide30            30   \n",
       "\n",
       "                             aligned_sequence  \\\n",
       "0    TAGGTTACAGTTACAGAGCAGGAAGGATTGCGTTGCGTTG   \n",
       "1    GAGGTTACAGTTACAGAGCAGGAAGGATTGCGTTGCGTTA   \n",
       "2    TAGAGAGGTTACAGTTACAGAGCAGGAAGGATTGCGTTG-   \n",
       "3    TAGAGAGGTTACAGTTACAGAGCAGGAAGGATTGCGTTGC   \n",
       "4    -TTTTACGGGAGAGAAATTAGAGAGGTTACAGTTACAGAG   \n",
       "..                                        ...   \n",
       "401  TAATCCAAGTCTAGCCAGTATTGTTGCCTGCATAAGAGCA   \n",
       "402  GCTTCGTCTCTAATCCAAGTCTAGCCAGTATTGTTGCCTG   \n",
       "403  GCTTCGTCTCTAATCCAAGTCTAGCCAGTATTGTTGCCTG   \n",
       "404  AAATGTAATTTATCCAAAGAAGGAGGTCAAAGCTGCTTCG   \n",
       "405  AAATGTAATTTATCCAAAGAAGGAGGTCAAAGCTGCTTCG   \n",
       "\n",
       "                           reference_sequence  ...  \\\n",
       "0    GAGGTTACAGTTACAGAGCAGGAAGGATTGCGTTGCGTTA  ...   \n",
       "1    GAGGTTACAGTTACAGAGCAGGAAGGATTGCGTTGCGTTA  ...   \n",
       "2    TAGAGAGGTTACAGTTACAGAGCAGGAAGGATTGCGTTGC  ...   \n",
       "3    TAGAGAGGTTACAGTTACAGAGCAGGAAGGATTGCGTTGC  ...   \n",
       "4    GTTTTACGGGAGAGAAATTAGAGAGGTTACAGTTACAGAG  ...   \n",
       "..                                        ...  ...   \n",
       "401  TAATCCAAGTCTAGCCAGTATTGTTGCCTGCATAAGAGCA  ...   \n",
       "402  GCTTCGTCTCTAATCCAAGTCTAGCCAGTATTGTTGCCTG  ...   \n",
       "403  GCTTCGTCTCTAATCCAAGTCTAGCCAGTATTGTTGCCTG  ...   \n",
       "404  AAATGTAATTTATCCAAAGAAGGAGGTCAAAGCTGCTTCG  ...   \n",
       "405  AAATGTAATTTATCCAAAGAAGGAGGTCAAAGCTGCTTCG  ...   \n",
       "\n",
       "    insertion_cut_site_distance  deletion_cut_site_distance  \\\n",
       "0                           NaN                         NaN   \n",
       "1                           NaN                         NaN   \n",
       "2                           NaN                        [19]   \n",
       "3                           NaN                         NaN   \n",
       "4                           NaN                  [-21, -20]   \n",
       "..                          ...                         ...   \n",
       "401                         NaN                         NaN   \n",
       "402                         NaN                         NaN   \n",
       "403                         NaN                         NaN   \n",
       "404                         NaN                         NaN   \n",
       "405                         NaN                         NaN   \n",
       "\n",
       "     substitution_cut_site_distance cut_site_promoter_position  \\\n",
       "0                         [-20, 19]                       1236   \n",
       "1                               NaN                       1236   \n",
       "2                               NaN                       1232   \n",
       "3                               NaN                       1232   \n",
       "4                               NaN                       1214   \n",
       "..                              ...                        ...   \n",
       "401                             NaN                        230   \n",
       "402                             NaN                        220   \n",
       "403                             NaN                        220   \n",
       "404                             NaN                        186   \n",
       "405                             NaN                        186   \n",
       "\n",
       "    insertion_positions_relative_to_TSS insertion_genomic_positions  \\\n",
       "0                                   NaN                         NaN   \n",
       "1                                   NaN                         NaN   \n",
       "2                                   NaN                         NaN   \n",
       "3                                   NaN                         NaN   \n",
       "4                                   NaN                         NaN   \n",
       "..                                  ...                         ...   \n",
       "401                                 NaN                         NaN   \n",
       "402                                 NaN                         NaN   \n",
       "403                                 NaN                         NaN   \n",
       "404                                 NaN                         NaN   \n",
       "405                                 NaN                         NaN   \n",
       "\n",
       "    deletion_positions_relative_to_TSS deletion_genomic_positions  \\\n",
       "0                                  NaN                        NaN   \n",
       "1                                  NaN                        NaN   \n",
       "2                                [233]                 [12451375]   \n",
       "3                                  NaN                        NaN   \n",
       "4                           [175, 176]       [12451317, 12451318]   \n",
       "..                                 ...                        ...   \n",
       "401                                NaN                        NaN   \n",
       "402                                NaN                        NaN   \n",
       "403                                NaN                        NaN   \n",
       "404                                NaN                        NaN   \n",
       "405                                NaN                        NaN   \n",
       "\n",
       "    substitution_positions_relative_to_TSS  substitution_genomic_positions  \n",
       "0                               [198, 237]            [12451340, 12451379]  \n",
       "1                                      NaN                             NaN  \n",
       "2                                      NaN                             NaN  \n",
       "3                                      NaN                             NaN  \n",
       "4                                      NaN                             NaN  \n",
       "..                                     ...                             ...  \n",
       "401                                    NaN                             NaN  \n",
       "402                                    NaN                             NaN  \n",
       "403                                    NaN                             NaN  \n",
       "404                                    NaN                             NaN  \n",
       "405                                    NaN                             NaN  \n",
       "\n",
       "[406 rows x 26 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutations_ARF9_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutations_df = find_overlapping_TFBSs(mutations_ARF9_df,mapped_motifs_df,output_folder,'ARF9')\n",
    "mutations_df = chunkify(mutations_ARF9_df,mapped_motifs_df,output_folder,'ARF9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations_df_genotyped = genotype_plant_lines(mutations_df,output_folder,'ARF9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ARF9_guide1': ['ARF9_guide5'], 'ARF9_guide2': ['ARF9_guide5'], 'ARF9_guide3': ['ARF9_guide5'], 'ARF9_guide4': ['ARF9_guide6'], 'ARF9_guide11': ['ARF9_guide6', 'ARF9_guide7', 'ARF9_guide8'], 'ARF9_guide9': ['ARF9_guide12'], 'ARF9_guide10': ['ARF9_guide12', 'ARF9_guide13'], 'ARF9_guide14': ['ARF9_guide13'], 'ARF9_guide15': ['ARF9_guide23'], 'ARF9_guide16': ['ARF9_guide23'], 'ARF9_guide17': ['ARF9_guide23'], 'ARF9_guide30': ['ARF9_guide23', 'ARF9_guide24'], 'ARF9_guide18': ['ARF9_guide25'], 'ARF9_guide19': ['ARF9_guide25'], 'ARF9_guide20': ['ARF9_guide26'], 'ARF9_guide21': ['ARF9_guide26', 'ARF9_guide27'], 'ARF9_guide22': ['ARF9_guide28', 'ARF9_guide29'], 'ARF18_guide1': ['ARF18_guide5'], 'ARF18_guide2': ['ARF18_guide5'], 'ARF18_guide12': ['ARF18_guide5', 'ARF18_guide6'], 'ARF18_guide3': ['ARF18_guide7'], 'ARF18_guide14': ['ARF18_guide19', 'ARF18_guide20', 'ARF18_guide21', 'ARF18_guide7'], 'ARF18_guide4': ['ARF18_guide9'], 'ARF18_guide17': ['ARF18_guide10', 'ARF18_guide9'], 'ARF18_guide13': ['ARF18_guide6'], 'ARF18_guide8': ['ARF18_guide15', 'ARF18_guide16'], 'ARF18_guide11': ['ARF18_guide18'], 'ARF18_guide23': ['ARF18_guide18'], 'ARF18_guide22': ['ARF18_guide24', 'ARF18_guide25', 'ARF18_guide26', 'ARF18_guide27', 'ARF18_guide28'], 'ARF18_guide29': ['ARF18_guide28'], 'ARF18_guide30': ['ARF18_guide28'], 'DREB26_guide1': ['DREB26_guide6'], 'DREB26_guide2': ['DREB26_guide7'], 'DREB26_guide3': ['DREB26_guide7'], 'DREB26_guide4': ['DREB26_guide7'], 'DREB26_guide5': ['DREB26_guide13'], 'DREB26_guide6': ['DREB26_guide1', 'DREB26_guide13'], 'DREB26_guide8': ['DREB26_guide14'], 'DREB26_guide9': ['DREB26_guide14'], 'DREB26_guide10': ['DREB26_guide14'], 'DREB26_guide11': ['DREB26_guide14'], 'DREB26_guide12': ['DREB26_guide15', 'DREB26_guide16', 'DREB26_guide17', 'DREB26_guide18'], 'DREB26_guide19': ['DREB26_guide23'], 'DREB26_guide20': ['DREB26_guide23'], 'DREB26_guide21': ['DREB26_guide23'], 'DREB26_guide22': ['DREB26_guide23', 'DREB26_guide24'], 'DREB26_guide27': ['DREB26_guide24'], 'DREB26_guide25': ['DREB26_guide28'], 'DREB26_guide26': ['DREB26_guide29', 'DREB26_guide30'], 'NLP7_guide1': ['NLP7_guide9'], 'NLP7_guide2': ['NLP7_guide9'], 'NLP7_guide3': ['NLP7_guide9'], 'NLP7_guide4': ['NLP7_guide10'], 'NLP7_guide5': ['NLP7_guide10'], 'NLP7_guide6': ['NLP7_guide10'], 'NLP7_guide7': ['NLP7_guide10'], 'NLP7_guide8': ['NLP7_guide10'], 'NLP7_guide9': ['NLP7_guide1', 'NLP7_guide10', 'NLP7_guide13', 'NLP7_guide2', 'NLP7_guide3'], 'NLP7_guide14': ['NLP7_guide10'], 'NLP7_guide11': ['NLP7_guide15'], 'NLP7_guide12': ['NLP7_guide15'], 'NLP7_guide16': ['NLP7_guide15'], 'NLP7_guide17': ['NLP7_guide15'], 'NLP7_guide18': ['NLP7_guide23'], 'NLP7_guide19': ['NLP7_guide23'], 'NLP7_guide20': ['NLP7_guide23'], 'NLP7_guide21': ['NLP7_guide23'], 'NLP7_guide22': ['NLP7_guide24', 'NLP7_guide25', 'NLP7_guide26', 'NLP7_guide27', 'NLP7_guide28'], 'NLP7_guide29': ['NLP7_guide28'], 'NLP7_guide30': ['NLP7_guide28'], 'ARF9_guide5': ['ARF9_guide1', 'ARF9_guide2', 'ARF9_guide3'], 'ARF9_guide6': ['ARF9_guide11', 'ARF9_guide4'], 'ARF9_guide7': ['ARF9_guide11'], 'ARF9_guide8': ['ARF9_guide11'], 'ARF9_guide12': ['ARF9_guide10', 'ARF9_guide9'], 'ARF9_guide13': ['ARF9_guide10', 'ARF9_guide14'], 'ARF9_guide23': ['ARF9_guide15', 'ARF9_guide16', 'ARF9_guide17', 'ARF9_guide30'], 'ARF9_guide25': ['ARF9_guide18', 'ARF9_guide19'], 'ARF9_guide26': ['ARF9_guide20', 'ARF9_guide21'], 'ARF9_guide27': ['ARF9_guide21'], 'ARF9_guide28': ['ARF9_guide22'], 'ARF9_guide29': ['ARF9_guide22'], 'ARF9_guide24': ['ARF9_guide30'], 'ARF18_guide5': ['ARF18_guide1', 'ARF18_guide12', 'ARF18_guide2'], 'ARF18_guide7': ['ARF18_guide14', 'ARF18_guide3'], 'ARF18_guide9': ['ARF18_guide17', 'ARF18_guide4'], 'ARF18_guide6': ['ARF18_guide12', 'ARF18_guide13'], 'ARF18_guide19': ['ARF18_guide14'], 'ARF18_guide20': ['ARF18_guide14'], 'ARF18_guide21': ['ARF18_guide14'], 'ARF18_guide15': ['ARF18_guide8'], 'ARF18_guide16': ['ARF18_guide8'], 'ARF18_guide10': ['ARF18_guide17'], 'ARF18_guide18': ['ARF18_guide11', 'ARF18_guide23'], 'ARF18_guide24': ['ARF18_guide22'], 'ARF18_guide25': ['ARF18_guide22'], 'ARF18_guide26': ['ARF18_guide22'], 'ARF18_guide27': ['ARF18_guide22'], 'ARF18_guide28': ['ARF18_guide22', 'ARF18_guide29', 'ARF18_guide30'], 'DREB26_guide7': ['DREB26_guide2', 'DREB26_guide3', 'DREB26_guide4'], 'DREB26_guide13': ['DREB26_guide5', 'DREB26_guide6'], 'DREB26_guide14': ['DREB26_guide10', 'DREB26_guide11', 'DREB26_guide8', 'DREB26_guide9'], 'DREB26_guide15': ['DREB26_guide12'], 'DREB26_guide16': ['DREB26_guide12'], 'DREB26_guide17': ['DREB26_guide12'], 'DREB26_guide18': ['DREB26_guide12'], 'DREB26_guide23': ['DREB26_guide19', 'DREB26_guide20', 'DREB26_guide21', 'DREB26_guide22'], 'DREB26_guide24': ['DREB26_guide22', 'DREB26_guide27'], 'DREB26_guide28': ['DREB26_guide25'], 'DREB26_guide29': ['DREB26_guide26'], 'DREB26_guide30': ['DREB26_guide26'], 'NLP7_guide10': ['NLP7_guide14', 'NLP7_guide4', 'NLP7_guide5', 'NLP7_guide6', 'NLP7_guide7', 'NLP7_guide8', 'NLP7_guide9'], 'NLP7_guide13': ['NLP7_guide9'], 'NLP7_guide15': ['NLP7_guide11', 'NLP7_guide12', 'NLP7_guide16', 'NLP7_guide17'], 'NLP7_guide23': ['NLP7_guide18', 'NLP7_guide19', 'NLP7_guide20', 'NLP7_guide21'], 'NLP7_guide24': ['NLP7_guide22'], 'NLP7_guide25': ['NLP7_guide22'], 'NLP7_guide26': ['NLP7_guide22'], 'NLP7_guide27': ['NLP7_guide22'], 'NLP7_guide28': ['NLP7_guide22', 'NLP7_guide29', 'NLP7_guide30']}\n"
     ]
    }
   ],
   "source": [
    "categorise_guide_pairs(mutations_df_genotyped,guide_pairs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2879a2396fb26a2192d4c546fae66e67014459dff7902256699e5c7228156d44"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pybedtools')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2879a2396fb26a2192d4c546fae66e67014459dff7902256699e5c7228156d44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
