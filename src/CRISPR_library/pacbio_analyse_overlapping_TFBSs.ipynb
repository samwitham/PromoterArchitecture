{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alleles_frequency_table.zip can be unzipped to a tab-separated text file that shows all reads and alignments to references. The first column shows the aligned sequence of the sequenced read. The second column shows the aligned sequence of the reference sequence. Gaps in each of these columns represent insertions and deletions. The next column 'Reference_Name' shows the name of the reference that the read aligned to. The fourth column, 'Read_Status' shows whether the read was modified or unmodified. The fifth through seventh columns ('n_deleted', 'n_inserted', 'n_substituted') show the number of bases deleted, inserted, and substituted as compared to the reference sequence. The eighth column shows the number of reads having that sequence, and the ninth column shows the percentage of all reads having that sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #features to add:\n",
    "# Distance from TSS - get relative position of mutation in the guide site - done. Add distance from cut site metric. - done Then calculate distance from Araport TSS - done\n",
    "# for this: first create a bed file for all of the mutations (relative to whole Arabidopsis genome). Then do bedtools merge or intersect (or bedtools coverage (../data_sorting/./TFBS_coverage.sh)) with the mapped motif bed file (all TFBSs for all genes). Record each TFBS that overlaps the mutation\n",
    "# Overlapping TFBSs - subnet\n",
    "# work and all TFs\n",
    "\n",
    "# Include secondary mutations in case both deletion and substitution for example - done\n",
    "# Plant ID\n",
    "# How many biallelic or homozygous? How many wildtype?\n",
    "# More than 2 alleles for a gene - record alleles until 80% of reads accounted for\n",
    "# Prioritise homozygous or biallelic\n",
    "# How many plants had mutations? How many guides produced mutations in each gene?\n",
    "#check window around cut site - at the moment I am including mutations 20bp either side, maybe cut the alignments down to 7bp either side before comparing them with find_indels_substitutions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use env pybedtools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "from pybedtools import BedTool\n",
    "from collections import defaultdict\n",
    "from more_itertools import sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_files(mutations_file,mapped_motifs,guide_pairs):\n",
    "    \"\"\"read in the files\"\"\"\n",
    "    #read in mapped motifs bed file\n",
    "    mapped_motifs = pd.read_table(mapped_motifs_bed, sep=\"\\t\", header=None)\n",
    "    if len(mapped_motifs.columns) == 24:\n",
    "        cols = [\n",
    "            \"chr\",\n",
    "            \"start\",\n",
    "            \"stop\",\n",
    "            \"promoter_AGI\",\n",
    "            \"dot1\",\n",
    "            \"strand\",\n",
    "            \"source\",\n",
    "            \"type\",\n",
    "            \"dot2\",\n",
    "            \"attributes\",\n",
    "            \"motif_chr\",\n",
    "            \"motif_start\",\n",
    "            \"motif_stop\",\n",
    "            \"name_rep\",\n",
    "            \"score\",\n",
    "            \"motif_strand\",\n",
    "            \"promoter_AGI2\",\n",
    "            \"p-value\",\n",
    "            \"q-value\",\n",
    "            \"matched_sequence\",\n",
    "            \"TF_name\",\n",
    "            \"TF_family\",\n",
    "            \"TF_AGI\",\n",
    "            \"bp_overlap\",\n",
    "        ]\n",
    "        mapped_motifs.columns = cols\n",
    "        # filter columns\n",
    "        mapped_motifs = mapped_motifs[\n",
    "            [\n",
    "                \"motif_chr\",\n",
    "                \"motif_start\",\n",
    "                \"motif_stop\",\n",
    "                \"name_rep\",\n",
    "                \"score\",\n",
    "                \"motif_strand\",\n",
    "                \"promoter_AGI2\",\n",
    "                \"p-value\",\n",
    "                \"q-value\",\n",
    "                \"matched_sequence\",\n",
    "                \"TF_name\",\n",
    "                \"TF_family\",\n",
    "                \"TF_AGI\",\n",
    "            ]\n",
    "        ]\n",
    "        #rename columns\n",
    "        cols = [\n",
    "            \"motif_chr\",\n",
    "            \"motif_start\",\n",
    "            \"motif_stop\",\n",
    "            \"name_rep\",\n",
    "            \"score\",\n",
    "            \"motif_strand\",\n",
    "            \"promoter_AGI\",\n",
    "            \"p-value\",\n",
    "            \"q-value\",\n",
    "            \"matched_sequence\",\n",
    "            \"TF_name\",\n",
    "            \"TF_family\",\n",
    "            \"TF_AGI\",\n",
    "        ]\n",
    "        mapped_motifs.columns = cols\n",
    "\n",
    "    elif len(mapped_motifs.columns) == 13:\n",
    "        cols = [\n",
    "            \"motif_chr\",\n",
    "            \"motif_start\",\n",
    "            \"motif_stop\",\n",
    "            \"name_rep\",\n",
    "            \"score\",\n",
    "            \"motif_strand\",\n",
    "            \"promoter_AGI\",\n",
    "            \"p-value\",\n",
    "            \"q-value\",\n",
    "            \"matched_sequence\",\n",
    "            \"TF_name\",\n",
    "            \"TF_family\",\n",
    "            \"TF_AGI\",\n",
    "        ]\n",
    "        mapped_motifs.columns = cols\n",
    "\n",
    "    elif len(mapped_motifs.columns) == 17:\n",
    "        cols = [\n",
    "            \"motif_chr\",\n",
    "            \"motif_start\",\n",
    "            \"motif_stop\",\n",
    "            \"name_rep\",\n",
    "            \"score\",\n",
    "            \"motif_strand\",\n",
    "            \"promoter_AGI\",\n",
    "            \"p-value\",\n",
    "            \"q-value\",\n",
    "            \"matched_sequence\",\n",
    "            \"TF_name\",\n",
    "            \"TF_family\",\n",
    "            \"TF_AGI\",\n",
    "            \"chr_openchrom\",\n",
    "            \"start_openchrom\",\n",
    "            \"stop_openchrom\",\n",
    "            \"bp_overlap\",\n",
    "        ]\n",
    "        mapped_motifs.columns = cols\n",
    "\n",
    "    mutations_df = pd.read_table(mutations_file,sep='\\t',header=0)\n",
    "    guide_pairs_df = pd.read_csv(guide_pairs,header=0)\n",
    "    #only keep first 2 columns\n",
    "    guide_cols = ['guide1','guide2']\n",
    "    guide_pairs_df = guide_pairs_df[guide_cols]\n",
    "    return mutations_df,mapped_motifs,guide_pairs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_bedfiles(bedfile, mapped_motifs_bed, output_buffer):\n",
    "    \"\"\"perform bedtools intersect on the two dfs\"\"\"\n",
    "    df = BedTool(bedfile)\n",
    "    motifs = BedTool(mapped_motifs_bed)\n",
    "    # -wao =Write the original A and B entries plus the number of base pairs of overlap between the two features.\n",
    "    # However, A features w/o overlap are also reported with a NULL B feature and overlap = 0\n",
    "    intersect = df.intersect(motifs, wao=True)\n",
    "    # Write to output_file\n",
    "    # Each line in the file contains bed entry a and bed entry b that it overlaps plus the number of bp in the overlap so 19 columns\n",
    "    output_buffer.write(str(intersect))\n",
    "    #go back to beginning of buffer\n",
    "    output_buffer.seek(0)\n",
    "    mapped_motifs_bed.seek(0)\n",
    "    return output_buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlapping_TFBSs(mutations_df_chunk,mapped_motifs_bed,mapped_motifs_bed_columns):\n",
    "    \"\"\"function to find any overlapping TFBSs from FIMO mapped motif file\"\"\"\n",
    "\n",
    "    #find mutations within\n",
    "    for mutations_df_index,mutations_df_row in mutations_df_chunk.iterrows():\n",
    "            \n",
    "        if mutations_df_row.mutation_type == 'None':\n",
    "            pass\n",
    "        else:\n",
    "            #create temporary df in bed format\n",
    "            \n",
    "            cols = [\"chr\",\n",
    "            \"start\",\n",
    "            \"stop\",\n",
    "            \"mutation_type\",'mutation_count']\n",
    "            temp_df = pd.DataFrame(columns=cols)\n",
    "            chr = mutations_df_row.chr\n",
    "            #if not NaN\n",
    "            if mutations_df_row.insertion_genomic_positions != 'nan':\n",
    "                #print(\"Index:\", index)\n",
    "                #print(row.insertion_genomic_positions)\n",
    "                #convert genomic positions from string to list\n",
    "                # Convert string to list if more than one\n",
    "                insertion_genomic_positions = mutations_df_row.insertion_genomic_positions.strip('][').split(', ')\n",
    "                #count which mutation number currently on to be added to the temporary bed file\n",
    "                count = 0\n",
    "                for gen_pos in insertion_genomic_positions:\n",
    "                    count += 1\n",
    "                    #get index\n",
    "                    # if len(insertion_genomic_positions) > 1:\n",
    "                    #     index = insertion_genomic_positions.index(gen_pos)\n",
    "                    # else:\n",
    "                    #     index = 'nan'\n",
    "                    start = int(gen_pos)\n",
    "                    stop = start + 1\n",
    "                    mutation_type = \"insertion\"\n",
    "                    #add to temp_df\n",
    "                    temp_list = [chr,start,stop,mutation_type,count]\n",
    "                    temp_df.loc[len(temp_df)] = temp_list\n",
    "            if mutations_df_row.deletion_genomic_positions != \"nan\":\n",
    "                # Convert string to list\n",
    "                deletion_genomic_positions = mutations_df_row.deletion_genomic_positions.strip('][').split(', ')\n",
    "                #count which mutation number currently on to be added to the temporary bed file\n",
    "                count = 0\n",
    "                for gen_pos in deletion_genomic_positions:\n",
    "                    count += 1\n",
    "                    #get index\n",
    "                    # if len(deletion_genomic_positions) > 1:\n",
    "                    #     index = deletion_genomic_positions.index(gen_pos)\n",
    "                    # else:\n",
    "                    #     index = 'nan'\n",
    "                    start = int(gen_pos)\n",
    "                    stop = start + 1\n",
    "                    mutation_type = \"deletion\"\n",
    "                    #add to temp_df\n",
    "                    temp_list = [chr,start,stop,mutation_type,count]\n",
    "                    temp_df.loc[len(temp_df)] = temp_list\n",
    "            if mutations_df_row.substitution_genomic_positions != \"nan\":\n",
    "                # Convert string to list\n",
    "                substitution_genomic_positions = mutations_df_row.substitution_genomic_positions.strip('][').split(', ')\n",
    "                #count which mutation number currently on to be added to the temporary bed file\n",
    "                count = 0\n",
    "                for gen_pos in substitution_genomic_positions:\n",
    "                    count += 1\n",
    "                    #get index\n",
    "                    # if len(substitution_genomic_positions) > 1:\n",
    "                    #     index = substitution_genomic_positions.index(gen_pos)\n",
    "                    # else:\n",
    "                    #     index = 'nan'\n",
    "                    start = int(gen_pos)\n",
    "                    stop = start + 1\n",
    "                    mutation_type = \"substitution\"\n",
    "                    #add to temp_df\n",
    "                    temp_list = [chr,start,stop,mutation_type,count]\n",
    "                    temp_df.loc[len(temp_df)] = temp_list\n",
    "            #now do bedtools intersect to find which TFBSs overlap with which mutations\n",
    "            #sort by chr then start\n",
    "            temp_df = temp_df.sort_values([\"chr\", \"start\"]).reset_index(drop=True)\n",
    "            # write to buffer\n",
    "            temp_df_buffer = io.StringIO()\n",
    "            temp_df.to_csv(temp_df_buffer, sep=\"\\t\", index=False, header=None)\n",
    "            temp_df_buffer.seek(0)\n",
    "            \n",
    "            output_buffer = io.StringIO()\n",
    "        \n",
    "            output_buffer = merge_bedfiles(temp_df_buffer, mapped_motifs_bed, output_buffer)\n",
    "            \n",
    "            #remove temp_df_buffer stream\n",
    "\n",
    "\n",
    "            #read in output buffer as df\n",
    "            output_df = pd.read_table(output_buffer, sep='\\t')\n",
    "            \n",
    "            #get column names and rename columns\n",
    "            output_df_cols = cols+mapped_motifs_bed_columns+['bp_overlap']\n",
    "            output_df.columns = output_df_cols\n",
    "            #for each mutation type get list of overlapping TFBSs. Add these to a dictionary column in the mutations_df_chunk\n",
    "            #create defaultdicts with lists as values so that non-existing keys can be added to in one go\n",
    "            insertion_overlapping_TFBS_family = defaultdict(list)\n",
    "            insertion_overlapping_TFBS_AGI = defaultdict(list)\n",
    "            #insertion_overlapping_TFBS_total = defaultdict(list)\n",
    "            deletion_overlapping_TFBS_family = defaultdict(list)\n",
    "            deletion_overlapping_TFBS_AGI = defaultdict(list)\n",
    "            #deletion_overlapping_TFBS_total = defaultdict(list)\n",
    "            substitution_overlapping_TFBS_family = defaultdict(list)\n",
    "            substitution_overlapping_TFBS_AGI = defaultdict(list)\n",
    "            #substitution_overlapping_TFBS_total = defaultdict(list)\n",
    "            \n",
    "\n",
    "            for index,row in output_df.iterrows():\n",
    "                # empty number that will increase for each insertion\n",
    "               # insertion_overlapping_TFBS_count = int()\n",
    "               #if mutation and has a 1bp overlap\n",
    "               #if no TF_AGI then pass\n",
    "                if row.TF_AGI == '.':\n",
    "                    pass\n",
    "                elif row.mutation_type == 'insertion' and row.bp_overlap > 0:\n",
    "                    #add insertion TFBS family information to dictionary for the correct mutation number\n",
    "                    #print(row)\n",
    "                    insertion_overlapping_TFBS_family[f'insertion{row.mutation_count}'] += [row.TF_family]\n",
    "                    #add insertion TFBS AGI information to dictionary for the correct mutation number\n",
    "                    insertion_overlapping_TFBS_AGI[f'insertion{row.mutation_count}'] += [row.TF_AGI]\n",
    "                    #add total number of TFBSs overlapping each insertion\n",
    "                 #   insertion_overlapping_TFBS_total[f'insertion{row.mutation_count}'] += 1\n",
    "                elif row.mutation_type == 'deletion' and row.bp_overlap > 0:\n",
    "                    #add deletion TFBS family information to dictionary for the correct mutation number\n",
    "                    deletion_overlapping_TFBS_family[f'deletion{row.mutation_count}'] += [row.TF_family]\n",
    "                    #add deletion TFBS AGI information to dictionary for the correct mutation number\n",
    "                    deletion_overlapping_TFBS_AGI[f'deletion{row.mutation_count}'] += [row.TF_AGI]\n",
    "                    #add total number of TFBSs overlapping each insertion\n",
    "                   # deletion_overlapping_TFBS_total[f'deletion{row.mutation_count}'] += 1\n",
    "                elif row.mutation_type == 'substitution' and row.bp_overlap > 0:\n",
    "                    #add substitution TFBS family information to dictionary for the correct mutation number\n",
    "                    substitution_overlapping_TFBS_family[f'substitution{row.mutation_count}'] += [row.TF_family]\n",
    "                    #add substitution TFBS AGI information to dictionary for the correct mutation number\n",
    "                    substitution_overlapping_TFBS_AGI[f'substitution{row.mutation_count}'] += [row.TF_AGI]\n",
    "                    #add total number of TFBSs overlapping each insertion\n",
    "                 #   substitution_overlapping_TFBS_total[f'substitution{row.mutation_count}'] += 1\n",
    "            # #calculate total unique TFBS for each insertion, deletion and subsitution\n",
    "            # insertion_overlapping_TFBS_total_unique = []\n",
    "            # for insertion,AGI in insertion_overlapping_TFBS_AGI.items():\n",
    "            #     insertion_overlapping_TFBS_total_unique += np.unique(AGI).astype(list)\n",
    "            # deletion_overlapping_TFBS_total_unique = []\n",
    "            # for deletion,AGI in deletion_overlapping_TFBS_AGI.items():\n",
    "            #     print(f'AGIunique={np.unique(AGI).astype(list)}')\n",
    "            #     print(f'total={deletion_overlapping_TFBS_total_unique}')\n",
    "            #     print(f'AGI={AGI}')\n",
    "            #     deletion_overlapping_TFBS_total_unique += np.unique(AGI).astype(list)\n",
    "            #     print(f'newtotal={deletion_overlapping_TFBS_total_unique}')\n",
    "            # substitution_overlapping_TFBS_total_unique = []\n",
    "            # for substitution,AGI in substitution_overlapping_TFBS_AGI.items():\n",
    "            #     substitution_overlapping_TFBS_total_unique += np.unique(AGI).astype(list)\n",
    "                \n",
    "            #add values to mutations_df row\n",
    "            #print(f'insertion_overlapping_TFBS_family={dict(insertion_overlapping_TFBS_family)}')\n",
    "            #print(mutations_df_row)\n",
    "            #first make overlapping TFBS families and AGIs unique\n",
    "            insertion_overlapping_TFBS_family = dict(insertion_overlapping_TFBS_family)\n",
    "            insertion_overlapping_TFBS_AGI = dict(insertion_overlapping_TFBS_AGI)\n",
    "            deletion_overlapping_TFBS_family = dict(deletion_overlapping_TFBS_family)\n",
    "            deletion_overlapping_TFBS_AGI = dict(deletion_overlapping_TFBS_AGI)\n",
    "            substitution_overlapping_TFBS_family = dict(substitution_overlapping_TFBS_family)\n",
    "            substitution_overlapping_TFBS_AGI = dict(substitution_overlapping_TFBS_AGI)\n",
    "            #if empty dictionary, change to nan\n",
    "            if insertion_overlapping_TFBS_family == {}:\n",
    "                insertion_overlapping_TFBS_family = 'nan'\n",
    "            else:\n",
    "                #keep only unique TFBS families\n",
    "                for k,v in insertion_overlapping_TFBS_family.items():\n",
    "                    #print(np.unique(v).astype(list))\n",
    "                    insertion_overlapping_TFBS_family[k] = np.unique(v).tolist()\n",
    "\n",
    "            if insertion_overlapping_TFBS_AGI == {}:\n",
    "                insertion_overlapping_TFBS_AGI = 'nan'\n",
    "            else:\n",
    "                #keep only unique TFBS AGIs\n",
    "                for k,v in insertion_overlapping_TFBS_AGI.items():\n",
    "                    #print(np.unique(v).astype(list))\n",
    "                    insertion_overlapping_TFBS_AGI[k] = np.unique(v).tolist()\n",
    "\n",
    "            if deletion_overlapping_TFBS_family == {}:\n",
    "                deletion_overlapping_TFBS_family = 'nan'\n",
    "            else:\n",
    "                #keep only unique TFBS families\n",
    "                for k,v in deletion_overlapping_TFBS_family.items():\n",
    "                    #print(np.unique(v).astype(list))\n",
    "                    deletion_overlapping_TFBS_family[k] = np.unique(v).tolist()\n",
    "\n",
    "            if deletion_overlapping_TFBS_AGI == {}:\n",
    "                deletion_overlapping_TFBS_AGI = 'nan'\n",
    "            else:\n",
    "                #keep only unique TFBS AGIs\n",
    "                for k,v in deletion_overlapping_TFBS_AGI.items():\n",
    "                    #print(np.unique(v).astype(list))\n",
    "                    deletion_overlapping_TFBS_AGI[k] = np.unique(v).tolist()\n",
    "            \n",
    "            if substitution_overlapping_TFBS_family == {}:\n",
    "                substitution_overlapping_TFBS_family = 'nan'\n",
    "            else:\n",
    "                #keep only unique TFBS families\n",
    "                for k,v in substitution_overlapping_TFBS_family.items():\n",
    "                    #print(np.unique(v).astype(list))\n",
    "                    substitution_overlapping_TFBS_family[k] = np.unique(v).tolist()\n",
    "                    \n",
    "            if substitution_overlapping_TFBS_AGI == {}:\n",
    "                substitution_overlapping_TFBS_AGI = 'nan'\n",
    "            else:\n",
    "                #keep only unique TFBS AGIs\n",
    "                for k,v in substitution_overlapping_TFBS_AGI.items():\n",
    "                    #print(np.unique(v).astype(list))\n",
    "                    substitution_overlapping_TFBS_AGI[k] = np.unique(v).tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            mutations_df_chunk.loc[mutations_df_index, \"insertion_overlapping_TFBS_family\"] = str(insertion_overlapping_TFBS_family)\n",
    "            mutations_df_chunk.loc[mutations_df_index, \"insertion_overlapping_TFBS_AGI\"]= str(insertion_overlapping_TFBS_AGI)\n",
    "            mutations_df_chunk.loc[mutations_df_index, \"deletion_overlapping_TFBS_family\"]= str(deletion_overlapping_TFBS_family)\n",
    "            mutations_df_chunk.loc[mutations_df_index, \"deletion_overlapping_TFBS_AGI\"]= str(deletion_overlapping_TFBS_AGI)\n",
    "            mutations_df_chunk.loc[mutations_df_index, \"substitution_overlapping_TFBS_family\"]= str(substitution_overlapping_TFBS_family)\n",
    "            mutations_df_chunk.loc[mutations_df_index, \"substitution_overlapping_TFBS_AGI\"]= str(substitution_overlapping_TFBS_AGI)\n",
    "            # row.insertion_overlapping_TFBS_total_unique= insertion_overlapping_TFBS_total_unique\n",
    "            # row.deletion_overlapping_TFBS_total_unique= deletion_overlapping_TFBS_total_unique\n",
    "            # row.substitution_overlapping_TFBS_total_unique= substitution_overlapping_TFBS_total_unique\n",
    "            #remove the buffer stream\n",
    "    return mutations_df_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkify(mutations_df,mapped_motifs_df,output_folder,gene):\n",
    "    \"\"\"function to prepare dfs and slice mutations_df into chunks to reduce memory before running find_overlapping_TFBSs() \"\"\"\n",
    "   \n",
    "\n",
    "    #for each guide containing mutations, create a temporary bed file containing each mutation and then do bedtools intersect to find which overlap TFBs\n",
    "    #then add the TFBS names into a new column for that row\n",
    "\n",
    "    #get column names from mapped_motifs_df\n",
    "    mapped_motifs_bed_columns = list(mapped_motifs_df.columns)\n",
    "\n",
    "\n",
    "    #turn mapped_motifs_df into a buffer\n",
    "    mapped_motifs_bed = io.StringIO()\n",
    "    mapped_motifs_df.to_csv(mapped_motifs_bed, sep=\"\\t\", index=False, header=None)\n",
    "    #go back to start of buffer\n",
    "    mapped_motifs_bed.seek(0)\n",
    "\n",
    "    #add columns to mutations_df\n",
    "    new_columns = ['insertion_overlapping_TFBS_family',\n",
    "    'insertion_overlapping_TFBS_AGI',\n",
    "    'deletion_overlapping_TFBS_family',\n",
    "    'deletion_overlapping_TFBS_AGI',\n",
    "    'substitution_overlapping_TFBS_family',\n",
    "    'substitution_overlapping_TFBS_AGI',\n",
    "                  ]\n",
    "    #first make a new df that will merge into mutations_df\n",
    "    temp_new_df = pd.DataFrame(columns=new_columns)\n",
    "    mutations_df = pd.concat([mutations_df,temp_new_df], axis=1)\n",
    "    #print(mutations_df)\n",
    "\n",
    "    #first make certain columns string\n",
    "    #make columns containing lists string for now so can use groupby\n",
    "    to_string = ['insertion_positions','deletion_positions','substitution_positions','insertion_cut_site_distance','deletion_cut_site_distance','substitution_cut_site_distance','insertion_positions_relative_to_TSS','insertion_genomic_positions','deletion_positions_relative_to_TSS','deletion_genomic_positions','substitution_positions_relative_to_TSS','substitution_genomic_positions']\n",
    "    mutations_df[to_string] = mutations_df[to_string].astype(str)\n",
    "\n",
    "    #convert mutations_df into chunks to reduce memory load\n",
    "    CHUNK_SIZE = 5\n",
    "\n",
    "    index_slices = sliced(range(len(mutations_df)), CHUNK_SIZE)\n",
    "    #create list of chunks\n",
    "    chunks = []\n",
    "    for index_slice in index_slices:\n",
    "        #go back to start of buffer\n",
    "        mapped_motifs_bed.seek(0)\n",
    "        chunk = mutations_df.iloc[index_slice] # your dataframe chunk ready for use\n",
    "        new_chunk = find_overlapping_TFBSs(mutations_df_chunk,mapped_motifs_bed,mapped_motifs_bed_columns)\n",
    "\n",
    "        \n",
    "        chunks.append(new_chunk)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    #concatenate chunks into mutations_df\n",
    "    mutations_df = pd.concat(chunks, axis=1)            \n",
    "    #write out mutations_df\n",
    "    mutations_df.to_csv(f'{output_folder}{gene}_TFBSoverlapping.tsv', sep=\"\\t\", index=False, header=1)\n",
    "                     \n",
    "    return mutations_df      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chunkify(mutations_df,mapped_motifs_df,output_folder,gene):\n",
    "#     \"\"\"function to prepare dfs and slice mutations_df into chunks to reduce memory before running find_overlapping_TFBSs() \"\"\"\n",
    "   \n",
    "\n",
    "#     #for each guide containing mutations, create a temporary bed file containing each mutation and then do bedtools intersect to find which overlap TFBs\n",
    "#     #then add the TFBS names into a new column for that row\n",
    "\n",
    "#     #get column names from mapped_motifs_df\n",
    "#     mapped_motifs_bed_columns = list(mapped_motifs_df.columns)\n",
    "\n",
    "\n",
    "#     #turn mapped_motifs_df into a buffer\n",
    "#     mapped_motifs_bed = io.StringIO()\n",
    "#     mapped_motifs_df.to_csv(mapped_motifs_bed, sep=\"\\t\", index=False, header=None)\n",
    "#     #go back to start of buffer\n",
    "#     mapped_motifs_bed.seek(0)\n",
    "\n",
    "#     #add columns to mutations_df\n",
    "#     new_columns = ['insertion_overlapping_TFBS_family',\n",
    "#     'insertion_overlapping_TFBS_AGI',\n",
    "#     'deletion_overlapping_TFBS_family',\n",
    "#     'deletion_overlapping_TFBS_AGI',\n",
    "#     'substitution_overlapping_TFBS_family',\n",
    "#     'substitution_overlapping_TFBS_AGI',\n",
    "#                   ]\n",
    "#     #first make a new df that will merge into mutations_df\n",
    "#     temp_new_df = pd.DataFrame(columns=new_columns)\n",
    "#     mutations_df = pd.concat([mutations_df,temp_new_df], axis=1)\n",
    "#     #print(mutations_df)\n",
    "\n",
    "#     #first make certain columns string\n",
    "#     #make columns containing lists string for now so can use groupby\n",
    "#     to_string = ['insertion_positions','deletion_positions','substitution_positions','insertion_cut_site_distance','deletion_cut_site_distance','substitution_cut_site_distance','insertion_positions_relative_to_TSS','insertion_genomic_positions','deletion_positions_relative_to_TSS','deletion_genomic_positions','substitution_positions_relative_to_TSS','substitution_genomic_positions']\n",
    "#     mutations_df[to_string] = mutations_df[to_string].astype(str)\n",
    "\n",
    "#     #convert mutations_df into chunks to reduce memory load\n",
    "#     CHUNK_SIZE = 5\n",
    "\n",
    "#     index_slices = sliced(range(len(mutations_df)), CHUNK_SIZE)\n",
    "\n",
    "#     for index_slice in index_slices:\n",
    "#         chunk = mutations_df.iloc[index_slice] # your dataframe chunk ready for use\n",
    "\n",
    "#     #find mutations within\n",
    "#     for mutations_df_index,mutations_df_row in mutations_df.iterrows():\n",
    "            \n",
    "#         if mutations_df_row.mutation_type == 'None':\n",
    "#             pass\n",
    "#         else:\n",
    "#             #create temporary df in bed format\n",
    "            \n",
    "#             cols = [\"chr\",\n",
    "#             \"start\",\n",
    "#             \"stop\",\n",
    "#             \"mutation_type\",'mutation_count']\n",
    "#             temp_df = pd.DataFrame(columns=cols)\n",
    "#             chr = mutations_df_row.chr\n",
    "#             #if not NaN\n",
    "#             if mutations_df_row.insertion_genomic_positions != 'nan':\n",
    "#                 #print(\"Index:\", index)\n",
    "#                 #print(row.insertion_genomic_positions)\n",
    "#                 #convert genomic positions from string to list\n",
    "#                 # Convert string to list if more than one\n",
    "#                 insertion_genomic_positions = mutations_df_row.insertion_genomic_positions.strip('][').split(', ')\n",
    "#                 #count which mutation number currently on to be added to the temporary bed file\n",
    "#                 count = 0\n",
    "#                 for gen_pos in insertion_genomic_positions:\n",
    "#                     count += 1\n",
    "#                     #get index\n",
    "#                     # if len(insertion_genomic_positions) > 1:\n",
    "#                     #     index = insertion_genomic_positions.index(gen_pos)\n",
    "#                     # else:\n",
    "#                     #     index = 'nan'\n",
    "#                     start = int(gen_pos)\n",
    "#                     stop = start + 1\n",
    "#                     mutation_type = \"insertion\"\n",
    "#                     #add to temp_df\n",
    "#                     temp_list = [chr,start,stop,mutation_type,count]\n",
    "#                     temp_df.loc[len(temp_df)] = temp_list\n",
    "#             if mutations_df_row.deletion_genomic_positions != \"nan\":\n",
    "#                 # Convert string to list\n",
    "#                 deletion_genomic_positions = mutations_df_row.deletion_genomic_positions.strip('][').split(', ')\n",
    "#                 #count which mutation number currently on to be added to the temporary bed file\n",
    "#                 count = 0\n",
    "#                 for gen_pos in deletion_genomic_positions:\n",
    "#                     count += 1\n",
    "#                     #get index\n",
    "#                     # if len(deletion_genomic_positions) > 1:\n",
    "#                     #     index = deletion_genomic_positions.index(gen_pos)\n",
    "#                     # else:\n",
    "#                     #     index = 'nan'\n",
    "#                     start = int(gen_pos)\n",
    "#                     stop = start + 1\n",
    "#                     mutation_type = \"deletion\"\n",
    "#                     #add to temp_df\n",
    "#                     temp_list = [chr,start,stop,mutation_type,count]\n",
    "#                     temp_df.loc[len(temp_df)] = temp_list\n",
    "#             if mutations_df_row.substitution_genomic_positions != \"nan\":\n",
    "#                 # Convert string to list\n",
    "#                 substitution_genomic_positions = mutations_df_row.substitution_genomic_positions.strip('][').split(', ')\n",
    "#                 #count which mutation number currently on to be added to the temporary bed file\n",
    "#                 count = 0\n",
    "#                 for gen_pos in substitution_genomic_positions:\n",
    "#                     count += 1\n",
    "#                     #get index\n",
    "#                     # if len(substitution_genomic_positions) > 1:\n",
    "#                     #     index = substitution_genomic_positions.index(gen_pos)\n",
    "#                     # else:\n",
    "#                     #     index = 'nan'\n",
    "#                     start = int(gen_pos)\n",
    "#                     stop = start + 1\n",
    "#                     mutation_type = \"substitution\"\n",
    "#                     #add to temp_df\n",
    "#                     temp_list = [chr,start,stop,mutation_type,count]\n",
    "#                     temp_df.loc[len(temp_df)] = temp_list\n",
    "#             #now do bedtools intersect to find which TFBSs overlap with which mutations\n",
    "#             #sort by chr then start\n",
    "#             temp_df = temp_df.sort_values([\"chr\", \"start\"]).reset_index(drop=True)\n",
    "#             # write to buffer\n",
    "#             temp_df_buffer = io.StringIO()\n",
    "#             temp_df.to_csv(temp_df_buffer, sep=\"\\t\", index=False, header=None)\n",
    "#             temp_df_buffer.seek(0)\n",
    "            \n",
    "#             output_buffer = io.StringIO()\n",
    "        \n",
    "#             output_buffer = merge_bedfiles(temp_df_buffer, mapped_motifs_bed, output_buffer)\n",
    "            \n",
    "#             #remove temp_df_buffer stream\n",
    "\n",
    "\n",
    "#             #read in output buffer as df\n",
    "#             output_df = pd.read_table(output_buffer, sep='\\t')\n",
    "            \n",
    "#             #get column names and rename columns\n",
    "#             output_df_cols = cols+mapped_motifs_bed_columns+['bp_overlap']\n",
    "#             output_df.columns = output_df_cols\n",
    "#             #for each mutation type get list of overlapping TFBSs. Add these to a dictionary column in the mutations_df\n",
    "#             #create defaultdicts with lists as values so that non-existing keys can be added to in one go\n",
    "#             insertion_overlapping_TFBS_family = defaultdict(list)\n",
    "#             insertion_overlapping_TFBS_AGI = defaultdict(list)\n",
    "#             #insertion_overlapping_TFBS_total = defaultdict(list)\n",
    "#             deletion_overlapping_TFBS_family = defaultdict(list)\n",
    "#             deletion_overlapping_TFBS_AGI = defaultdict(list)\n",
    "#             #deletion_overlapping_TFBS_total = defaultdict(list)\n",
    "#             substitution_overlapping_TFBS_family = defaultdict(list)\n",
    "#             substitution_overlapping_TFBS_AGI = defaultdict(list)\n",
    "#             #substitution_overlapping_TFBS_total = defaultdict(list)\n",
    "            \n",
    "\n",
    "#             for index,row in output_df.iterrows():\n",
    "#                 # empty number that will increase for each insertion\n",
    "#                # insertion_overlapping_TFBS_count = int()\n",
    "#                #if mutation and has a 1bp overlap\n",
    "#                #if no TF_AGI then pass\n",
    "#                 if row.TF_AGI == '.':\n",
    "#                     pass\n",
    "#                 elif row.mutation_type == 'insertion' and row.bp_overlap > 0:\n",
    "#                     #add insertion TFBS family information to dictionary for the correct mutation number\n",
    "#                     #print(row)\n",
    "#                     insertion_overlapping_TFBS_family[f'insertion{row.mutation_count}'] += [row.TF_family]\n",
    "#                     #add insertion TFBS AGI information to dictionary for the correct mutation number\n",
    "#                     insertion_overlapping_TFBS_AGI[f'insertion{row.mutation_count}'] += [row.TF_AGI]\n",
    "#                     #add total number of TFBSs overlapping each insertion\n",
    "#                  #   insertion_overlapping_TFBS_total[f'insertion{row.mutation_count}'] += 1\n",
    "#                 elif row.mutation_type == 'deletion' and row.bp_overlap > 0:\n",
    "#                     #add deletion TFBS family information to dictionary for the correct mutation number\n",
    "#                     deletion_overlapping_TFBS_family[f'deletion{row.mutation_count}'] += [row.TF_family]\n",
    "#                     #add deletion TFBS AGI information to dictionary for the correct mutation number\n",
    "#                     deletion_overlapping_TFBS_AGI[f'deletion{row.mutation_count}'] += [row.TF_AGI]\n",
    "#                     #add total number of TFBSs overlapping each insertion\n",
    "#                    # deletion_overlapping_TFBS_total[f'deletion{row.mutation_count}'] += 1\n",
    "#                 elif row.mutation_type == 'substitution' and row.bp_overlap > 0:\n",
    "#                     #add substitution TFBS family information to dictionary for the correct mutation number\n",
    "#                     substitution_overlapping_TFBS_family[f'substitution{row.mutation_count}'] += [row.TF_family]\n",
    "#                     #add substitution TFBS AGI information to dictionary for the correct mutation number\n",
    "#                     substitution_overlapping_TFBS_AGI[f'substitution{row.mutation_count}'] += [row.TF_AGI]\n",
    "#                     #add total number of TFBSs overlapping each insertion\n",
    "#                  #   substitution_overlapping_TFBS_total[f'substitution{row.mutation_count}'] += 1\n",
    "#             # #calculate total unique TFBS for each insertion, deletion and subsitution\n",
    "#             # insertion_overlapping_TFBS_total_unique = []\n",
    "#             # for insertion,AGI in insertion_overlapping_TFBS_AGI.items():\n",
    "#             #     insertion_overlapping_TFBS_total_unique += np.unique(AGI).astype(list)\n",
    "#             # deletion_overlapping_TFBS_total_unique = []\n",
    "#             # for deletion,AGI in deletion_overlapping_TFBS_AGI.items():\n",
    "#             #     print(f'AGIunique={np.unique(AGI).astype(list)}')\n",
    "#             #     print(f'total={deletion_overlapping_TFBS_total_unique}')\n",
    "#             #     print(f'AGI={AGI}')\n",
    "#             #     deletion_overlapping_TFBS_total_unique += np.unique(AGI).astype(list)\n",
    "#             #     print(f'newtotal={deletion_overlapping_TFBS_total_unique}')\n",
    "#             # substitution_overlapping_TFBS_total_unique = []\n",
    "#             # for substitution,AGI in substitution_overlapping_TFBS_AGI.items():\n",
    "#             #     substitution_overlapping_TFBS_total_unique += np.unique(AGI).astype(list)\n",
    "                \n",
    "#             #add values to mutations_df row\n",
    "#             #print(f'insertion_overlapping_TFBS_family={dict(insertion_overlapping_TFBS_family)}')\n",
    "#             #print(mutations_df_row)\n",
    "#             #first make overlapping TFBS families and AGIs unique\n",
    "#             insertion_overlapping_TFBS_family = dict(insertion_overlapping_TFBS_family)\n",
    "#             insertion_overlapping_TFBS_AGI = dict(insertion_overlapping_TFBS_AGI)\n",
    "#             deletion_overlapping_TFBS_family = dict(deletion_overlapping_TFBS_family)\n",
    "#             deletion_overlapping_TFBS_AGI = dict(deletion_overlapping_TFBS_AGI)\n",
    "#             substitution_overlapping_TFBS_family = dict(substitution_overlapping_TFBS_family)\n",
    "#             substitution_overlapping_TFBS_AGI = dict(substitution_overlapping_TFBS_AGI)\n",
    "#             #if empty dictionary, change to nan\n",
    "#             if insertion_overlapping_TFBS_family == {}:\n",
    "#                 insertion_overlapping_TFBS_family = 'nan'\n",
    "#             else:\n",
    "#                 #keep only unique TFBS families\n",
    "#                 for k,v in insertion_overlapping_TFBS_family.items():\n",
    "#                     #print(np.unique(v).astype(list))\n",
    "#                     insertion_overlapping_TFBS_family[k] = np.unique(v).tolist()\n",
    "\n",
    "#             if insertion_overlapping_TFBS_AGI == {}:\n",
    "#                 insertion_overlapping_TFBS_AGI = 'nan'\n",
    "#             else:\n",
    "#                 #keep only unique TFBS AGIs\n",
    "#                 for k,v in insertion_overlapping_TFBS_AGI.items():\n",
    "#                     #print(np.unique(v).astype(list))\n",
    "#                     insertion_overlapping_TFBS_AGI[k] = np.unique(v).tolist()\n",
    "\n",
    "#             if deletion_overlapping_TFBS_family == {}:\n",
    "#                 deletion_overlapping_TFBS_family = 'nan'\n",
    "#             else:\n",
    "#                 #keep only unique TFBS families\n",
    "#                 for k,v in deletion_overlapping_TFBS_family.items():\n",
    "#                     #print(np.unique(v).astype(list))\n",
    "#                     deletion_overlapping_TFBS_family[k] = np.unique(v).tolist()\n",
    "\n",
    "#             if deletion_overlapping_TFBS_AGI == {}:\n",
    "#                 deletion_overlapping_TFBS_AGI = 'nan'\n",
    "#             else:\n",
    "#                 #keep only unique TFBS AGIs\n",
    "#                 for k,v in deletion_overlapping_TFBS_AGI.items():\n",
    "#                     #print(np.unique(v).astype(list))\n",
    "#                     deletion_overlapping_TFBS_AGI[k] = np.unique(v).tolist()\n",
    "            \n",
    "#             if substitution_overlapping_TFBS_family == {}:\n",
    "#                 substitution_overlapping_TFBS_family = 'nan'\n",
    "#             else:\n",
    "#                 #keep only unique TFBS families\n",
    "#                 for k,v in substitution_overlapping_TFBS_family.items():\n",
    "#                     #print(np.unique(v).astype(list))\n",
    "#                     substitution_overlapping_TFBS_family[k] = np.unique(v).tolist()\n",
    "                    \n",
    "#             if substitution_overlapping_TFBS_AGI == {}:\n",
    "#                 substitution_overlapping_TFBS_AGI = 'nan'\n",
    "#             else:\n",
    "#                 #keep only unique TFBS AGIs\n",
    "#                 for k,v in substitution_overlapping_TFBS_AGI.items():\n",
    "#                     #print(np.unique(v).astype(list))\n",
    "#                     substitution_overlapping_TFBS_AGI[k] = np.unique(v).tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             mutations_df.loc[mutations_df_index, \"insertion_overlapping_TFBS_family\"] = str(insertion_overlapping_TFBS_family)\n",
    "#             mutations_df.loc[mutations_df_index, \"insertion_overlapping_TFBS_AGI\"]= str(insertion_overlapping_TFBS_AGI)\n",
    "#             mutations_df.loc[mutations_df_index, \"deletion_overlapping_TFBS_family\"]= str(deletion_overlapping_TFBS_family)\n",
    "#             mutations_df.loc[mutations_df_index, \"deletion_overlapping_TFBS_AGI\"]= str(deletion_overlapping_TFBS_AGI)\n",
    "#             mutations_df.loc[mutations_df_index, \"substitution_overlapping_TFBS_family\"]= str(substitution_overlapping_TFBS_family)\n",
    "#             mutations_df.loc[mutations_df_index, \"substitution_overlapping_TFBS_AGI\"]= str(substitution_overlapping_TFBS_AGI)\n",
    "#             # row.insertion_overlapping_TFBS_total_unique= insertion_overlapping_TFBS_total_unique\n",
    "#             # row.deletion_overlapping_TFBS_total_unique= deletion_overlapping_TFBS_total_unique\n",
    "#             # row.substitution_overlapping_TFBS_total_unique= substitution_overlapping_TFBS_total_unique\n",
    "#             #remove the buffer stream\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "#     #concatenate chunks into mutations_df\n",
    "#     # pd.concat(chunks, axis=1)            \n",
    "#     #write out mutations_df\n",
    "#     mutations_df.to_csv(f'{output_folder}{gene}_TFBSoverlapping.tsv', sep=\"\\t\", index=False, header=1)\n",
    "                     \n",
    "#     return mutations_df      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genotype_plant_lines(mutations_df,output_folder,gene):\n",
    "    \"\"\"function to decide whether each plant line is -homozygous \n",
    "    -biallelic - each mutated at same location/site twice\n",
    "    -chimeric - different mutations in different cells or tissues - dont analyse if chimeric - 1 small region, if more than 2 mutations then probably chimeric - ie.    probably still has tDNA\n",
    "    Multiple guide sites - eg. multiple agro strains in each plant. Check for paired guides and whether guides that arenâ€™t meant to be paired are paired.\n",
    "    \"\"\"\n",
    "    #homozygouslines are those with no duplicated guides in each plant line\n",
    "    mutations_df.loc[~mutations_df.duplicated(['plant_ID','guide']),'genotype'] = 'homozygous'\n",
    "    #biallelic\n",
    "    #N = 2\n",
    "    #mutations_df_copy = mutations_df[mutations_df.duplicated(['plant_ID','guide']) | mutations_df['count'].ge(N)]\n",
    "    #if 70% of reads or more are the same then mark as homozygous\n",
    "    mutations_df.loc[mutations_df.read_percentage >= 70, 'genotype'] = 'homozygous'\n",
    "    #if 10% of reads or less are that mutation, mark genotype as 'nan\n",
    "    mutations_df.loc[mutations_df.read_percentage <=10, 'genotype'] = 'nan'\n",
    "    #if between 10 and 70% of reads, mark genotype as heterozygous\n",
    "    mutations_df.loc[(mutations_df.read_percentage > 10) & (mutations_df.read_percentage < 70), 'genotype'] = 'heterozygous'\n",
    "\n",
    "    #create a count column\n",
    "    mutations_df['number_of_different_alleles'] = int()\n",
    "    #create non wild type count column\n",
    "    mutations_df['number_of_different_non_wt_alleles'] = int()\n",
    "    \n",
    "    #create a sum_of_count column\n",
    "    #mutations_df['sum_of_count'] = int()\n",
    "    #count how many duplicates there are for heterozygous lines.\n",
    "    mutations_df.loc[mutations_df.genotype == 'heterozygous','number_of_different_alleles'] = mutations_df[mutations_df.genotype == 'heterozygous'].groupby(['plant_ID','guide'])['number_of_different_alleles'].transform('count')\n",
    "    #make non wild type count\n",
    "    mutations_df.loc[(mutations_df.genotype == 'heterozygous')&~(mutations_df.mutation_type == 'None'),'number_of_different_non_wt_alleles'] = mutations_df[(mutations_df.genotype == 'heterozygous')&~(mutations_df.mutation_type == 'None')].groupby(['plant_ID','guide'])['number_of_different_non_wt_alleles'].transform('count')\n",
    "    #make count numeric\n",
    "    #mutations_df['count'] = mutations_df['count'].astype(int)\n",
    "    #print(mutations_df.dtypes)\n",
    "    #if heterozygous count is 1 then homozygous\n",
    "    mutations_df.loc[(mutations_df.genotype == 'heterozygous') & (mutations_df.number_of_different_alleles == 1),'genotype'] = 'homozygous'\n",
    "    #print(mutations_df.loc[(mutations_df.genotype == 'heterozygous') & (mutations_df.count == 1)])\n",
    "    #\n",
    "    #if homozygous then count is 1\n",
    "    mutations_df.loc[mutations_df.genotype == 'homozygous','number_of_different_alleles'] = 1\n",
    "\n",
    "    #if mutation_type is None, count is 0\n",
    "    #create mask for wildtype\n",
    "    # wt_mask = (mutations_df['mutation_type']=='None')\n",
    "    # mutations_df.loc[wt_mask, 'count'] = 0\n",
    "\n",
    "    #get the sum of the counts for each set of duplicates( wild type is 0, each mutation is counted as 1)\n",
    "    # sort=False, as_index=False\n",
    "\n",
    "   # mutations_df['sum_of_count'] = mutations_df.groupby(['plant_ID','guide'])['sum_of_count'].agg({\"count\":\"sum\"})\n",
    "    #print(mutations_df.groupby(['plant_ID','guide'],sort=False, as_index=False)['count'].agg({\"sum_of_count\":\"sum\"}))\n",
    "   # print(mutations_df.groupby(['plant_ID','guide'])['count'].transform('count'))\n",
    "\n",
    "\n",
    "\n",
    "    #if number_of_different_alleles is two and no wild type is present in either of the groups of reads then biallelic\n",
    "    mutations_df.loc[(mutations_df['number_of_different_non_wt_alleles']==2)&~(mutations_df.mutation_type == 'None'),'genotype'] = 'biallelic'\n",
    "    \n",
    "    #if number_of_different_alleles more than two then chimeric\n",
    "    mutations_df.loc[mutations_df['number_of_different_alleles']>2,'genotype'] = 'chimeric'\n",
    "\n",
    "    # reset count column\n",
    "    #filtered['count'] = filtered.groupby(['plant_ID','guide'])[['plant_ID','guide']].transform('count')\n",
    "\n",
    "    #df1.loc[df['count'] < N, 'count'] = 1\n",
    "    #mutations_df[mutations_df.duplicated('plant_ID','guide')]\n",
    "    #add plant\n",
    "    #print(mutations_df_copy)\n",
    "    #change column order\n",
    "    mutations_df = mutations_df[['chr', 'plant_ID', 'platename', 'library', 'first_reaction_primers',\n",
    "       'second_reaction_primers', 'guide', 'guide_number', 'aligned_sequence',\n",
    "       'reference_sequence', 'mutation_type','genotype', 'read_number', 'read_percentage',\n",
    "       'insertion_positions', 'deletion_positions', 'substitution_positions',\n",
    "       'insertion_cut_site_distance', 'deletion_cut_site_distance',\n",
    "       'substitution_cut_site_distance', 'cut_site_promoter_position',\n",
    "       'insertion_positions_relative_to_TSS', 'insertion_genomic_positions',\n",
    "       'deletion_positions_relative_to_TSS', 'deletion_genomic_positions',\n",
    "       'substitution_positions_relative_to_TSS',\n",
    "       'substitution_genomic_positions', 'insertion_overlapping_TFBS_family',\n",
    "       'insertion_overlapping_TFBS_AGI', 'deletion_overlapping_TFBS_family',\n",
    "       'deletion_overlapping_TFBS_AGI', 'substitution_overlapping_TFBS_family',\n",
    "       'substitution_overlapping_TFBS_AGI','number_of_different_alleles','number_of_different_non_wt_alleles'\n",
    "       ]]\n",
    "    #remove genotype 'nan'\n",
    "    mutations_df = mutations_df[~(mutations_df.genotype == 'nan')]\n",
    "    \n",
    "   \n",
    "   \n",
    "    #save df\n",
    "    mutations_df.to_csv(f'{output_folder}{gene}_TFBSoverlapping_categorised.tsv', sep=\"\\t\", index=False, header=1)\n",
    "\n",
    "    return mutations_df\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise_guide_pairs(mutations_df_genotyped, guide_pairs_df):\n",
    "    \"\"\"function to check which guide pairs where delivered to each plant line and to check whether mutations at more than one guide site are within the other guide pair\"\"\"\n",
    "    #first get unique guides based on 2 columns in guide_pairs_df\n",
    "    \n",
    "    unique_guides = pd.concat([guide_pairs_df['guide1'],guide_pairs_df['guide2']]).unique()\n",
    "    #for guides in unique guides list, add dictionary value of all other potential guides that it is paired with\n",
    "    #create defaultdict with lists as values so that non-existing keys can be added to in one go\n",
    "    guide_dict = defaultdict(list)\n",
    "    for guide in unique_guides:\n",
    "        #check for instances of that guide in the first column\n",
    "        filtered_col_1 = guide_pairs_df[guide_pairs_df.guide1==guide]['guide2'].to_list()\n",
    "        filtered_col_2 = guide_pairs_df[guide_pairs_df.guide2==guide]['guide1'].to_list()\n",
    "\n",
    "        #then do the same for the second column\n",
    "        guide_dict[guide] = np.unique((filtered_col_1 + filtered_col_2)).astype(list)\n",
    "        print(guide_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/Variant_call'\n",
    "# ARF9_root = f'{folder}/ARF9_sgRNAs/test'\n",
    "# ARF18_root = f'{folder}/ARF18_sgRNAs/7bp_window_noplots'\n",
    "# DREB26_root = f'{folder}/DREB26_sgRNAs/7bp_window_noplots'\n",
    "# NLP7_root = f'{folder}/NLP7_sgRNAs/7bp_window_noplots'\n",
    "# output = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/Variant_call/'\n",
    "# #dictionary of reference fasta file locations\n",
    "# reference_folder = '../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/References'\n",
    "# reference_gene_dict = {'ARF9':f'{reference_folder}/ARF9_promoter.fa','ARF18':f'{reference_folder}/ARF18_promoter.fa','DREB26':f'{reference_folder}/DREB26_promoter.fa','NLP7':f'{reference_folder}/NLP7_promoter.fa'}\n",
    "# reference_fasta = f'{reference_folder}/genes_longest_region.fa'\n",
    "# reference_promoter_bed = f'{reference_folder}/genes_longest_region.bed'\n",
    "# #promoters bed file when 3' end is the TSS (used the bed file from promoter architecture non-overlapping_includingbidirectional_all_genes_newannotation project FIMO folder)\n",
    "# all_promoters_bed = f'{reference_folder}/promoters.bed'\n",
    "# #mapped motif bed file of TFBSs scanned with FIMO\n",
    "# mapped_motifs_bed = '../../data/output/non-overlapping_includingbidirectional_all_genes_newannotation_3KB/FIMO/promoters_5UTR_motifs_mapped_q0_05.bed'\n",
    "# plant_IDs = f'{reference_folder}/plant_IDs.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_motifs_bed = '../../data/output/non-overlapping_includingbidirectional_all_genes_newannotation_3KB/FIMO/promoters_5UTR_motifs_mapped_q0_05.bed'\n",
    "mutations_ARF9 = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/Variant_call/ARF9_merged.tsv'\n",
    "mutations_ARF18 = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/Variant_call/ARF18_merged.tsv'\n",
    "mutations_DREB26 = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/Variant_call/DREB26_merged.tsv'\n",
    "mutations_NLP7 = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/Variant_call/NLP7_merged.tsv'\n",
    "output_folder = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/Variant_call/'\n",
    "guide_pairs = f'../../data/CRISPR_library/pacbio/demultiplexed/Data_Package_Batch_04_04_2022/Sam_Witham_EI_SW_ENQ-5142_A_01_Additional_Barcode_Analysis/References/all_guide_pairs.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in files\n",
    "mutations_ARF9_df,mapped_motifs_df,guide_pairs_df =  read_in_files(mutations_ARF9, mapped_motifs_bed, guide_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations_df = find_overlapping_TFBSs(mutations_ARF9_df,mapped_motifs_df,output_folder,'ARF9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/witham/opt/anaconda3/envs/pybedtools/lib/python3.9/site-packages/pandas/core/indexing.py:2115: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  new_ix = Index(new_ix)\n",
      "/home/witham/opt/anaconda3/envs/pybedtools/lib/python3.9/site-packages/pandas/core/indexing.py:2115: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  new_ix = Index(new_ix)\n"
     ]
    }
   ],
   "source": [
    "mutations_df_genotyped = genotype_plant_lines(mutations_df,output_folder,'ARF9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'unique'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/pacbio_analyse_overlapping_TFBSs.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/pacbio_analyse_overlapping_TFBSs.ipynb#ch0000013?line=0'>1</a>\u001b[0m categorise_guide_pairs(mutations_df_genotyped,guide_pairs_df)\n",
      "\u001b[1;32m/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/pacbio_analyse_overlapping_TFBSs.ipynb Cell 8'\u001b[0m in \u001b[0;36mcategorise_guide_pairs\u001b[0;34m(mutations_df_genotyped, guide_pairs_df)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/pacbio_analyse_overlapping_TFBSs.ipynb#ch0000007?line=11'>12</a>\u001b[0m filtered_col_2 \u001b[39m=\u001b[39m guide_pairs_df[guide_pairs_df\u001b[39m.\u001b[39mguide2\u001b[39m==\u001b[39mguide][\u001b[39m'\u001b[39m\u001b[39mguide1\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto_list()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/pacbio_analyse_overlapping_TFBSs.ipynb#ch0000007?line=13'>14</a>\u001b[0m \u001b[39m#then do the same for the second column\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/pacbio_analyse_overlapping_TFBSs.ipynb#ch0000007?line=14'>15</a>\u001b[0m guide_dict[guide] \u001b[39m=\u001b[39m (filtered_col_1 \u001b[39m+\u001b[39;49m filtered_col_2)\u001b[39m.\u001b[39;49munique()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/witham/Documents/pipeline_new/PromoterArchitecture/src/CRISPR_library/pacbio_analyse_overlapping_TFBSs.ipynb#ch0000007?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(guide_dict)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'unique'"
     ]
    }
   ],
   "source": [
    "categorise_guide_pairs(mutations_df_genotyped,guide_pairs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2879a2396fb26a2192d4c546fae66e67014459dff7902256699e5c7228156d44"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pybedtools')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2879a2396fb26a2192d4c546fae66e67014459dff7902256699e5c7228156d44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
