{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from matplotlib import rcParams\n",
    "from statannotations.Annotator import Annotator\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy import stats\n",
    "rcParams.update({'figure.autolayout': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to read in csv file as pandas df\n",
    "def read_csv(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    #keep the Well, Sample, Target, Cq and Amp Status columns\n",
    "    df = df[['Well', 'Sample', 'Target', 'Cq', 'Amp Status']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #returns test statistic, p-value\n",
    "# for name1 in prom_names_plate1:\n",
    "#     for name in names_plate1:\n",
    "#         print(name1,'{}: {}'.format(name, stats.shapiro(luminescence_raw_df_plate1['nluc/fluc'][luminescence_raw_df_plate1.TF_added == name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for normality of the data\n",
    "def test_normality(df, location):\n",
    "    \"\"\"run Shapiro-Wilk test\"\"\"\n",
    "    #iterate over rows\n",
    "    #get sample names\n",
    "    sample_names = df['Sample'].unique()\n",
    "    #get Target names\n",
    "    target_names = df['Target'].unique()\n",
    "    #iterate over samples and targets\n",
    "    #make empty df to store p-values\n",
    "    p_values = pd.DataFrame(columns=['Sample', 'Target', 'pvalue'])\n",
    "    for sample in sample_names:\n",
    "        for target in target_names:\n",
    "            # #run Shapiro-Wilk test\n",
    "           # print(sample,'{}: {}'.format(target, stats.shapiro(df['relative_expression'][df.Target == target])))\n",
    "            #write a df with the results of the Shapiro-Wilk test\n",
    "            #shapiro_df = pd.DataFrame(columns=['Sample', 'Target', 'p-value'])\n",
    "            #results = sample,target,'{}'.format(stats.shapiro(df['relative_expression'][df.Target == target]))\n",
    "            results = sample,target,stats.shapiro(df['relative_expression'][df.Target == target])\n",
    "            #('125-4', 'NLP7: ShapiroResult(statistic=0.707939088344574, pvalue=9.890874935081229e-05)')\n",
    "            shapiro_df = pd.DataFrame([results], columns=['Sample','Target', 'shapiro_test']).reset_index(drop=True)\n",
    "            #get statistic and pvalue\n",
    "            shapiro_df['statistic'] = shapiro_df['shapiro_test'].apply(lambda x: x[0])\n",
    "            shapiro_df['pvalue'] = shapiro_df['shapiro_test'].apply(lambda x: x[1])\n",
    "            #filter columns\n",
    "            shapiro_df = shapiro_df[['Sample', 'Target', 'pvalue', 'statistic',]]\n",
    "            #append to p_values df\n",
    "            p_values = pd.concat([p_values, shapiro_df], axis=0, ignore_index=True)\n",
    "\n",
    "    #write to tsv\n",
    "    p_values.to_csv(f'{location}/shapiro_normality.tsv', sep='\\t', index=False)\n",
    "\n",
    "    return p_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to filter out certain data points\n",
    "def filter_data(df, amp_status, cq):\n",
    "    #filter out the data points with amp_status = Amp using .loc\n",
    "    df = df.loc[df['Amp Status'] == amp_status]\n",
    "    #make Cq column numerical\n",
    "    dfcopy = df.copy()\n",
    "    dfcopy['Cq'] = pd.to_numeric(dfcopy['Cq'])  \n",
    "    #filter out the data points with cq < cq_threshold using .loc\n",
    "    dfcopy = dfcopy.loc[dfcopy['Cq'] <= cq]\n",
    "\n",
    "    return dfcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idea from https://www.nature.com/articles/s41598-021-99727-6#Sec2\n",
    "#To detect outliers, the CT standard deviation (Cq-SD) of the technical replicates for a given sample is calculated, if the Cq-SD is greater than the cut-off (the default value is 0.3), then the technical replicate furthest from the sample mean is removed. The process occurs recursively until the Cq-SD is less than the cut-off or the value of “max outliers” is reached. This is determined by the parameter ‘Max Proportion’, the 0.5 default means that outliers will be removed until two technical replicates remain. The ‘preserve highly variable replicates’: If the Cq-SD is higher than 0.3, but the absolute (mean-median)/median is less than 0.1, replicates are preserved. This helps to account for a lack of a clear outlier, where two of three replicates are close to equally distributed around the mean.\n",
    "def remove_outliers(df, max_outliers, ct_sd_threshold):\n",
    "    \n",
    "    #copy the dataframe\n",
    "    dfcopy = df.copy()\n",
    "    # Add filter columns\n",
    "    dfcopy['Ignore'] = False\n",
    "    #dfcopy['Cq-SD'] = int()\n",
    "    \n",
    "    #make Cq column numerical\n",
    "    dfcopy['Cq'] = pd.to_numeric(dfcopy['Cq'])\n",
    "    #calculate the Cq-SD of the technical replicates for a given sample\n",
    "    f = (dfcopy['Ignore'].eq(False))\n",
    "    dfcopy1 = dfcopy[f].groupby(['Sample','Target']).agg({'Cq':['std']})\n",
    "    #dfcopy = dfcopy[f].groupby(['Sample','Target']).agg({'Cq-SD':['std']})#['Cq'].transform(lambda x: x.std() / np.sqrt(x.count()))\n",
    "    #make df containing all samples with outliers\n",
    "    f = dfcopy1['Cq']['std'] > ct_sd_threshold\n",
    "    dfcopy_outliers = dfcopy1[f]\n",
    "\n",
    "    \n",
    "    # dfcopy_outliers = dfcopy[dfcopy['Cq-SD'] > ct_sd_threshold]\n",
    "    if not dfcopy_outliers.empty:\n",
    "        #mark all outliers\n",
    "        #iterate over rows as tuples (sample, target)\n",
    "        for i, row in enumerate(dfcopy_outliers.itertuples(name = None),1):\n",
    "            #example row: (('144-5AH', 'DREB26'), 0.6497278066418295)\n",
    "         \n",
    "           \n",
    "            #check that the dfcopy sample name is the same as the sample name in the current row\n",
    "            f = (dfcopy.Sample == row[0][0]) & (dfcopy.Target == row[0][1]) & (dfcopy['Ignore'].eq(False))\n",
    "            dx_idx = dfcopy[f].index\n",
    "            group_size = len(dx_idx)\n",
    "            min_size = round(group_size * (1-max_outliers))\n",
    "            size = group_size\n",
    "            if min_size < 2:\n",
    "                min_size = 2\n",
    "                print('Warning: minimum size of technical replicate group is 2')\n",
    "            while True:\n",
    "                f = (dfcopy.Sample == row[0][0]) & (dfcopy.Target == row[0][1])\n",
    "                dx = dfcopy[f].copy()\n",
    "                dxg = dfcopy[f].groupby(['Sample', 'Target']).agg({'Cq': [np.size, 'std', 'mean']})\n",
    "                if dxg['Cq']['std'].iloc[0] <= ct_sd_threshold:\n",
    "                    #Cq std is under threshold, so no outliers\n",
    "                    break\n",
    "                size -= 1\n",
    "                if size < min_size:\n",
    "                    #not enough technical replicates to remove outliers\n",
    "                    break\n",
    "                #remove the technical replicate furthest from the mean\n",
    "                dx['Distance'] = (dx['Cq'] - dxg['Cq']['mean'].iloc[0])**2\n",
    "                dx_sorted = dx.sort_values(by = 'Distance', ascending=False).index[0]\n",
    "                #print()\n",
    "                #dfcopy = dfcopy.loc[dx_sorted].assign(Ignore=True)\n",
    "                #dfcopy.loc[dx_sorted].loc(:, 'Ignore') = True\n",
    "                #print(dx_sorted)\n",
    "                dfcopy.loc[[dx_sorted], 'Ignore'] = True\n",
    "                #dfcopy['Ignore'].loc[dx_sorted] = True\n",
    "                #rint(dx_sorted)\n",
    "                \n",
    "    return dfcopy\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "   \n",
    "    # #remove the highly variable replicates\n",
    "    # if preserve_highly_variable_replicates == True:\n",
    "    #     dfcopy = dfcopy.loc[dfcopy['Cq-SD'] > ct_sd_threshold]\n",
    "    #     dfcopy = dfcopy.loc[dfcopy['Cq-SD'] < (dfcopy['Cq-SD'].mean() - dfcopy['Cq-SD'].median())/dfcopy['Cq-SD'].median()]\n",
    "    # #remove the outliers until the number of outliers is less than max_outliers\n",
    "    # while dfcopy['Cq-SD'].count() > max_outliers:\n",
    "    #     dfcopy = dfcopy.loc[dfcopy['Cq-SD'] < ct_sd_threshold]\n",
    "    #     if preserve_highly_variable_replicates == True:\n",
    "    #         dfcopy = dfcopy.loc[dfcopy['Cq-SD'] > ct_sd_threshold]\n",
    "    #         dfcopy = dfcopy.loc[dfcopy['Cq-SD'] < (dfcopy['Cq-SD'].mean() - dfcopy['Cq-SD'].median())/dfcopy['Cq-SD'].median()]\n",
    "    # return dfcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to make new columns and sort the data\n",
    "def sort_data(df, location):\n",
    "    #make new column called EF1a_Cq, make the value in this column for a particular sample equal to the Cq value for the EF1a Target for that sample\n",
    "    ##remove if not amplified\n",
    "    df = df.loc[df['Amp Status'] == 'Amp']\n",
    "\n",
    "    #first remove outliers\n",
    "    df = remove_outliers(df, 0.5, 0.3)\n",
    "    #save outliers df to tsv\n",
    "    df.to_csv(f'{location}/including_outliers.tsv', sep='\\t', index=False)\n",
    "    #remove outliers\n",
    "    df = df.loc[df['Ignore'] == False]    \n",
    "    #get the mean of each sample/target (take mean of technical replicates)\n",
    "    df['Cq_mean'] = df.groupby(['Sample','Target'])['Cq'].transform('mean')\n",
    "    #make a df containing only EF1a target (housekeeping gene)\n",
    "    df_EF1a = df.loc[df['Target'] == 'EF1a'].copy()\n",
    "\n",
    "    #rename the Cq_mean column to EF1a_Cq_mean\n",
    "    df_EF1a.rename(columns={'Cq_mean': 'EF1a_Cq_mean'}, inplace=True)\n",
    "    #filter other df_EF1a columns\n",
    "    df_EF1a = df_EF1a[['Sample','EF1a_Cq_mean']]\n",
    "    #remove duplicates from df_EF1a\n",
    "    df_EF1a = df_EF1a.drop_duplicates()\n",
    "    \n",
    "    #merge the two dfs together\n",
    "    df = pd.merge(df, df_EF1a, on=['Sample'], how='left')\n",
    "\n",
    "    #normalise based on eEF1a gene\n",
    "    df = normalise_data(df, 'Cq_mean','EF1a_Cq_mean','MeanCq_ECnormalised')\n",
    "    #filter columns\n",
    "    df = df[['Sample','Target','Cq_mean','MeanCq_ECnormalised']]\n",
    "    #remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "   \n",
    "   # print(df)\n",
    "    #if Sample column ends with NRT, add NRT_Cq column\n",
    "    df['NRT'] = False\n",
    "    df.loc[df['Sample'].str.endswith('NRT'), 'NRT'] = True\n",
    "    #remove NRT string from Sample columns ending with NRT\n",
    "    df['Sample'] = df['Sample'].str.replace('NRT', '')\n",
    "    \n",
    "    #if Sample column ends with H, add condition column with 10mM_nitrate\n",
    "    df['condition'] = np.nan\n",
    "    df.loc[df['Sample'].str.endswith('H'), 'condition'] = '10mM_nitrate'\n",
    "    #remove H string from Sample columns ending with H\n",
    "    df['Sample'] = df['Sample'].str.replace('H', '')\n",
    "\n",
    "    #if Sample column ends with L, add condition column with 1mM_nitrate\n",
    "    df.loc[df['Sample'].str.endswith('L'), 'condition'] = '1mM_nitrate'\n",
    "    #remove L string from Sample columns ending with L\n",
    "    df['Sample'] = df['Sample'].str.replace('L', '')\n",
    "    #remove A, B or C string from Sample columns ending with A, B or C\n",
    "    df.loc[:, 'Sample_old'] = df['Sample']\n",
    "    df['Sample'] = df['Sample'].str.replace('A', '')\n",
    "    df['Sample'] = df['Sample'].str.replace('B', '')\n",
    "    df['Sample'] = df['Sample'].str.replace('C', '')\n",
    "    #remove whitespace from Sample columns\n",
    "    df['Sample'] = df['Sample'].str.strip()\n",
    " \n",
    "    #now make a df containing only Samples with 1mM_nitrate condition\n",
    "    df_1mM_nitrate = df.loc[df['condition'] == '1mM_nitrate'].copy()\n",
    "\n",
    "    #make new column that is the Mean expression across all biological replicates\n",
    "    df_1mM_nitrate['Mean_biological_Cq_ECnormalised'] = df_1mM_nitrate.groupby(['Sample','Target', 'condition'])['MeanCq_ECnormalised'].transform('mean')\n",
    "\n",
    "\n",
    "    #rename Mean_biological_Cq_ECnormalised column to 1mMnitrate_Cq_mean\n",
    "    df_1mM_nitrate.rename(columns={'Mean_biological_Cq_ECnormalised': '1mMnitrate_Cq_mean'}, inplace=True)\n",
    "    #filter other columns\n",
    "    df_1mM_nitrate = df_1mM_nitrate[['Sample_old','Target','1mMnitrate_Cq_mean']]\n",
    "    #remove duplicates from df_1mM_nitrate\n",
    "    df_1mM_nitrate = df_1mM_nitrate.drop_duplicates()\n",
    "    #merge the dfs\n",
    "    df = pd.merge(df, df_1mM_nitrate, on=['Sample_old','Target'], how='left')\n",
    "\n",
    "    \n",
    "\n",
    "    #remove nan\n",
    "    df = df.dropna()\n",
    "\n",
    "    #remove NRT values\n",
    "    df = df.loc[df['NRT'] == False]\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to normalise the data based on a column of Cq values (either to housekeeping or based on nitrate or wild type plant)\n",
    "def normalise_data(df, orig_col,normalisation_col, new_column_name):\n",
    "   \n",
    "    #normalise Cq values to the EF1a housekeeping gene mean Cq value for each sample\n",
    "    df.loc[:,new_column_name] = df[orig_col] - df[normalisation_col]\n",
    "    #remove nan values in the new column\n",
    "    df = df[df[new_column_name].notna()]\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make individual plots\n",
    "def make_plots(df,location, normal):\n",
    "    \"\"\"function to make barplots of relative expression of each target gene in each plant line\"\"\"\n",
    "    #plot height and width\n",
    "    height = 5\n",
    "    width = 2.4\n",
    "\n",
    "    #decide on stats test\n",
    "    if normal is True:\n",
    "        stats_test = 't-test_ind'\n",
    "    if normal is False:\n",
    "        stats_test = 't-test_welch'\n",
    "\n",
    "\n",
    "    #make individual plots\n",
    "    \n",
    "    \n",
    "    for plantline in df['Sample'].unique():\n",
    "        temp_df =  df[df.Sample == plantline]\n",
    "        for target in temp_df['Target'].unique():\n",
    "            #if target is not EF1a, make plot\n",
    "            if target != 'EF1a':            \n",
    "                new_temp_df = temp_df[temp_df.Target == target]\n",
    "                #change condition values\n",
    "                new_temp_df.loc[new_temp_df['condition'] == '10mM_nitrate', 'condition'] = '10'\n",
    "                new_temp_df.loc[new_temp_df['condition'] == '1mM_nitrate', 'condition'] = '1'\n",
    "\n",
    "                order = ['1','10']\n",
    "                #create box pairs\n",
    "                pair = [('1', '10')]\n",
    "\n",
    "                #make plot \n",
    "                _ = plt.figure(figsize=(width,height))\n",
    "                fig = sns.barplot(x='condition', y='relative_expression', data=new_temp_df, order=order, linewidth=2,  errcolor=\"black\", edgecolor=\"black\", ci=68, errwidth=1,capsize=0.4,color='cyan')\n",
    "\n",
    "                fig = sns.swarmplot(x='condition', y='relative_expression', data=new_temp_df, order=order,color='black')\n",
    "\n",
    "                #add stats\n",
    "                annotator = Annotator(fig, pair, data=new_temp_df, x='condition', y='relative_expression',order=order,verbose=False)\n",
    "                annotator.configure(test=stats_test, text_format='star',pvalue_thresholds=[[1e-3, \"***\"],[1e-2, \"**\"],[0.05, \"*\"],[1, \"ns\"]])\n",
    "                \n",
    "                #save stats to file\n",
    "                ax, test_results = annotator.apply_and_annotate()\n",
    "                with open(f'{location}/individual/stats.txt', 'a') as f:                            \n",
    "                    for res in test_results:\n",
    "                        f.write(f'{str(plantline)},{target},{pair},{str(res.data)}\\n')\n",
    "                \n",
    "                # change axes labels\n",
    "                _ = plt.ylabel('Relative expression (a.u.)')\n",
    "                \n",
    "                \n",
    "                #add plot title\n",
    "                _ = plt.title(f'{plantline} {target}')\n",
    "\n",
    "                #rename x axis labels\n",
    "                #_ = plt.set_xticklabels( ('1','10') )\n",
    "                #change x axis name\n",
    "                _ = plt.xlabel('Nitrate concentration (mM)')\n",
    "        \n",
    "                #make xticks diagonal\n",
    "               # _ = plt.xticks(rotation=90, ha='center')\n",
    "\n",
    "\n",
    "                #save plot to file\n",
    "                plt.savefig(\n",
    "                                f'{location}/individual/{plantline}_{target}.pdf',\n",
    "                                format=\"pdf\",\n",
    "                                bbox_inches=\"tight\",transparent=True)\n",
    "                plt.savefig(\n",
    "                                f'{location}/individual/{plantline}_{target}.svg',\n",
    "                                format=\"svg\",\n",
    "                                bbox_inches=\"tight\",transparent=True)\n",
    "                plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make combined plots with all samples\n",
    "def make_combined_plots(df,location, normal):\n",
    "    \"\"\"function to make barplots of relative expression of each target gene in each plant line on the same axes\"\"\"\n",
    "    #plot height and width\n",
    "    height = 5\n",
    "    bar_width = 0.3\n",
    "    #decide on stats test\n",
    "    if normal is True:\n",
    "        stats_test = 't-test_ind'\n",
    "    if normal is False:\n",
    "        stats_test = 't-test_welch'\n",
    "\n",
    "    #set width of bars\n",
    "    def change_width(ax, new_value) :\n",
    "        for patch in ax.patches :\n",
    "            current_width = patch.get_width()\n",
    "            diff = current_width - new_value\n",
    "            # we change the bar width\n",
    "            patch.set_width(new_value)\n",
    "            # we recenter the bar\n",
    "            patch.set_x(patch.get_x() + diff * .5)\n",
    "\n",
    "    for target in df['Target'].unique():\n",
    "            #if target is not EF1a, make plot\n",
    "            if target != 'EF1a':\n",
    "                temp_df = df[df.Target == target]\n",
    "                #change condition values\n",
    "                temp_df.loc[temp_df['condition'] == '10mM_nitrate', 'condition'] = '10'\n",
    "                temp_df.loc[temp_df['condition'] == '1mM_nitrate', 'condition'] = '1'\n",
    "\n",
    "                #get list of samples\n",
    "                samples_unique = temp_df['Sample'].unique()\n",
    "\n",
    "                #sample order\n",
    "                sample_order = ['col-0','125-4','130-4','142-4','142-8','144-5']\n",
    "\n",
    "                #sort based on custom order\n",
    "                samples = []\n",
    "                for i in range(len(sample_order)):\n",
    "                    if sample_order[i] in samples_unique:\n",
    "                        samples+=[sample_order[i]]\n",
    "\n",
    "                #get length of number of samples\n",
    "                length_samples = len(samples)\n",
    "\n",
    "                #create order and box pairs based on the length of TFs\n",
    "                order = []\n",
    "                box_pairs = []\n",
    "                for x in range (0, (length_samples)):\n",
    "                    order.append(samples[x])\n",
    "                    # if 'col-0' in samples:\n",
    "                    #     if samples[x] != 'col-0':\n",
    "                    #         box_pairs.append(('col-0', samples[x]))\n",
    "                    # if 'col-0' not in samples:\n",
    "                    box_pairs.append(((samples[x],'1'), (samples[x],'10')))\n",
    "\n",
    "\n",
    "                fig_args = {'x':'Sample', 'y':'relative_expression','hue':'condition', 'hue_order':['1','10'],'data':temp_df, 'order':order, 'dodge':True}\n",
    "                #'linewidth':2,  'errcolor':\"black\", 'edgecolor':\"black\", 'ci':68, 'errwidth':1,'capsize':0.4\n",
    "\n",
    "                configuration = {'test':stats_test, 'text_format':'star', 'pvalue_thresholds':[[1e-3, \"***\"],[1e-2, \"**\"],[0.05, \"*\"],[1, \"ns\"]]}\n",
    "\n",
    "\n",
    "                #make plot              \n",
    "                \n",
    "                _ = plt.figure(figsize=((3+(length_samples-1)*2),height))\n",
    "                \n",
    "                #_ = plt.figure(figsize=(width,height))\n",
    "                fig = sns.barplot(**fig_args, color='cyan',linewidth=2,  errcolor=\"black\", edgecolor=\"black\", ci=68, errwidth=1,capsize=0.4)\n",
    "                fig = sns.swarmplot(**fig_args, color='black')\n",
    "\n",
    "                #set width of bars\n",
    "                change_width(fig, bar_width)\n",
    "\n",
    "                # #add stats\n",
    "                annotator = Annotator(fig, box_pairs, **fig_args,verbose=False)\n",
    "                annotator.configure(**configuration)\n",
    "\n",
    "\n",
    "                # fig = sns.barplot(x='Sample', y='relative_expression',hue='condition', data=temp_df, order=order, linewidth=2,  errcolor=\"black\", edgecolor=\"black\", ci=68, errwidth=1,capsize=0.4,color='cyan')\n",
    "\n",
    "                # fig = sns.swarmplot(x='Sample', y='relative_expression',hue='condition', data=temp_df, order=order,color='black')\n",
    "\n",
    "                #add stats\n",
    "                # annotator = Annotator(fig, pair, data=temp_df, x='Sample', y='relative_expression',order=order,verbose=False)\n",
    "                # annotator.configure(test='t-test_ind', text_format='star',pvalue_thresholds=[[1e-3, \"***\"],[1e-2, \"**\"],[0.05, \"*\"],[1, \"ns\"]])\n",
    "                \n",
    "                #save stats to file\n",
    "                ax, test_results = annotator.apply_and_annotate()\n",
    "                # with open(f'{location}/targets/stats.txt', 'a') as f:                            \n",
    "                #     for res in test_results:\n",
    "                #         f.write(f'{target}',f'{box_pairs},{str(res.data)}\\n')\n",
    "                \n",
    "                # change axes labels\n",
    "                _ = plt.ylabel('Relative expression (a.u.)')\n",
    "                \n",
    "                \n",
    "                #add plot title\n",
    "                _ = plt.title(f'{target}')\n",
    "\n",
    "                #rename x axis labels\n",
    "                #_ = plt.set_xticklabels( ('1','10') )\n",
    "                #change x axis name\n",
    "                _ = plt.xlabel('Nitrate concentration (mM)')\n",
    "        \n",
    "                #make xticks diagonal\n",
    "                _ = plt.xticks(rotation=45, ha='center')\n",
    "\n",
    "               #plot legend, excluding legend from swarm plot\n",
    "                h,l = fig.get_legend_handles_labels()\n",
    "                #change name of label\n",
    "                l[3] = \"10 mM nitrate\"\n",
    "                #l[2] = \"20 mM KNO\\u2083 + 20 mM NH\\u2083NO\\u2083\"   \n",
    "                l[2] = \"1 mM nitrate\"     \n",
    "                plt.legend(h[2:4],l[2:4],bbox_to_anchor=(0.3,0.87), loc='lower left',fontsize=10)\n",
    "\n",
    "                # tight layout\n",
    "                #plt.tight_layout()\n",
    "\n",
    "\n",
    "                #save plot to file\n",
    "                plt.savefig(\n",
    "                                f'{location}/targets/{target}.pdf',\n",
    "                                format=\"pdf\",\n",
    "                                bbox_inches=\"tight\",transparent=True)\n",
    "                plt.savefig(\n",
    "                                f'{location}/targets/{target}.svg',\n",
    "                                format=\"svg\",\n",
    "                                bbox_inches=\"tight\",transparent=True)\n",
    "                plt.close()        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set matplotlib rc parameters\n",
    "def set_rc_params():\n",
    "    #set matplotlib default parameters\n",
    "    rcParams['xtick.major.width'] = 2\n",
    "    rcParams['ytick.major.width'] = 2\n",
    "    rcParams['axes.linewidth'] = 2\n",
    "    #rcParams['lines.linewidth'] = 2\n",
    "    #remove top and right lines\n",
    "    rcParams['axes.spines.top'] = False\n",
    "    rcParams['axes.spines.right'] = False\n",
    "    #font size\n",
    "    fontsize = 14\n",
    "    rcParams['font.size'] = fontsize\n",
    "    #for getting the microsoft font Arial working, please follow this guide: https://alexanderlabwhoi.github.io/post/2021-03-missingfont/\n",
    "    rcParams['font.family'] = 'sans-serif'\n",
    "    rcParams['font.sans-serif'] = ['Arial']\n",
    "    #allow font to be edited later in pdf editor\n",
    "    #make svg text editable\n",
    "    rcParams['svg.fonttype'] = 'none'\n",
    "    rcParams ['pdf.fonttype'] = 42 \n",
    "    #align y-axis top most tick with end of axis\n",
    "    rcParams['axes.autolimit_mode'] = 'round_numbers'\n",
    "    #set margins to ensure any error bars fit\n",
    "    rcParams['axes.xmargin'] = 0.2\n",
    "    rcParams['axes.ymargin'] = 0.2\n",
    "    #define bar width\n",
    "    #bar_width = 0.65\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\" function\n",
    "def main():\n",
    "    location = '../../data/CRISPR_library/qPCR/10.08.22'\n",
    "    csv_file = f'{location}/10.8.22_platelayout_19310threshold.csv'\n",
    "    #read in file\n",
    "    df = read_csv(csv_file)\n",
    "    #filter out the data points with amp_status = Amp and cq above 32\n",
    "    df = filter_data(df, 'Amp', 40)\n",
    "    #sort the data\n",
    "    df = sort_data(df,location)\n",
    "    #make copy of df\n",
    "    df_norm_lowest_sample = df.copy()\n",
    "    #normalise based on 1mM_nitrate Cq values, mean between all 3 biological reps \n",
    "    df = normalise_data(df, 'MeanCq_ECnormalised','1mMnitrate_Cq_mean','MeanCq_EC_1mM_nitrate_normalised')\n",
    "    #now filter columns\n",
    "    df = df[['Sample','Target','MeanCq_EC_1mM_nitrate_normalised','condition']]\n",
    "    #now filter columns\n",
    "    #df = df[['Sample','Target','MeanCq_ECnormalised','condition']]\n",
    "    #first do inverse log transformation\n",
    "    #(fold change of GOI in treated sample if delta delta Ct value  = X then relative expression  = 2 ( to the power of X))\n",
    "    #df['relative_expression'] = 2**(df['MeanCq_ECnormalised'])\n",
    "    df['relative_expression'] = 2**(df['MeanCq_EC_1mM_nitrate_normalised'])\n",
    "    #save df to tsv\n",
    "    df.to_csv('../../data/CRISPR_library/qPCR/10.8.22_platelayout_19310threshold_normEC1mMnitrate_relative_expression.tsv', sep='\\t', index=False)\n",
    "\n",
    "    #now normalise the df_norm_lowest_sample to the sample with the lowest MeanCq_ECnormalised value\n",
    "    \n",
    "    #get sample with lowest MeanCq_ECnormalised value that isn't equal to 0\n",
    "    #remove all MeanCq_ECnormalised values equal to 0\n",
    "    df_norm_nozeroes = df_norm_lowest_sample[df_norm_lowest_sample['MeanCq_ECnormalised'] != 0]\n",
    "    #get lowest MeanCq_ECnormalised value in df_norm_lowest_sample\n",
    "    lowest_mean_cq = df_norm_nozeroes['MeanCq_ECnormalised'].min()\n",
    "    lowest_mean_cq_sample = df_norm_nozeroes[df_norm_nozeroes['MeanCq_ECnormalised'] == lowest_mean_cq].iloc[0]['Sample']\n",
    "    print(f'lowestmeancq={lowest_mean_cq}')\n",
    "    print(f'normalising to lowest mean cq sample: {lowest_mean_cq_sample}')\n",
    "    #normalise df_norm_lowest_sample to lowest mean cq sample\n",
    "    df_norm_lowest_sample.loc[:,'MeanCq_EClowestsample'] = df_norm_lowest_sample['MeanCq_ECnormalised'] - lowest_mean_cq\n",
    "    #remove nan values in the new column\n",
    "    df_norm_lowest_sample = df_norm_lowest_sample[df_norm_lowest_sample['MeanCq_EClowestsample'].notna()]\n",
    "\n",
    "    #do inverse log transformation\n",
    "    df_norm_lowest_sample['relative_expression'] = 2**(df_norm_lowest_sample['MeanCq_EClowestsample'])\n",
    "    #save df to tsv\n",
    "    df_norm_lowest_sample.to_csv('../../data/CRISPR_library/qPCR/10.8.22_platelayout_19310threshold_normEClowest_sample_relative_expression.tsv', sep='\\t', index=False)\n",
    "\n",
    "    #create plot folder name\n",
    "    #make directory for the plots to be exported to\n",
    "    dirName = f'{location}/plots'\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir(dirName)\n",
    "        print(\"Directory \" , dirName ,  \" created\") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , dirName ,  \" already exists\")\n",
    "\n",
    "\n",
    "    dirName = f'{location}/plots/individual'\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir(dirName)\n",
    "        print(\"Directory \" , dirName ,  \" created\") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , dirName ,  \" already exists\")\n",
    "\n",
    "        dirName = f'{location}/plots/targets'\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir(dirName)\n",
    "        print(\"Directory \" , dirName ,  \" created\") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , dirName ,  \" already exists\")\n",
    "\n",
    "\n",
    "    #save df to csv\n",
    "    df.to_csv(f'{location}/mean_normalised.csv')\n",
    "\n",
    "\n",
    "    #set matplotlib rc parameters\n",
    "    set_rc_params()\n",
    "\n",
    "    #test for normality of data - Shapiro-Wilk test\n",
    "    #test_normality(df)\n",
    "    normality = test_normality(df_norm_lowest_sample, location)\n",
    "\n",
    "    #check if any of the p values are less than 0.05 (not normal)\n",
    "    significant = normality[normality['pvalue'] < 0.05]\n",
    "    if significant.empty:\n",
    "        print('all p values are greater than 0.05, data is normal, using independent t-test')\n",
    "        normal = True\n",
    "    if not significant.empty:\n",
    "        print('some p values are less than 0.05, data is not normal, using welchs t-test')\n",
    "        normal = False\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    #make plots\n",
    "    #individual plots\n",
    "    make_plots(df,f'{location}/plots', normal)\n",
    "    #combined plots\n",
    "    make_combined_plots(df_norm_lowest_sample,f'{location}/plots', normal)\n",
    "\n",
    "    #print(df)\n",
    "    #print(df)\n",
    "    #print(df[df.NRT==True])\n",
    "    # normalised_housekeeping = normalise_data(df, 'EF1a')\n",
    "    # print(normalised_housekeeping)\n",
    "    #normalised_housekeeping = normalise_data(df, 'EF1a')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "lowestmeancq=1.3342826533153627\n",
      "normalising to lowest mean cq sample: 125-4\n",
      "Directory  ../../data/CRISPR_library/qPCR/10.08.22/plots  already exists\n",
      "Directory  ../../data/CRISPR_library/qPCR/10.08.22/plots/individual  already exists\n",
      "Directory  ../../data/CRISPR_library/qPCR/10.08.22/plots/targets  already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/scipy/stats/_morestats.py:1797: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/scipy/stats/_morestats.py:1797: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/scipy/stats/_morestats.py:1797: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/scipy/stats/_morestats.py:1797: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.10/site-packages/scipy/stats/_morestats.py:1797: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some p values are less than 0.05, data is not normal, using welchs t-test\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #normality tests - kolmogorov smirnov test\n",
    "# #returns test statistic, p-value\n",
    "# for name1 in prom_names_plate1:\n",
    "#     for name in names_plate1:\n",
    "#         print(name1,'{}: {}'.format(name, stats.shapiro(luminescence_raw_df_plate1['nluc/fluc'][luminescence_raw_df_plate1.TF_added == name])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('qpcr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c2acf9d6025fe51d3e4a4cb09a2ff19b54eaae2da571c8e6469319b5fd828be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
