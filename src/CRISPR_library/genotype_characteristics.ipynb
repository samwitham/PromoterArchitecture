{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#script to read in .csv output files from SmartRoot analysis, concatenate them and then analyse and make plots\n",
    "#use qpcr conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#allow exporting to latex as pgf\n",
    "# import matplotlib as mpl\n",
    "# # Use the pgf backend (must be set before pyplot imported)\n",
    "# mpl.use('pgf')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob \n",
    "# import sys\n",
    "# import argparse\n",
    "import statsmodels.api as sm\n",
    "# stats annotations\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "from bioinfokit.analys import stat\n",
    "\n",
    "import pingouin as pg\n",
    "#allow changing of axes label floats\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy import stats\n",
    "#allow changing of axes label floats\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import math\n",
    "#cycle through alphabet\n",
    "from string import ascii_uppercase as alc\n",
    "\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "#installed statannotations from different branch to master too allow the annotator flag \"show_non_significant=False\": pip install -e git+https://github.com/sepro/statannotations#egg=statannotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to read in csv file as pandas df\n",
    "def read_csv(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    #keep the Well, Sample, Target, Cq and Amp Status columns\n",
    "    df = df[['Well', 'Sample', 'Target', 'Cq', 'Amp Status']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for normality of the data\n",
    "def test_normality(df, location):\n",
    "    \"\"\"run Shapiro-Wilk test\"\"\"\n",
    "    #iterate over rows\n",
    "    #get sample names\n",
    "    sample_names = df['Sample'].unique()\n",
    "    #get Target names\n",
    "    target_names = df['Target'].unique()\n",
    "    #iterate over samples and targets\n",
    "    #make empty df to store p-values\n",
    "    p_values = pd.DataFrame(columns=['Sample', 'Target', 'pvalue'])\n",
    "    for sample in sample_names:\n",
    "        for target in target_names:\n",
    "            # #run Shapiro-Wilk test\n",
    "           # print(sample,'{}: {}'.format(target, stats.shapiro(df['relative_expression'][df.Target == target])))\n",
    "            #write a df with the results of the Shapiro-Wilk test\n",
    "            #shapiro_df = pd.DataFrame(columns=['Sample', 'Target', 'p-value'])\n",
    "            #results = sample,target,'{}'.format(stats.shapiro(df['relative_expression'][df.Target == target]))\n",
    "            results = sample,target,stats.shapiro(df['relative_expression'][df.Target == target])\n",
    "            #('125-4', 'NLP7: ShapiroResult(statistic=0.707939088344574, pvalue=9.890874935081229e-05)')\n",
    "            shapiro_df = pd.DataFrame([results], columns=['Sample','Target', 'shapiro_test']).reset_index(drop=True)\n",
    "            #get statistic and pvalue\n",
    "            shapiro_df['statistic'] = shapiro_df['shapiro_test'].apply(lambda x: x[0])\n",
    "            shapiro_df['pvalue'] = shapiro_df['shapiro_test'].apply(lambda x: x[1])\n",
    "            #filter columns\n",
    "            shapiro_df = shapiro_df[['Sample', 'Target', 'pvalue', 'statistic',]]\n",
    "            #append to p_values df\n",
    "            p_values = pd.concat([p_values, shapiro_df], axis=0, ignore_index=True)\n",
    "\n",
    "    #write to tsv\n",
    "    p_values.to_csv(f'{location}/shapiro_normality.tsv', sep='\\t', index=False)\n",
    "\n",
    "    return p_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to filter out certain data points\n",
    "def filter_data(df, amp_status, cq):\n",
    "    #filter out the data points with amp_status = Amp using .loc\n",
    "    df = df.loc[df['Amp Status'] == amp_status]\n",
    "    #make Cq column numerical\n",
    "    dfcopy = df.copy()\n",
    "    dfcopy['Cq'] = pd.to_numeric(dfcopy['Cq'])  \n",
    "    #filter out the data points with cq < cq_threshold using .loc\n",
    "    dfcopy = dfcopy.loc[dfcopy['Cq'] <= cq]\n",
    "\n",
    "    return dfcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea from https://www.nature.com/articles/s41598-021-99727-6#Sec2\n",
    "# To detect outliers, the CT standard deviation (Cq-SD) of the technical replicates for a given sample is calculated, \n",
    "# if the Cq-SD is greater than the cut-off (the default value is 0.3), then the technical replicate furthest \n",
    "# from the sample mean is removed. The process occurs recursively until the Cq-SD is less than the cut-off \n",
    "# or the value of “max outliers” is reached. This is determined by the parameter ‘Max Proportion’, the 0.5 default \n",
    "# means that outliers will be removed until two technical replicates remain. The ‘preserve highly variable replicates’: \n",
    "# If the Cq-SD is higher than 0.3, but the absolute (mean-median)/median is less than 0.1, replicates are preserved. \n",
    "# This helps to account for a lack of a clear outlier, where two of three replicates are close to equally distributed \n",
    "# around the mean.\n",
    "def remove_outliers(df, max_outliers, ct_sd_threshold):\n",
    "    \n",
    "    #copy the dataframe\n",
    "    dfcopy = df.copy()\n",
    "    # Add filter columns\n",
    "    dfcopy['Ignore'] = False\n",
    "    #dfcopy['Cq-SD'] = int()\n",
    "    \n",
    "    #make Cq column numerical\n",
    "    dfcopy['Cq'] = pd.to_numeric(dfcopy['Cq'])\n",
    "    #calculate the Cq-SD of the technical replicates for a given sample\n",
    "    f = (dfcopy['Ignore'].eq(False))\n",
    "    dfcopy1 = dfcopy[f].groupby(['Sample','Target']).agg({'Cq':['std']})\n",
    "    #dfcopy = dfcopy[f].groupby(['Sample','Target']).agg({'Cq-SD':['std']})#['Cq'].transform(lambda x: x.std() / np.sqrt(x.count()))\n",
    "    #make df containing all samples with outliers\n",
    "    f = dfcopy1['Cq']['std'] > ct_sd_threshold\n",
    "    dfcopy_outliers = dfcopy1[f]\n",
    "\n",
    "    \n",
    "    # dfcopy_outliers = dfcopy[dfcopy['Cq-SD'] > ct_sd_threshold]\n",
    "    if not dfcopy_outliers.empty:\n",
    "        #mark all outliers\n",
    "        #iterate over rows as tuples (sample, target)\n",
    "        for i, row in enumerate(dfcopy_outliers.itertuples(name = None),1):\n",
    "            #example row: (('144-5AH', 'DREB26'), 0.6497278066418295)\n",
    "         \n",
    "           \n",
    "            #check that the dfcopy sample name is the same as the sample name in the current row\n",
    "            f = (dfcopy.Sample == row[0][0]) & (dfcopy.Target == row[0][1]) & (dfcopy['Ignore'].eq(False))\n",
    "            dx_idx = dfcopy[f].index\n",
    "            group_size = len(dx_idx)\n",
    "            min_size = round(group_size * (1-max_outliers))\n",
    "            size = group_size\n",
    "            if min_size < 2:\n",
    "                min_size = 2\n",
    "                print('Warning: minimum size of technical replicate group is 2')\n",
    "            while True:\n",
    "                f = (dfcopy.Sample == row[0][0]) & (dfcopy.Target == row[0][1])\n",
    "                dx = dfcopy[f].copy()\n",
    "                dxg = dfcopy[f].groupby(['Sample', 'Target']).agg({'Cq': [np.size, 'std', 'mean']})\n",
    "                if dxg['Cq']['std'].iloc[0] <= ct_sd_threshold:\n",
    "                    #Cq std is under threshold, so no outliers\n",
    "                    break\n",
    "                size -= 1\n",
    "                if size < min_size:\n",
    "                    #not enough technical replicates to remove outliers\n",
    "                    break\n",
    "                #remove the technical replicate furthest from the mean\n",
    "                dx['Distance'] = (dx['Cq'] - dxg['Cq']['mean'].iloc[0])**2\n",
    "                dx_sorted = dx.sort_values(by = 'Distance', ascending=False).index[0]\n",
    "                #print()\n",
    "                #dfcopy = dfcopy.loc[dx_sorted].assign(Ignore=True)\n",
    "                #dfcopy.loc[dx_sorted].loc(:, 'Ignore') = True\n",
    "                #print(dx_sorted)\n",
    "                dfcopy.loc[[dx_sorted], 'Ignore'] = True\n",
    "                #dfcopy['Ignore'].loc[dx_sorted] = True\n",
    "                #rint(dx_sorted)\n",
    "                \n",
    "    return dfcopy\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "   \n",
    "    # #remove the highly variable replicates\n",
    "    # if preserve_highly_variable_replicates == True:\n",
    "    #     dfcopy = dfcopy.loc[dfcopy['Cq-SD'] > ct_sd_threshold]\n",
    "    #     dfcopy = dfcopy.loc[dfcopy['Cq-SD'] < (dfcopy['Cq-SD'].mean() - dfcopy['Cq-SD'].median())/dfcopy['Cq-SD'].median()]\n",
    "    # #remove the outliers until the number of outliers is less than max_outliers\n",
    "    # while dfcopy['Cq-SD'].count() > max_outliers:\n",
    "    #     dfcopy = dfcopy.loc[dfcopy['Cq-SD'] < ct_sd_threshold]\n",
    "    #     if preserve_highly_variable_replicates == True:\n",
    "    #         dfcopy = dfcopy.loc[dfcopy['Cq-SD'] > ct_sd_threshold]\n",
    "    #         dfcopy = dfcopy.loc[dfcopy['Cq-SD'] < (dfcopy['Cq-SD'].mean() - dfcopy['Cq-SD'].median())/dfcopy['Cq-SD'].median()]\n",
    "    # return dfcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to recursively find all .csv files in a directory and concatenate them into a single dataframe\n",
    "def concat_csv_recursive(PATH, EXT):\n",
    "    #find all .csv files in the directory\n",
    "    csv_files = [file for path, subdir, fname in os.walk(PATH) \n",
    "                for file in glob.glob(os.path.join(path, EXT))]\n",
    "        #glob.glob(f'{directory}/{EXT}', recursive=True)\n",
    "    #print(csv_files)\n",
    "    #initialise empty dataframe\n",
    "    df = pd.DataFrame()\n",
    "    #loop through all files and concatenate them into a single dataframe\n",
    "    for file in csv_files:\n",
    "        df = pd.concat([df, pd.read_csv(file)], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_data(df,output_location):\n",
    "    #sort dataframe by sample name\n",
    "    df = df.sort_values(by=['image'])\n",
    "    #remove duplicate rows\n",
    "    df = df.drop_duplicates(keep='first')\n",
    "    #make nitrate concentration column using image column\n",
    "    df['nitrate_concentration'] = df['image'].str.split('_').str[1]\n",
    "    #make sample name column using image column\n",
    "    df['sample_name'] = df['image'].str.split('_').str[0]\n",
    "    #make plate column\n",
    "    df['plate'] = df['sample_name']+'_'+df['image'].str.split('_').str[2]\n",
    "    #remove spaces from column names\n",
    "    df.columns = df.columns.str.replace(' ', '')\n",
    "   \n",
    "    \n",
    "    #make several new columns\n",
    "    #first make new df which will contain one row per plant\n",
    "    df_plant = df[df.root_order == 0]\n",
    "    #remove all lines which have no length or which are NaN\n",
    "    df_plant = df_plant[df_plant.length.notnull()]\n",
    "    #df_plant = df_plant[df_plant.length != 0]\n",
    "    # df_plant = df.groupby(['sample_name', 'plate', 'nitrate_concentration',root_ontology]).agg({'image':'count', 'nitrate_concentration':'first', 'sample_name':'first', 'plate':'first'})\n",
    "    #print(df_plant)\n",
    "    ## PR = primary root length (cm)\n",
    "    #change length column to PR\n",
    "    df_plant['PR'] = df_plant['length']\n",
    "    # LR = lateral root number (visible from scan)\n",
    "    #for each root in df_plant, count the number of rows whose parent root in df is the same as the root id in df_plant\n",
    "    df_plant['LR'] = df_plant.apply(lambda row: df[(df.parent == row.root) & (df.root_order == 1)].shape[0], axis=1)\n",
    "    #make list of first order lateral root ids\n",
    "    df_plant['LR_ids'] = df_plant.apply(lambda row: df[(df.parent == row.root) & (df.root_order == 1)].root.tolist(), axis=1)\n",
    "    #for each id in LR_ids, count the number of rows whose parent root in df is the same as the root id \n",
    "    df_plant['LR_2nd_order'] = df_plant.apply(lambda row: df[(df.parent.isin(row.LR_ids)) & (df.root_order == 2)].shape[0], axis=1)\n",
    "    # LRL = total lateral root length (all LRs added together - cm). Have separate column for 2nd order lateral roots\n",
    "    \n",
    "    df_plant['LRL_1st_order'] = df_plant.apply(lambda row: df[(df.parent == row.root) & (df.root_order == 1)].length.sum(), axis=1)\n",
    "    df_plant['LRL_2nd_order'] = df_plant.apply(lambda row: df[(df.parent.isin(row.LR_ids)) & (df.root_order == 2)].length.sum(), axis=1)\n",
    "    #add LRL and 2nd order LRL to get total LRL\n",
    "    df_plant['LRL'] = df_plant['LRL_1st_order'] + df_plant['LRL_2nd_order']\n",
    "    # ALRL = average lateral root length (LRL/LR - cm)\n",
    "    df_plant['ALRL'] = (df_plant.LRL) / (df_plant.LR)\n",
    "   # df_plant['ALRL'] = df_plant.apply(lambda row: (row.LRL / row.LR, axis=1)\n",
    "    # TRL = total root length (PR + LRL)\n",
    "    df_plant['TRL'] = df_plant.PR + df_plant.LRL\n",
    "    # LRD = lateral root density (LR/PR)\n",
    "    df_plant['LRD'] = df_plant.LR / df_plant.PR\n",
    "    # LRL_div_TRL = percentage of LRL contributing to TRL (LRL/TRL)\n",
    "    df_plant['LRL_div_TRL'] = (df_plant.LRL) / df_plant.TRL\n",
    "\n",
    "    #add genotype column\n",
    "    df_plant['genotype'] = df_plant['root_name'].str.split('_').str[0]\n",
    "    #remove spaces from genotype\n",
    "    df_plant['genotype'] = df_plant['genotype'].str.replace(' ', '')\n",
    "\n",
    "    #add log columns for PR, LR, LR_2nd_order, LRL, LRL_2nd_order. ALRL, TRL, LRD, LRL_div_TRL\n",
    "    df_plant['log_PR'] = np.log(df_plant.PR)\n",
    "    df_plant['log_LR'] = np.log(df_plant.LR)\n",
    "    df_plant['log_LR_2nd_order'] = np.log(df_plant.LR_2nd_order)\n",
    "    df_plant['log_LRL'] = np.log(df_plant.LRL)\n",
    "    df_plant['LRL_1st_order'] = df_plant.LRL_1st_order\n",
    "    df_plant['log_LRL_2nd_order'] = np.log(df_plant.LRL_2nd_order)\n",
    "    df_plant['log_ALRL'] = np.log(df_plant.ALRL)\n",
    "    df_plant['log_TRL'] = np.log(df_plant.TRL)\n",
    "    df_plant['log_LRD'] = np.log(df_plant.LRD)\n",
    "    df_plant['log_LRL_div_TRL'] = np.log(df_plant.LRL_div_TRL)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #save df as tsv file\n",
    "    # df_plant.to_csv(f'{output_location}/single_plant_data.tsv', sep='\\t', index=False)\n",
    "    #count number of plants for each plant line\n",
    "\n",
    "    #partition variation across mutants relative to wild type using principal component analysis of all RSA traits\n",
    "    #do stats: Using a two-way ANOVA, three phenotypic categories: genotype effects in both nitrogen conditions (genotype-dependent), genotype effects in only one condition (nitrogen-condition-dependent) or genotype by nitrogen condition-dependent effects \n",
    "    \n",
    "\n",
    "    #print(len(df))\n",
    "    return df, df_plant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set matplotlib rc parameters\n",
    "def set_rc_params():\n",
    "    #set matplotlib default parameters\n",
    "    rcParams['xtick.major.width'] = 2\n",
    "    rcParams['ytick.major.width'] = 2\n",
    "    rcParams['axes.linewidth'] = 2\n",
    "    rcParams['lines.linewidth'] = 2\n",
    "    #remove top and right lines\n",
    "    rcParams['axes.spines.top'] = False\n",
    "    rcParams['axes.spines.right'] = False\n",
    "    #font size\n",
    "    fontsize = 20\n",
    "    rcParams['font.size'] = fontsize\n",
    "    #for getting the microsoft font Arial working, please follow this guide: https://alexanderlabwhoi.github.io/post/2021-03-missingfont/\n",
    "    rcParams['font.family'] = 'sans-serif'\n",
    "    rcParams['font.sans-serif'] = ['Arial']\n",
    "    #allow font to be edited later in pdf editor\n",
    "    #make svg text editable\n",
    "    rcParams['svg.fonttype'] = 'none'\n",
    "    rcParams ['pdf.fonttype'] = 42 \n",
    "    #align y-axis top most tick with end of axis\n",
    "    rcParams['axes.autolimit_mode'] = 'round_numbers'\n",
    "    #set margins to ensure any error bars fit\n",
    "    rcParams['axes.xmargin'] = 0.2\n",
    "    rcParams['axes.ymargin'] = 0.2\n",
    "    #define bar width\n",
    "    #bar_width = 0.65\n",
    "    #allow math text to be displayed\n",
    "    #rcParams['mathtext.default'] = 'regular'\n",
    "    return fontsize\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(df,var,y_label,sample_name,box_pair_p_values, fontsize, ax):\n",
    "    \"\"\"function to make box plots\"\"\"\n",
    "    #plot height and width\n",
    "   # height = 5\n",
    "   # width = 4\n",
    "    \n",
    "    order = ['1mM','10mM']\n",
    "    fig_args = {'x':'nitrate_concentration', 'y':var,'data':df, 'order':order, 'dodge':True,'hue':'genotype','hue_order':['col0',sample_name]}#'ax':ax\n",
    "    configuration = {'test':None, 'text_format':'star', 'pvalue_thresholds':[[1e-3, \"***\"],[1e-2, \"**\"],[0.05, \"*\"],[1, \"ns\"]]}#\"pairs\":list(box_pairs_significant.keys()),\"pvalues\":list(box_pairs_significant.values()), 'loc':'inside'\n",
    "    #_ = plt.figure(figsize=(width,height))\n",
    "\n",
    "    fig = sns.boxplot(**fig_args, linewidth=2, palette=[\"white\", \"grey\"],ax = ax, boxprops={\"edgecolor\":\"black\"},flierprops={\"markeredgecolor\":\"black\"},whiskerprops={\"color\":\"black\"},capprops={\"color\":\"black\"}, medianprops={\"color\":\"black\"})\n",
    "    fig = sns.swarmplot(**fig_args, color='black', palette=[\"black\", \"black\"],size=4, ax=ax)\n",
    "    #get pairs and pvalues\n",
    "    #print(box_pairs_significant)\n",
    "    pairs=list(box_pair_p_values.keys())\n",
    "    #print(f'pairs={pairs}')\n",
    "    \n",
    "    pvalues=list(box_pair_p_values.values())\n",
    "    #print(f'pvalues={pvalues}')\n",
    "    #add statsannotator = Annotator(fig, pairs, **fig_args,verbose=False)\n",
    "    annotator = Annotator(ax, pairs, **fig_args,verbose=False, show_non_significant=False)#show_non_significant=False will be added in the next version of statsannotator\n",
    "    #annotator.set_pvalues(pvalues)\n",
    "    annotator.configure(**configuration)\n",
    "    \n",
    "    annotator.set_pvalues_and_annotate(pvalues)\n",
    "\n",
    "    ax.set_xlabel(r'KNO$_{3}$ concentration (mM)')\n",
    "    ax.set_ylabel(y_label)\n",
    "    #set y axis limit to start at 0\n",
    "    _ = ax.set_ylim(0,None)\n",
    "\n",
    "    \n",
    "\n",
    "    ##plot legend, excluding legend from swarm plot\n",
    "    h,l = ax.get_legend_handles_labels()\n",
    "    #change name of label\n",
    "    l[0] = \"Col-0\"\n",
    "    l[1] = sample_name\n",
    "    #set edge color\n",
    "    h[0].set_edgecolor('black')\n",
    "    h[1].set_edgecolor('black')\n",
    "    #l[2] = \"1 mM nitrate\"     \n",
    "    leg = ax.legend(h[0:2],l[0:2],frameon=False,edgecolor='black')#.set_linewidth(2)#,bbox_to_anchor=(0,0.85), loc='best',fontsize=fontsize,\n",
    "\n",
    "    #set linewith of each legend object\n",
    "    for legobj in leg.legendHandles:\n",
    "        legobj.set_linewidth(2)\n",
    "    # change axes labels\n",
    "    #_ = plt.ylabel('Relative expression (a.u.)')\n",
    "    #rename x axis labels\n",
    "    _ = ax.set_xticklabels( ('1','10') )\n",
    "\n",
    "    # change x axis labels\n",
    "    # _ = ax.set_xticklabels([0,1],['1','10'])\n",
    "    #max 1 decimal place y tick labels\n",
    "    # ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "    # #save plot to file\n",
    "    # plt.savefig(\n",
    "    #                 f'{output_location}/{var}_{sample_name}_boxplot.pdf',\n",
    "    #                 format=\"pdf\",\n",
    "    #                 bbox_inches=\"tight\",transparent=True)\n",
    "    # plt.savefig(\n",
    "    #                 f'{output_location}/{var}_{sample_name}_boxplot.svg',\n",
    "    #                 format=\"svg\",\n",
    "    #                 bbox_inches=\"tight\",transparent=True)\n",
    "    # plt.savefig(\n",
    "    #                 f'{output_location}/{var}_{sample_name}_boxplot.pgf',\n",
    "    #                 format=\"pgf\",\n",
    "    #                 bbox_inches=\"tight\",transparent=True)\n",
    "    plt.cla()  # clear axis              \n",
    "    plt.close('all')   \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginal_effects(df,variables,sample_name, fontsize, qpcr_df,combined_output_dir,normal,sample_order):\n",
    "\n",
    "    \"\"\"function to calculate marginal means for interaction genotype*nitrate_concentration\"\"\"\n",
    "\n",
    "    #determine how many subplots needed - 7 + number of genes in qpcr_df\n",
    "    #look at subset of qpcr_df with sample_name in it\n",
    "    qpcr_df_subset = qpcr_df[qpcr_df['Sample']==sample_name]\n",
    "    #count number of unique targets\n",
    "    number_of_targets = len(qpcr_df_subset['Target'].unique())\n",
    "    #add 7 to number of targets\n",
    "    number_of_subplots = number_of_targets + 7\n",
    "    print(f'number of subplots for {sample_name }= {number_of_subplots}')\n",
    "\n",
    "\n",
    "    #divide number of subplots by 3 to get number of rows\n",
    "    number_of_rows = math.ceil(number_of_subplots/3) \n",
    "    height = 4.8*number_of_rows\n",
    "    width = 12\n",
    "    #make subplots equal to number_of_subplots\n",
    "    fig, axes = plt.subplots(nrows=number_of_rows, ncols=3, figsize=(width, height), sharex=False)\n",
    "    #flatten axis array\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "\n",
    "    #subset df by and sample name\n",
    "    qpcr_df_subset = qpcr_df[(qpcr_df['Sample']==sample_name) | (qpcr_df['Sample']=='Col-0')]\n",
    "\n",
    "    #make ax number count\n",
    "    ax_num = 0\n",
    "\n",
    "    #add qpcr data\n",
    "    for target in qpcr_df_subset['Target'].unique():\n",
    "    #if target is not EF1a, make plot\n",
    "        if target != 'EF1a':            \n",
    "            temp_df = qpcr_df_subset[qpcr_df_subset.Target == target]\n",
    "            #change condition values\n",
    "            temp_df.loc[temp_df['condition'] == '10mM_nitrate', 'condition'] = '10'\n",
    "            temp_df.loc[temp_df['condition'] == '1mM_nitrate', 'condition'] = '1'\n",
    "\n",
    "\n",
    "            #get list of samples\n",
    "            samples_unique = temp_df['Sample'].unique()\n",
    "\n",
    "            \n",
    "\n",
    "            #sort based on custom order\n",
    "            samples = []\n",
    "            for i in range(len(sample_order)):\n",
    "                if sample_order[i] in samples_unique:\n",
    "                    samples+=[sample_order[i]]\n",
    "            #create new df with only sample of interest and Col-0 based on plateID so that Col-0 from the same plate is prioritised\n",
    "            #if temp_df plateID is \"22.08.22_plate1\"\n",
    "\n",
    "            for sample in samples:\n",
    "                if sample != 'Col-0':\n",
    "                    plateID_value = temp_df.loc[temp_df['Sample'] == sample, 'plateID'].values[0]\n",
    "                # print(plateID_value)\n",
    "                    if plateID_value == '22.08.22_plate1':   \n",
    "                        #print(f'platevalueis{plateID_value}')                \n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | ((temp_df.Sample == 'Col-0') & (temp_df.plateID == plateID_value))]\n",
    "\n",
    "                    if plateID_value == '22.08.22_plate2':\n",
    "\n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | ((temp_df.Sample == 'Col-0') & (temp_df.plateID == plateID_value))]\n",
    "                    if plateID_value == '06.09.22_plate1':\n",
    "\n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | ((temp_df.Sample == 'Col-0') & (temp_df.plateID == plateID_value))]\n",
    "                    if plateID_value == '06.09.22_plate2':\n",
    "\n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | ((temp_df.Sample == 'Col-0') & (temp_df.plateID == plateID_value))]\n",
    "                    if plateID_value == '06.09.22_plate3':\n",
    "\n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | ((temp_df.Sample == 'Col-0') & (temp_df.plateID == plateID_value))]\n",
    "                    if plateID_value == '10.8.22':\n",
    "                        #include all col-0 values from both plates       \n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | (temp_df.Sample == 'Col-0')]\n",
    "\n",
    "                    #print(ax_num)\n",
    "                    make_plots(df_new, normal,sample, fig, axes[ax_num], target)\n",
    "\n",
    "                    \n",
    "                    #add 1 to ax_num\n",
    "                    ax_num += 1\n",
    "\n",
    "    #make boxplots for each variable\n",
    "    for var, y_label in variables.items():\n",
    "\n",
    "        #remove NaN values from dataframe\n",
    "        df = df.dropna(subset=[var]).copy()\n",
    "        \n",
    "        #only run if not empty array\n",
    "        #try:\n",
    "\n",
    "        #run anova\n",
    "        anova = smf.ols(f'{var} ~ genotype*nitrate_concentration + plate', data=df).fit()\n",
    "        #get marginal means, save as txt file            \n",
    "        #anova.summary_frame().to_csv(f'{output_location}/marginal_means_{var}.tsv', sep='\\t')\n",
    "        #save anova summary to tsv\n",
    "        #use type 1 anova to test interaction term. If not significant, refit without the interaction term and use Type-II to test the main effects\n",
    "        table = sm.stats.anova_lm(anova, type=1)\n",
    "       \n",
    "        #check if interaction term genotype:nitrate_concentration is significant\n",
    "        if table.loc['genotype:nitrate_concentration']['PR(>F)'] >= 0.05:\n",
    "            #print(table.loc['genotype:nitrate_concentration']['PR(>F)'])\n",
    "            #if not significant, refit without the interaction term and use Type-II to test the main effects\n",
    "\n",
    "            anova = smf.ols(f'{var} ~ genotype+nitrate_concentration + plate', data=df).fit()\n",
    "            #filter columns of df\n",
    "            df_filtered = df[['genotype','nitrate_concentration',var]].copy()\n",
    "            #drop na\n",
    "            df_filtered = df_filtered.dropna(subset=['genotype','nitrate_concentration',var]).copy()\n",
    "            \n",
    "            genotypes_unique = df['genotype'].unique()\n",
    "            length_samples = len(genotypes_unique)\n",
    "            \n",
    "            box_pair_p_values = {}\n",
    "            for x in range (0, (length_samples)):                        \n",
    "                if genotypes_unique[x] != 'col0':\n",
    "                    #perform estimated marginal means contrasts between genotype*nitrate interaction\n",
    "                    #create model, dropping the plate effects because it seems non-significant in most/all cases\n",
    "                    #test assumption that variances are all equal\n",
    "                    #split df by nitrate concentration\n",
    "                    df_10mM = df_filtered[df_filtered['nitrate_concentration'] == '10mM']\n",
    "                    df_1mM = df_filtered[df_filtered['nitrate_concentration'] == '1mM']\n",
    "                    var_10mM = pg.homoscedasticity(df_10mM, group='genotype', dv=f'{var}')#Levene test\n",
    "                    var_1mM = pg.homoscedasticity(df_1mM, group='genotype', dv=f'{var}')\n",
    "\n",
    "                        #print(f'df_1mM_genotype variance {var} {sample_name}: {var_1mM}')\n",
    "                    # print(f'df_10mM_genotype variance {var} {sample_name}: {var_10mM}')\n",
    "                    #followed this https://www.reneshbedre.com/blog/anova.html\n",
    "                    res = stat()\n",
    "                    res.anova_stat(df=df_filtered, res_var=var, anova_model=f'{var}~C(genotype)+C(nitrate_concentration)')\n",
    "                  \n",
    "                    # for interaction effect between genotype and nitrate_concentration\n",
    "                    res.tukey_hsd(df=df_filtered, res_var=var, xfac_var=['genotype','nitrate_concentration'], anova_model=f'{var}~C(genotype)+C(nitrate_concentration)')\n",
    "                    genotype_nitrate_concentration_tukey = res.tukey_summary\n",
    "\n",
    "                    #get p values\n",
    "                    p_values = genotype_nitrate_concentration_tukey.copy()\n",
    "\n",
    "\n",
    "                    # #write stats to file\n",
    "                    # with open(f'{output_location}/stats/marginal_means_{var}_{sample_name}.txt', 'w', encoding=\"utf-8\", ) as f:\n",
    "            \n",
    "                    #     f.write(f'first test assumption that variances are all equal\\ndf_1mM_genotype variance {var} {sample_name}:\\n {var_1mM}\\ndf_10mM_genotype variance {var} {sample_name}:\\n {var_10mM}\\nanova_type_1:\\n{table}\\ngenotype:nitrate_concentration is not significant so use type 2 anova excluding interaction term\\nanova_type_2:\\n{res.anova_summary}\\nTukey_post_hocs:\\ngenotype_nitrate_concentration_tukey\\n{p_values}')\n",
    "                    \n",
    "\n",
    "                    #add to box_pair_p_values dictionary the box pair as the key and the p value as the value\n",
    "                    box_pair_p_values[(('1mM','col0'),('1mM',genotypes_unique[x]))] = p_values.loc[((p_values['group1'] == (f'col0', '1mM')) & (p_values['group2'] == (f'{genotypes_unique[x]}', '1mM')))|((p_values['group1'] == (f'{genotypes_unique[x]}', '1mM')) & (p_values['group2'] == (f'col0', '1mM'))),'p-value'].values[0]\n",
    "                    box_pair_p_values[(('10mM','col0'),('10mM',genotypes_unique[x]))] = p_values.loc[((p_values['group1'] == (f'col0', '10mM')) & (p_values['group2'] == (f'{genotypes_unique[x]}', '10mM')))|((p_values['group1'] == (f'{genotypes_unique[x]}', '10mM')) & (p_values['group2'] == (f'col0', '10mM'))),'p-value'].values[0]\n",
    "                    # box_pair_p_values[(('1mM','col0'),('1mM',genotypes_unique[x]))] = p_values.loc[((p_values['group1'] == f'(col0, 1mM)') & (p_values['group2'] == f'({genotypes_unique[x]}, 1mM)'))|((p_values['group1'] == f'({genotypes_unique[x]}, 1mM)') & (p_values['group2'] == f'(col0, 1mM)')),'p-value'].values[0]\n",
    "                    # box_pair_p_values[(('10mM','col0'),('10mM',genotypes_unique[x]))] = p_values.loc[((p_values['group1'] == f'(col0, 10mM)') & (p_values['group2'] == f'({genotypes_unique[x]}, 10mM)'))|((p_values['group1'] == f'({genotypes_unique[x]}, 10mM)') & (p_values['group2'] == f'(col0, 10mM)')),'p-value'].values[0]\n",
    "                    \n",
    "\n",
    "            \n",
    "            \n",
    "        if table.loc['genotype:nitrate_concentration']['PR(>F)'] < 0.05:\n",
    "            #if significant interaction effect, analyse nitrate concentrations separately using one-way ANOVA\n",
    "            #first split dataframe into separate dataframes for each nitrate concentration\n",
    "            print(f'{var}{sample_name} is significant for genotype*nitrate_concentration interaction')\n",
    "            df_low = df[df.nitrate_concentration == '1mM']\n",
    "            df_high = df[df.nitrate_concentration == '10mM']\n",
    "            anova_low_nitrate = smf.ols(f'{var} ~ genotype + plate', data=df_low).fit()\n",
    "            anova_high_nitrate = smf.ols(f'{var} ~ genotype + plate', data=df_high).fit()\n",
    "            table_low = sm.stats.anova_lm(anova_low_nitrate, type=2)\n",
    "            table_high = sm.stats.anova_lm(anova_high_nitrate, type=2)\n",
    "            #print(table_high)\n",
    "            # #write stats to file\n",
    "            # with open(f'{output_location}/stats/marginal_means_{var}_{sample_name}.txt', 'w', encoding=\"utf-8\") as f:\n",
    "            \n",
    "            #     f.write(f'anova_type_1:\\n{table}\\ngenotype*nitrate_concentration is significant so analyse each nitrate concentration separately\\nanova_type_2_1mM_nitrate:\\n{table_low}\\nanova_type_2_10mM_nitrate:\\n{table_high} \\n{anova.summary()}')\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "            #get p values\n",
    "            p_value_low_nitrate_df = pd.DataFrame(data=table_low)\n",
    "            p_value_high_nitrate_df = pd.DataFrame(data=table_high)\n",
    "            \n",
    "            #get box pairs and p values for adding stats annotations\n",
    "            genotypes_unique = df['genotype'].unique()\n",
    "            length_samples = len(genotypes_unique)\n",
    "            box_pair_p_values = {}\n",
    "            for x in range (0, (length_samples)):                        \n",
    "                if genotypes_unique[x] != 'col0':                            \n",
    "                    box_pair_p_values[(('1mM','col0'),('1mM',genotypes_unique[x]))] = p_value_low_nitrate_df.loc['genotype','PR(>F)']\n",
    "                    box_pair_p_values[(('10mM','col0'),('10mM',genotypes_unique[x]))] = p_value_high_nitrate_df.loc['genotype','PR(>F)']\n",
    "                    \n",
    "        \n",
    "        #PR(>F)\n",
    "        #make boxplots\n",
    "        #remove all string before the first underscore in the variable name, and return all subsequent string     \n",
    "\n",
    "        #split var string on _\n",
    "        no_log_var = var.split('_')[1:]\n",
    "        no_log_var = '_'.join(no_log_var)\n",
    "        #print(no_log_var)\n",
    "        #make boxplots\n",
    "        #first filter df\n",
    "        boxplot_df = df.filter(items=[no_log_var, 'nitrate_concentration','genotype']).dropna().copy()\n",
    "        #get column types\n",
    "        #print(boxplot_df.dtypes)\n",
    "\n",
    "        # #save box_pair_p_values\n",
    "        # with open(f'{output_location}/stats/box_pair_p_values_{var}_{sample_name}.txt', 'w', encoding=\"utf-8\") as f:\n",
    "        #     f.write(f'{box_pair_p_values}')\n",
    "\n",
    "        \n",
    "        \n",
    "        boxplot(boxplot_df,no_log_var,y_label,sample_name,box_pair_p_values, fontsize ,axes[ax_num])\n",
    "        #add 1 to ax_num\n",
    "        ax_num += 1\n",
    "    #add A B C labels to all subplots\n",
    "\n",
    "    #\n",
    "\n",
    "\n",
    "    letter_count = 1\n",
    "\n",
    "\n",
    "    for ax in axes:\n",
    "        \n",
    "        #if letter_count is higher than number of subplots, remove axis\n",
    "        if letter_count >= number_of_subplots:\n",
    "            ax.axis('off')\n",
    "            letter_count += 1\n",
    "        else:\n",
    "            letter = alc[letter_count]\n",
    "            ax.text(-0.1, 1.1, letter, transform=ax.transAxes, fontsize=18,  va='top', ha='right')#fontweight='bold'\n",
    "            letter_count += 1\n",
    "\n",
    "        #ax.label_outer()\n",
    "    \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    #save figure\n",
    "    fig.savefig(f'{combined_output_dir}/{sample_name}_characteristics_plot.pdf', format=\"pdf\", bbox_inches=\"tight\",transparent=True)\n",
    "    fig.savefig(f'{combined_output_dir}/{sample_name}_characteristics_plot.svg', format=\"svg\", bbox_inches=\"tight\",transparent=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to normalise the data based on a column of Cq values (either to housekeeping or based on nitrate or wild type plant)\n",
    "def normalise_data(df, orig_col,normalisation_col, new_column_name):\n",
    "   \n",
    "    #normalise Cq values to the EF1a housekeeping gene mean Cq value for each sample\n",
    "    df.loc[:,new_column_name] = df[orig_col] - df[normalisation_col]\n",
    "    #remove nan values in the new column\n",
    "    df = df[df[new_column_name].notna()]\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to make new columns and sort the data\n",
    "def sort_data_qpcr(df, location, name):\n",
    "    #make new column called EF1a_Cq, make the value in this column for a particular sample equal to the Cq value for the EF1a Target for that sample\n",
    "    ##remove if not amplified\n",
    "    df = df.loc[df['Amp Status'] == 'Amp']\n",
    "    \n",
    "\n",
    "    #first remove outliers\n",
    "    df = remove_outliers(df, 0.5, 0.3)\n",
    "    #save outliers df to tsv\n",
    "    df.to_csv(f'{location}/including_outliers_{name}.tsv', sep='\\t', index=False)\n",
    "    #remove outliers\n",
    "    df = df.loc[df['Ignore'] == False]    \n",
    "    #get the mean of each sample/target (take mean of technical replicates)\n",
    "    df['Cq_mean'] = df.groupby(['Sample','Target'])['Cq'].transform('mean')\n",
    "    #make a df containing only EF1a target (housekeeping gene)\n",
    "    df_EF1a = df.loc[df['Target'] == 'EF1a'].copy()\n",
    "\n",
    "    #rename the Cq_mean column to EF1a_Cq_mean\n",
    "    df_EF1a.rename(columns={'Cq_mean': 'EF1a_Cq_mean'}, inplace=True)\n",
    "    #filter other df_EF1a columns\n",
    "    df_EF1a = df_EF1a[['Sample','EF1a_Cq_mean']]\n",
    "    #remove duplicates from df_EF1a\n",
    "    df_EF1a = df_EF1a.drop_duplicates()\n",
    "    \n",
    "    #merge the two dfs together\n",
    "    df = pd.merge(df, df_EF1a, on=['Sample'], how='left')\n",
    "    \n",
    "\n",
    "    #normalise based on eEF1a gene\n",
    "    df = normalise_data(df, 'Cq_mean','EF1a_Cq_mean','MeanCq_ECnormalised')\n",
    "    #filter columns\n",
    "    df = df[['Sample','Target','Cq_mean','MeanCq_ECnormalised']]\n",
    "    #remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "\n",
    "    #normalise to sample 125-4AH on each plate (plate normalisation so can compare between plates)\n",
    "    #get 125-4AH NIR1 10mM nitrate sample MeanCq_ECnormalised\n",
    "    #sample_125_4AH = df[(df.Sample == '125-4AH')&(df.Target == \"NIR1\")].MeanCq_ECnormalised.values[0]\n",
    "    #print(f'{sample_125_4AH}')\n",
    "    #normalise\n",
    "    #df.loc[:,'MeanCq_EC_plate_calibrated'] = df['MeanCq_ECnormalised'] - sample_125_4AH\n",
    "    #remove nan values in the new column\n",
    "    #df = df[df['MeanCq_EC_plate_calibrated'].notna()]\n",
    "    #not doing a plate calibration step for now\n",
    "    df = df.rename(columns={'MeanCq_ECnormalised': 'MeanCq_EC_plate_calibrated'})\n",
    "    #add column with name\n",
    "    df['plateID'] = name\n",
    "   \n",
    "   # print(df)\n",
    "    #if Sample column ends with NRT, add NRT_Cq column\n",
    "    df['NRT'] = False\n",
    "    df.loc[df['Sample'].str.endswith('NRT'), 'NRT'] = True\n",
    "    #remove NRT string from Sample columns ending with NRT\n",
    "    df['Sample'] = df['Sample'].str.replace('NRT', '')\n",
    "    \n",
    "    \n",
    "    #if Sample column ends with H, add condition column with 10mM_nitrate\n",
    "    df['condition'] = np.nan\n",
    "    df.loc[df['Sample'].str.endswith('H'), 'condition'] = '10mM_nitrate'\n",
    "    #remove H string from Sample columns ending with H\n",
    "    df['Sample'] = df['Sample'].str.replace('H', '')\n",
    "\n",
    "    #if Sample column ends with L, add condition column with 1mM_nitrate\n",
    "    df.loc[df['Sample'].str.endswith('L'), 'condition'] = '1mM_nitrate'\n",
    "    #remove L string from Sample columns ending with L\n",
    "    df['Sample'] = df['Sample'].str.replace('L', '')\n",
    "    #remove A, B or C string from Sample columns ending with A, B or C\n",
    "    df.loc[:, 'Sample_old'] = df['Sample']\n",
    "    df['Sample'] = df['Sample'].str.replace('A', '')\n",
    "    df['Sample'] = df['Sample'].str.replace('B', '')\n",
    "    #remove C string from Sample columns ending with C after the dash\n",
    "    df['Sample'] = df['Sample'].str.replace('C', '')\n",
    "    #remove whitespace from Sample columns\n",
    "    df['Sample'] = df['Sample'].str.strip()\n",
    "    #if sample is \"ol-0\", rename to Col-0\n",
    "    df.loc[df['Sample'] == 'ol-0', 'Sample'] = 'Col-0'\n",
    "    \n",
    " \n",
    "    #now make a df containing only Samples with 1mM_nitrate condition\n",
    "    df_1mM_nitrate = df.loc[df['condition'] == '1mM_nitrate'].copy()\n",
    "\n",
    "    #make new column that is the Mean expression across all biological replicates\n",
    "    df_1mM_nitrate['Mean_biological_Cq_ECnormalised'] = df_1mM_nitrate.groupby(['Sample','Target', 'condition'])['MeanCq_EC_plate_calibrated'].transform('mean')\n",
    "\n",
    "\n",
    "    #rename Mean_biological_Cq_ECnormalised column to 1mMnitrate_Cq_mean\n",
    "    df_1mM_nitrate.rename(columns={'Mean_biological_Cq_ECnormalised': '1mMnitrate_Cq_mean'}, inplace=True)\n",
    "    #filter other columns\n",
    "    df_1mM_nitrate = df_1mM_nitrate[['Sample_old','Target','1mMnitrate_Cq_mean']]\n",
    "    #remove duplicates from df_1mM_nitrate\n",
    "    df_1mM_nitrate = df_1mM_nitrate.drop_duplicates()\n",
    "    #merge the dfs\n",
    "    df = pd.merge(df, df_1mM_nitrate, on=['Sample_old','Target'], how='left')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    #remove nan\n",
    "    #df = df.dropna()\n",
    "\n",
    "    #remove NRT values\n",
    "    df = df.loc[df['NRT'] == False]\n",
    "    #filter out sample 125-4AH\n",
    "    #f = df.loc[df['Sample'] != '125-4']\n",
    "    #filter out target ARF18\n",
    "    #df = df.loc[df['Target'] != 'ARF18']\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to analyse data and make plots\n",
    "def analyse_data(df_plant,sample_name, fontsize,qpcr_df,combined_output_dir,normal,sample_order):\n",
    "    \"\"\"function to run anovas and make boxplots\"\"\"\n",
    "    #anova_PR <- lm(logPR ~ Genotype*NO3_Level + Plate, data = Roots1)\n",
    "    #change -inf values to NaN using .loc\n",
    "    df_plant.loc[df_plant['log_PR'] == -np.inf, 'log_PR'] = np.nan\n",
    "    df_plant.loc[df_plant['log_LR'] == -np.inf, 'log_LR'] = np.nan\n",
    "    df_plant.loc[df_plant['log_LRL'] == -np.inf, 'log_LRL'] = np.nan\n",
    "    df_plant.loc[df_plant['log_ALRL'] == -np.inf, 'log_ALRL'] = np.nan\n",
    "    df_plant.loc[df_plant['log_TRL'] == -np.inf, 'log_TRL'] = np.nan\n",
    "    df_plant.loc[df_plant['log_LRD'] == -np.inf, 'log_LRD'] = np.nan\n",
    "    df_plant.loc[df_plant['log_LRL_div_TRL'] == -np.inf, 'log_LRL_div_TRL'] = np.nan\n",
    "    df_plant.loc[df_plant['log_LR_2nd_order'] == -np.inf, 'log_LR_2nd_order'] = np.nan\n",
    "    df_plant.loc[df_plant['log_LRL_2nd_order'] == -np.inf, 'log_LRL_2nd_order'] = np.nan\n",
    "   \n",
    "\n",
    "    # anova_PR = smf.ols('PR ~ genotype*nitrate_concentration + plate', data=df_plant).fit()\n",
    "    #check anova assumptions\n",
    "    # print(anova_PR.summary())\n",
    "    # fig = sm.qqplot(anova_PR.resid, line='s')\n",
    "    #save figure\n",
    "    #make directory for the plots to be exported to\n",
    "    # output_dir = f'{output_location}/qqplots'\n",
    "    \n",
    "        \n",
    "    # fig.savefig(f'{output_location}/qqplots/qqplot_PR.png')\n",
    "    #log_PR residuals look mainly normal from the qqplot, (points at the extreme ends can be discounted)\n",
    "    variables = ['PR','log_PR','LR','log_LR','LRL','log_LRL','ALRL','log_ALRL','TRL','log_TRL','LRD','log_LRD','LRL_div_TRL','log_LRL_div_TRL','LR_2nd_order','log_LR_2nd_order','LRL_2nd_order','log_LRL_2nd_order']\n",
    "    #variables_logs = ['log_PR','log_LR','log_LRL','log_ALRL','log_TRL','log_LRD','log_LRL_div_TRL','log_LR_2nd_order','log_LRL_2nd_order']\n",
    "    variables_logs_dict = {'log_PR':'Primary root length (cm)','log_LR':'Number of lateral roots','log_LRL':'Total lateral root length (cm)','log_ALRL':'Average lateral root length (cm)','log_TRL':'Total root length (cm)','log_LRD':'Lateral root density','log_LRL_div_TRL':'Ratio of lateral root length to\\ntotal root length (LRL/TRL)',}#'log_LR_2nd_order':'Number of second order lateral roots','log_LRL_2nd_order':'Second order lateral root length (cm)'\n",
    "    # qqplots(df_plant,variables,sample_name, output_dir, fontsize)\n",
    "    #I will only use log transformed data\n",
    "    #run anovas and calculate marginal effects for interaction genotype*nitrate_concentration\n",
    "    \n",
    "    marginal_effects(df_plant,variables_logs_dict, sample_name ,fontsize, qpcr_df,combined_output_dir,normal,sample_order)\n",
    "    return df_plant\n",
    "\n",
    "\n",
    "\n",
    "    # ANOVA table using bioinfokit v1.0.3 or later (it uses wrapper script for anova_lm)\n",
    "\n",
    "    # res = stat()\n",
    "    # res.anova_stat(df=df_plant, res_var='PR', anova_model='PR ~ genotype*nitrate_concentration + plate')\n",
    "    # res.anova_summary\n",
    "    # #generate QQ-plot from standardized residuals\n",
    "    # # res.anova_std_residuals are standardized residuals obtained from ANOVA (check above)\n",
    "    # # sm.qqplot(res.anova_std_residuals, line='45')\n",
    "    # # plt.xlabel(\"Theoretical Quantiles\")\n",
    "    # # plt.ylabel(\"Standardized Residuals\")\n",
    "    # # plt.show()\n",
    "    # res.qq_plot(df=df_plant, res_var='PR', anova_model='PR ~ genotype*nitrate_concentration + plate')\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make individual plots\n",
    "def make_plots(df_new, normal,sample, fig, ax, target):\n",
    "    \"\"\"function to make barplots of relative expression of each target gene in each plant line\"\"\"\n",
    "    # #plot height and width\n",
    "    # height = 4.5\n",
    "    # width = 3\n",
    "   # print(df_new)\n",
    "\n",
    "    #decide on stats test\n",
    "    if normal is True:\n",
    "        stats_test = 't-test_ind'\n",
    "    if normal is False:\n",
    "        stats_test = 't-test_welch'\n",
    "\n",
    "\n",
    "    #make individual plots\n",
    "     \n",
    "\n",
    "    # create box pairs\n",
    "    # pairs = [(('Col-0','1'),(sample,'1')),(('Col-0','10'),(sample,'10')), (('Col-0','1'),('Col-0','10')), ((sample,'1'),(sample,'10'))]\n",
    "    pairs = [(('1','Col-0'),('1',sample)),(('10','Col-0'),('10',sample)), (('1','Col-0'),('10','Col-0')), (('1',sample),('10',sample))]\n",
    "\n",
    "    #order = ['Col-0',sample]\n",
    "    order = ['1','10']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #make plot\n",
    "    fig_args = {'x':'condition', 'y':'relative_expression','hue':'Sample', 'hue_order':['Col-0',sample],'data':df_new, 'order':order, 'dodge':True}#'ax':ax\n",
    "\n",
    "    configuration = {'test':stats_test, 'text_format':'star', 'pvalue_thresholds':[[1e-3, \"***\"],[1e-2, \"**\"],[0.05, \"*\"],[1, \"ns\"]]}\n",
    "\n",
    "   # _ = plt.figure(figsize=(width,height))\n",
    "\n",
    "    sns.barplot(**fig_args, palette=[\"white\", \"grey\"],linewidth=2,  errcolor=\"black\", edgecolor=\"black\", ci=68, errwidth=1,capsize=0.4,ax=ax)\n",
    "    sns.swarmplot(**fig_args, color='black',ax=ax, palette=['black','black'])\n",
    "    \n",
    "    #fig = sns.barplot(x='Sample', y='relative_expression', data=temp_df, order=order, linewidth=2,  errcolor=\"black\", edgecolor=\"black\", ci=68, errwidth=1,capsize=0.4,color='cyan')\n",
    "\n",
    "    #fig = sns.swarmplot(x='condition', y='relative_expression', data=temp_df, order=order,color='black')\n",
    "\n",
    "    #add stats\n",
    "    annotator = Annotator(ax, pairs, **fig_args,verbose=False, show_non_significant=False)\n",
    "    annotator.configure(**configuration)\n",
    "    # # annotator = Annotator(fig, pairs, data=temp_df, x='condition', y='relative_expression',order=order,verbose=False)\n",
    "    # # annotator.configure(test=stats_test, text_format='star',pvalue_thresholds=[[1e-3, \"***\"],[1e-2, \"**\"],[0.05, \"*\"],[1, \"ns\"]])\n",
    "    \n",
    "    # #save stats to file\n",
    "    ax, test_results = annotator.apply_and_annotate()\n",
    "    # with open(f'{location}/individual/stats.txt', 'a') as f:                            \n",
    "    #     for res in test_results:\n",
    "    #         f.write(f'{str(sample)},{target},{pairs},{str(res.data)}\\n')\n",
    "    \n",
    "    # # change axes labels\n",
    "    _ = ax.set_ylabel('Relative expression (a.u.)')\n",
    "    \n",
    "    #max 1 decimal place y tick labels\n",
    "    # fig.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    #add plot title\n",
    "    _ = ax.set_title(f'{target}')\n",
    "\n",
    "    #rename x axis labels\n",
    "    _ = ax.set_xticklabels( ('1','10') )\n",
    "    #change x axis name\n",
    "    _ = ax.set_xlabel(r'KNO$_{3}$ concentration (mM)')\n",
    "\n",
    "    #make xticks diagonal\n",
    "    # _ = plt.xticks(rotation=90, ha='center')\n",
    "\n",
    "    #plot legend, excluding legend from swarm plot\n",
    "    h,l = ax.get_legend_handles_labels()\n",
    "    #change name of label\n",
    "    #l[3] = \"10 mM nitrate\"\n",
    "    l[3] = sample\n",
    "    l[2] = \"Col-0\"\n",
    "    #l[2] = \"20 mM KNO\\u2083 + 20 mM NH\\u2083NO\\u2083\"   \n",
    "    #l[2] = \"1 mM nitrate\"     \n",
    "    ax.legend(h[2:4],l[2:4],frameon=False,loc='best')#fontsize=fontsize,,bbox_to_anchor=(0,0.85), loc='best',,bbox_to_anchor=(0.6,0.95) ,ncol=len(df_new.Sample.unique()), columnspacing=0.8\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function\n",
    "def main():\n",
    "    #read in arguments\n",
    "    #input_dir = args.input\n",
    "    input_dir = '../../data/CRISPR_library/images/rsa_output'\n",
    "    #output_dir = args.output\n",
    "    output_dir = '../../data/CRISPR_library'\n",
    "    #make directory for the plots to be exported to\n",
    "    combined_output_dir = f'{output_dir}/characteristics_plots'\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir(combined_output_dir)\n",
    "        print(\"Directory \" , combined_output_dir ,  \" created\") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , combined_output_dir ,  \" already exists\")\n",
    "\n",
    "\n",
    "\n",
    "    #read in and concatenate .csv files\n",
    "    df_rsa = concat_csv_recursive(input_dir, '*.csv')\n",
    "    #print(df.head())\n",
    "\n",
    "    \n",
    "    #sort data\n",
    "    df_rsa,df_plant = sort_data(df_rsa,output_dir)\n",
    "    #analyse dataframe and make plots\n",
    "    #analyse_data(output_dir)\n",
    "    #set matplotlib rc parameters\n",
    "    fontsize = set_rc_params()\n",
    "    #first split into separate dataframes for each sample_name\n",
    "    #then analyse each dataframe and make plots\n",
    "\n",
    "    # if __name__ == \"__main__\" function\n",
    "\n",
    "    location = '../../data/CRISPR_library/qPCR'\n",
    "    csv_file1 = f'{location}/06.09.22/06.09.22_plate1_19310threshold.csv'\n",
    "    csv_file2 = f'{location}/06.09.22/06.09.22_plate2_19310threshold.csv'\n",
    "    csv_file3 = f'{location}/06.09.22/06.09.22_plate3_19310threshold.csv'\n",
    "    #read in files\n",
    "    df1 = read_csv(csv_file1)\n",
    "    df2 = read_csv(csv_file2)\n",
    "    df3 = read_csv(csv_file3)\n",
    "    #filter, sort and normalise to plate calibrator\n",
    "    def filter_sort_normalise(df,location,name):\n",
    "        #filter out the data points with amp_status = Amp and cq above 32\n",
    "        df = filter_data(df, 'Amp', 40)\n",
    "\n",
    "        \n",
    "        #sort the data, and normalise to the eEF1a gene\n",
    "        df = sort_data_qpcr(df,location,name)\n",
    "        \n",
    "\n",
    "        return df\n",
    "    #filter, sort and normalise to plate calibrator\n",
    "    df1 = filter_sort_normalise(df1,location,\"06.09.22_plate1\")\n",
    "    #save df1 to file\n",
    "    #df1.to_csv(f'{location}/10.08.22/10.8.22_plate_test.csv')\n",
    "    #print(df1)\n",
    "\n",
    "    df2 = filter_sort_normalise(df2,location,\"06.09.22_plate2\")\n",
    "    #df2.to_csv(f'{location}/22.08.22_plate1_test.tsv',sep='\\t')\n",
    "    #print(df2)\n",
    "    df3 = filter_sort_normalise(df3,location,\"06.09.22_plate3\")\n",
    "\n",
    "    #merge the dfs\n",
    "    df = pd.concat([df1,df2,df3])\n",
    "    #sort by Sample, Target and condition\n",
    "    df = df.sort_values(by=['Sample','Target','condition'])\n",
    "    #save df to file\n",
    "    # df.to_csv(f'{location}/merged_plates.tsv', sep='\\t')\n",
    "    #make a copy of the df\n",
    "    df_col_norm = df.copy()\n",
    "\n",
    "    \n",
    "\n",
    "    #normalise based on 1mM_nitrate Cq values, mean between all 3 biological reps \n",
    "    df = normalise_data(df, 'MeanCq_EC_plate_calibrated','1mMnitrate_Cq_mean','MeanCq_EC_1mM_nitrate_normalised')\n",
    "    #now filter columns\n",
    "    df = df[['Sample','Target','MeanCq_EC_1mM_nitrate_normalised','condition']]\n",
    "\n",
    "    #first do inverse log transformation\n",
    "    #(fold change of GOI in treated sample if delta delta Ct value  = X then relative expression  = 2 ( to the power of X))\n",
    "    #df['relative_expression'] = 2**(df['MeanCq_ECnormalised'])\n",
    "    df['relative_expression'] = 2**(df['MeanCq_EC_1mM_nitrate_normalised'])\n",
    "    #save df to tsv\n",
    "    # df.to_csv('../../data/CRISPR_library/qPCR/merged_plates_19310threshold_normEC1mMnitrate_relative_expression.tsv', sep='\\t', index=False)\n",
    "\n",
    "    #Normalise to 1mM_nitrate Col-0 within each original plate\n",
    "    #now make a df containing only Col-0 Samples with 1mM_nitrate condition\n",
    "    df_col_1mM_nitrate = df_col_norm.loc[(df_col_norm['condition'] == '1mM_nitrate') & (df_col_norm.Sample=='Col-0')].copy()\n",
    "\n",
    "    #make new column that is the Mean Col-0 1mM expression across biological replicates for that target on each plate\n",
    "    df_col_1mM_nitrate['Mean_biological_Cq_ECnormalised'] = df_col_1mM_nitrate.groupby(['Sample','Target', 'condition','plateID'])['MeanCq_EC_plate_calibrated'].transform('mean')\n",
    "\n",
    "\n",
    "    #rename Mean_biological_Cq_ECnormalised column to Col0_1mMnitrate_Cq_mean\n",
    "    df_col_1mM_nitrate.rename(columns={'Mean_biological_Cq_ECnormalised': 'Col0_1mMnitrate_Cq_mean'}, inplace=True)\n",
    "    #filter other columns\n",
    "    df_col_1mM_nitrate = df_col_1mM_nitrate[['Sample_old','Target','Col0_1mMnitrate_Cq_mean','plateID']]\n",
    "    #remove duplicates from df_col_1mM_nitrate\n",
    "    df_col_1mM_nitrate = df_col_1mM_nitrate.drop_duplicates()\n",
    "    #merge the dfs, putting the Col-0 1mM nitrate mean values for each target across all plant lines within each plate\n",
    "    df_col_norm = pd.merge(df_col_norm, df_col_1mM_nitrate, on=['Target', 'plateID'], how='left')\n",
    "    #save df to file\n",
    "    df_col_norm.to_csv('../../data/CRISPR_library/qPCR/merged_plates_19310threshold_norm_col0_1mMnitrate.tsv', sep='\\t', index=False)\n",
    "    #normalise based on Col0_1mMnitrate_Cq_mean Cq values, mean between all 3 biological reps \n",
    "    df_col_norm = normalise_data(df_col_norm, 'MeanCq_EC_plate_calibrated','Col0_1mMnitrate_Cq_mean','MeanCq_EC_Col0_1mM_nitrate_normalised')\n",
    "    #print(df_col_norm)\n",
    "    #now filter columns\n",
    "    df_col_norm = df_col_norm[['Sample','Target','MeanCq_EC_Col0_1mM_nitrate_normalised','condition', 'plateID']]\n",
    "\n",
    "\n",
    "    # #first do inverse log transformation\n",
    "    # #(fold change of GOI in treated sample if delta delta Ct value  = X then relative expression  = 2 ( to the power of X))\n",
    "    # #df['relative_expression'] = 2**(df['MeanCq_ECnormalised'])\n",
    "    df_col_norm['relative_expression'] = 2**(df_col_norm['MeanCq_EC_Col0_1mM_nitrate_normalised'])\n",
    "    #remove duplicates\n",
    "    df_col_norm = df_col_norm.drop_duplicates()\n",
    "\n",
    "    #set matplotlib rc parameters\n",
    "    fontsize = set_rc_params()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    #test for normality of data - Shapiro-Wilk test\n",
    "    #test_normality(df)\n",
    "    normality = test_normality(df_col_norm, location)\n",
    "\n",
    "    #check if any of the p values are less than 0.05 (not normal)\n",
    "    significant = normality[normality['pvalue'] < 0.05]\n",
    "    if significant.empty:\n",
    "        print('all p values are greater than 0.05, data is normal, using independent t-test')\n",
    "        normal = True\n",
    "    if not significant.empty:\n",
    "        print('some p values are less than 0.05, data is not normal, using welchs t-test')\n",
    "        normal = False\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "    #sample order in the plots\n",
    "    sample_order = ['Col-0','69-9','125-4','127-10','130-4','134-3','139-9','142-4','142-8','144-5','154-4']\n",
    "    sample_order_col0 = ['Col-0','69-9','125-4','127-10','130-4','134-3','139-9','142-4','142-8','144-5','154-4','Col-0_highnitrate','69-9_highnitrate','125-4_highnitrate','127-10_highnitrate','130-4_highnitrate','134-3_highnitrate','139-9_highnitrate','142-4_highnitrate','142-8_highnitrate','144-5_highnitrate','154-4_highnitrate']\n",
    "    #individual plots compare between 1 and 10mM nitrate, and only show Col-0 from that plate if present on that plate, otherwise show all Col-0 samples from other two plates\n",
    "\n",
    "    #compare between 1 and 10mM nitrate\n",
    "    # make_combined_plots(df_col_norm,f'{location}/plots', normal,sample_order,fontsize)\n",
    "    # #make plots compared to Col-0 1 and 10mM nitrate\n",
    "    # make_combined_plots_col0(df_col_norm,f'{location}/plots', normal,sample_order_col0,fontsize)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    qpcr_df = df_col_norm.copy()\n",
    "    for sample_name in df_plant['sample_name'].unique():\n",
    "        #get dataframe for each sample_name\n",
    "        df_sample = df_plant[df_plant['sample_name'] == sample_name].copy()\n",
    "        #analyse dataframe and make plots\n",
    "        analyse_data(df_sample,sample_name,fontsize,qpcr_df,combined_output_dir,normal,sample_order)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #analyse_data(df_plant, output_dir)\n",
    "    \n",
    "    #save dataframe to csv file\n",
    "    # df_rsa.to_csv(f'{output_dir}/all_smartroot_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ../../data/CRISPR_library/characteristics_plots  already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/series.py:726: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/scipy/stats/_morestats.py:1797: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some p values are less than 0.05, data is not normal, using welchs t-test\n",
      "number of subplots for 125-4= 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subplots for 130-4= 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subplots for 134-3= 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subplots for 139-9= 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subplots for 69-9= 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('qpcr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c2acf9d6025fe51d3e4a4cb09a2ff19b54eaae2da571c8e6469319b5fd828be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
