{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from matplotlib import rcParams\n",
    "from statannotations.Annotator import Annotator\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy import stats\n",
    "rcParams.update({'figure.autolayout': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to read in csv file as pandas df\n",
    "def read_csv(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    #keep the Well, Sample, Target, Cq and Amp Status columns\n",
    "    df = df[['Well', 'Sample', 'Target', 'Cq', 'Amp Status']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #returns test statistic, p-value\n",
    "# for name1 in prom_names_plate1:\n",
    "#     for name in names_plate1:\n",
    "#         print(name1,'{}: {}'.format(name, stats.shapiro(luminescence_raw_df_plate1['nluc/fluc'][luminescence_raw_df_plate1.TF_added == name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for normality of the data\n",
    "def test_normality(df, location):\n",
    "    \"\"\"run Shapiro-Wilk test\"\"\"\n",
    "    #iterate over rows\n",
    "    #get sample names\n",
    "    sample_names = df['Sample'].unique()\n",
    "    #get Target names\n",
    "    target_names = df['Target'].unique()\n",
    "    #iterate over samples and targets\n",
    "    #make empty df to store p-values\n",
    "    p_values = pd.DataFrame(columns=['Sample', 'Target', 'pvalue'])\n",
    "    for sample in sample_names:\n",
    "        for target in target_names:\n",
    "            # #run Shapiro-Wilk test\n",
    "           # print(sample,'{}: {}'.format(target, stats.shapiro(df['relative_expression'][df.Target == target])))\n",
    "            #write a df with the results of the Shapiro-Wilk test\n",
    "            #shapiro_df = pd.DataFrame(columns=['Sample', 'Target', 'p-value'])\n",
    "            #results = sample,target,'{}'.format(stats.shapiro(df['relative_expression'][df.Target == target]))\n",
    "            results = sample,target,stats.shapiro(df['relative_expression'][df.Target == target])\n",
    "            #('125-4', 'NLP7: ShapiroResult(statistic=0.707939088344574, pvalue=9.890874935081229e-05)')\n",
    "            shapiro_df = pd.DataFrame([results], columns=['Sample','Target', 'shapiro_test']).reset_index(drop=True)\n",
    "            #get statistic and pvalue\n",
    "            shapiro_df['statistic'] = shapiro_df['shapiro_test'].apply(lambda x: x[0])\n",
    "            shapiro_df['pvalue'] = shapiro_df['shapiro_test'].apply(lambda x: x[1])\n",
    "            #filter columns\n",
    "            shapiro_df = shapiro_df[['Sample', 'Target', 'pvalue', 'statistic',]]\n",
    "            #append to p_values df\n",
    "            p_values = pd.concat([p_values, shapiro_df], axis=0, ignore_index=True)\n",
    "\n",
    "    #write to tsv\n",
    "    p_values.to_csv(f'{location}/shapiro_normality.tsv', sep='\\t', index=False)\n",
    "\n",
    "    return p_values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to filter out certain data points\n",
    "def filter_data(df, amp_status, cq):\n",
    "    #filter out the data points with amp_status = Amp using .loc\n",
    "    df = df.loc[df['Amp Status'] == amp_status]\n",
    "    #make Cq column numerical\n",
    "    dfcopy = df.copy()\n",
    "    dfcopy['Cq'] = pd.to_numeric(dfcopy['Cq'])  \n",
    "    #filter out the data points with cq < cq_threshold using .loc\n",
    "    dfcopy = dfcopy.loc[dfcopy['Cq'] <= cq]\n",
    "\n",
    "    return dfcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idea from https://www.nature.com/articles/s41598-021-99727-6#Sec2\n",
    "#To detect outliers, the CT standard deviation (Cq-SD) of the technical replicates for a given sample is calculated, if the Cq-SD is greater than the cut-off (the default value is 0.3), then the technical replicate furthest from the sample mean is removed. The process occurs recursively until the Cq-SD is less than the cut-off or the value of “max outliers” is reached. This is determined by the parameter ‘Max Proportion’, the 0.5 default means that outliers will be removed until two technical replicates remain. The ‘preserve highly variable replicates’: If the Cq-SD is higher than 0.3, but the absolute (mean-median)/median is less than 0.1, replicates are preserved. This helps to account for a lack of a clear outlier, where two of three replicates are close to equally distributed around the mean.\n",
    "def remove_outliers(df, max_outliers, ct_sd_threshold):\n",
    "    \n",
    "    #copy the dataframe\n",
    "    dfcopy = df.copy()\n",
    "    # Add filter columns\n",
    "    dfcopy['Ignore'] = False\n",
    "    #dfcopy['Cq-SD'] = int()\n",
    "    \n",
    "    #make Cq column numerical\n",
    "    dfcopy['Cq'] = pd.to_numeric(dfcopy['Cq'])\n",
    "    #calculate the Cq-SD of the technical replicates for a given sample\n",
    "    f = (dfcopy['Ignore'].eq(False))\n",
    "    dfcopy1 = dfcopy[f].groupby(['Sample','Target']).agg({'Cq':['std']})\n",
    "    #dfcopy = dfcopy[f].groupby(['Sample','Target']).agg({'Cq-SD':['std']})#['Cq'].transform(lambda x: x.std() / np.sqrt(x.count()))\n",
    "    #make df containing all samples with outliers\n",
    "    f = dfcopy1['Cq']['std'] > ct_sd_threshold\n",
    "    dfcopy_outliers = dfcopy1[f]\n",
    "\n",
    "    \n",
    "    # dfcopy_outliers = dfcopy[dfcopy['Cq-SD'] > ct_sd_threshold]\n",
    "    if not dfcopy_outliers.empty:\n",
    "        #mark all outliers\n",
    "        #iterate over rows as tuples (sample, target)\n",
    "        for i, row in enumerate(dfcopy_outliers.itertuples(name = None),1):\n",
    "            #example row: (('144-5AH', 'DREB26'), 0.6497278066418295)\n",
    "         \n",
    "           \n",
    "            #check that the dfcopy sample name is the same as the sample name in the current row\n",
    "            f = (dfcopy.Sample == row[0][0]) & (dfcopy.Target == row[0][1]) & (dfcopy['Ignore'].eq(False))\n",
    "            dx_idx = dfcopy[f].index\n",
    "            group_size = len(dx_idx)\n",
    "            min_size = round(group_size * (1-max_outliers))\n",
    "            size = group_size\n",
    "            if min_size < 2:\n",
    "                min_size = 2\n",
    "                print('Warning: minimum size of technical replicate group is 2')\n",
    "            while True:\n",
    "                f = (dfcopy.Sample == row[0][0]) & (dfcopy.Target == row[0][1])\n",
    "                dx = dfcopy[f].copy()\n",
    "                dxg = dfcopy[f].groupby(['Sample', 'Target']).agg({'Cq': [np.size, 'std', 'mean']})\n",
    "                if dxg['Cq']['std'].iloc[0] <= ct_sd_threshold:\n",
    "                    #Cq std is under threshold, so no outliers\n",
    "                    break\n",
    "                size -= 1\n",
    "                if size < min_size:\n",
    "                    #not enough technical replicates to remove outliers\n",
    "                    break\n",
    "                #remove the technical replicate furthest from the mean\n",
    "                dx['Distance'] = (dx['Cq'] - dxg['Cq']['mean'].iloc[0])**2\n",
    "                dx_sorted = dx.sort_values(by = 'Distance', ascending=False).index[0]\n",
    "                #print()\n",
    "                #dfcopy = dfcopy.loc[dx_sorted].assign(Ignore=True)\n",
    "                #dfcopy.loc[dx_sorted].loc(:, 'Ignore') = True\n",
    "                #print(dx_sorted)\n",
    "                dfcopy.loc[[dx_sorted], 'Ignore'] = True\n",
    "                #dfcopy['Ignore'].loc[dx_sorted] = True\n",
    "                #rint(dx_sorted)\n",
    "                \n",
    "    return dfcopy\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "   \n",
    "    # #remove the highly variable replicates\n",
    "    # if preserve_highly_variable_replicates == True:\n",
    "    #     dfcopy = dfcopy.loc[dfcopy['Cq-SD'] > ct_sd_threshold]\n",
    "    #     dfcopy = dfcopy.loc[dfcopy['Cq-SD'] < (dfcopy['Cq-SD'].mean() - dfcopy['Cq-SD'].median())/dfcopy['Cq-SD'].median()]\n",
    "    # #remove the outliers until the number of outliers is less than max_outliers\n",
    "    # while dfcopy['Cq-SD'].count() > max_outliers:\n",
    "    #     dfcopy = dfcopy.loc[dfcopy['Cq-SD'] < ct_sd_threshold]\n",
    "    #     if preserve_highly_variable_replicates == True:\n",
    "    #         dfcopy = dfcopy.loc[dfcopy['Cq-SD'] > ct_sd_threshold]\n",
    "    #         dfcopy = dfcopy.loc[dfcopy['Cq-SD'] < (dfcopy['Cq-SD'].mean() - dfcopy['Cq-SD'].median())/dfcopy['Cq-SD'].median()]\n",
    "    # return dfcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to make new columns and sort the data\n",
    "def sort_data(df, location, name):\n",
    "    #make new column called EF1a_Cq, make the value in this column for a particular sample equal to the Cq value for the EF1a Target for that sample\n",
    "    ##remove if not amplified\n",
    "    df = df.loc[df['Amp Status'] == 'Amp']\n",
    "    \n",
    "\n",
    "    #first remove outliers\n",
    "    df = remove_outliers(df, 0.5, 0.3)\n",
    "    #save outliers df to tsv\n",
    "    df.to_csv(f'{location}/including_outliers_{name}.tsv', sep='\\t', index=False)\n",
    "    #remove outliers\n",
    "    df = df.loc[df['Ignore'] == False]    \n",
    "    #get the mean of each sample/target (take mean of technical replicates)\n",
    "    df['Cq_mean'] = df.groupby(['Sample','Target'])['Cq'].transform('mean')\n",
    "    #make a df containing only EF1a target (housekeeping gene)\n",
    "    df_EF1a = df.loc[df['Target'] == 'EF1a'].copy()\n",
    "\n",
    "    #rename the Cq_mean column to EF1a_Cq_mean\n",
    "    df_EF1a.rename(columns={'Cq_mean': 'EF1a_Cq_mean'}, inplace=True)\n",
    "    #filter other df_EF1a columns\n",
    "    df_EF1a = df_EF1a[['Sample','EF1a_Cq_mean']]\n",
    "    #remove duplicates from df_EF1a\n",
    "    df_EF1a = df_EF1a.drop_duplicates()\n",
    "    \n",
    "    #merge the two dfs together\n",
    "    df = pd.merge(df, df_EF1a, on=['Sample'], how='left')\n",
    "    \n",
    "\n",
    "    #normalise based on eEF1a gene\n",
    "    df = normalise_data(df, 'Cq_mean','EF1a_Cq_mean','MeanCq_ECnormalised')\n",
    "    #filter columns\n",
    "    df = df[['Sample','Target','Cq_mean','MeanCq_ECnormalised']]\n",
    "    #remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "\n",
    "    #normalise to sample 125-4AH on each plate (plate normalisation so can compare between plates)\n",
    "    #get 125-4AH NIR1 10mM nitrate sample MeanCq_ECnormalised\n",
    "    #sample_125_4AH = df[(df.Sample == '125-4AH')&(df.Target == \"NIR1\")].MeanCq_ECnormalised.values[0]\n",
    "    #print(f'{sample_125_4AH}')\n",
    "    #normalise\n",
    "    #df.loc[:,'MeanCq_EC_plate_calibrated'] = df['MeanCq_ECnormalised'] - sample_125_4AH\n",
    "    #remove nan values in the new column\n",
    "    #df = df[df['MeanCq_EC_plate_calibrated'].notna()]\n",
    "    #not doing a plate calibration step for now\n",
    "    df = df.rename(columns={'MeanCq_ECnormalised': 'MeanCq_EC_plate_calibrated'})\n",
    "    #add column with name\n",
    "    df['plateID'] = name\n",
    "   \n",
    "   # print(df)\n",
    "    #if Sample column ends with NRT, add NRT_Cq column\n",
    "    df['NRT'] = False\n",
    "    df.loc[df['Sample'].str.endswith('NRT'), 'NRT'] = True\n",
    "    #remove NRT string from Sample columns ending with NRT\n",
    "    df['Sample'] = df['Sample'].str.replace('NRT', '')\n",
    "    \n",
    "    \n",
    "    #if Sample column ends with H, add condition column with 10mM_nitrate\n",
    "    df['condition'] = np.nan\n",
    "    df.loc[df['Sample'].str.endswith('H'), 'condition'] = '10mM_nitrate'\n",
    "    #remove H string from Sample columns ending with H\n",
    "    df['Sample'] = df['Sample'].str.replace('H', '')\n",
    "\n",
    "    #if Sample column ends with L, add condition column with 1mM_nitrate\n",
    "    df.loc[df['Sample'].str.endswith('L'), 'condition'] = '1mM_nitrate'\n",
    "    #remove L string from Sample columns ending with L\n",
    "    df['Sample'] = df['Sample'].str.replace('L', '')\n",
    "    #remove A, B or C string from Sample columns ending with A, B or C\n",
    "    df.loc[:, 'Sample_old'] = df['Sample']\n",
    "    df['Sample'] = df['Sample'].str.replace('A', '')\n",
    "    df['Sample'] = df['Sample'].str.replace('B', '')\n",
    "    #remove C string from Sample columns ending with C after the dash\n",
    "    df['Sample'] = df['Sample'].str.replace('C', '')\n",
    "    #remove whitespace from Sample columns\n",
    "    df['Sample'] = df['Sample'].str.strip()\n",
    "    #if sample is \"ol-0\", rename to Col-0\n",
    "    df.loc[df['Sample'] == 'ol-0', 'Sample'] = 'Col-0'\n",
    "    \n",
    " \n",
    "    #now make a df containing only Samples with 1mM_nitrate condition\n",
    "    df_1mM_nitrate = df.loc[df['condition'] == '1mM_nitrate'].copy()\n",
    "\n",
    "    #make new column that is the Mean expression across all biological replicates\n",
    "    df_1mM_nitrate['Mean_biological_Cq_ECnormalised'] = df_1mM_nitrate.groupby(['Sample','Target', 'condition'])['MeanCq_EC_plate_calibrated'].transform('mean')\n",
    "\n",
    "\n",
    "    #rename Mean_biological_Cq_ECnormalised column to 1mMnitrate_Cq_mean\n",
    "    df_1mM_nitrate.rename(columns={'Mean_biological_Cq_ECnormalised': '1mMnitrate_Cq_mean'}, inplace=True)\n",
    "    #filter other columns\n",
    "    df_1mM_nitrate = df_1mM_nitrate[['Sample_old','Target','1mMnitrate_Cq_mean']]\n",
    "    #remove duplicates from df_1mM_nitrate\n",
    "    df_1mM_nitrate = df_1mM_nitrate.drop_duplicates()\n",
    "    #merge the dfs\n",
    "    df = pd.merge(df, df_1mM_nitrate, on=['Sample_old','Target'], how='left')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    #remove nan\n",
    "    #df = df.dropna()\n",
    "\n",
    "    #remove NRT values\n",
    "    df = df.loc[df['NRT'] == False]\n",
    "    #filter out sample 125-4AH\n",
    "    df = df.loc[df['Sample'] != '125-4']\n",
    "    #filter out target ARF18\n",
    "    df = df.loc[df['Target'] != 'ARF18']\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to normalise the data based on a column of Cq values (either to housekeeping or based on nitrate or wild type plant)\n",
    "def normalise_data(df, orig_col,normalisation_col, new_column_name):\n",
    "   \n",
    "    #normalise Cq values to the EF1a housekeeping gene mean Cq value for each sample\n",
    "    df.loc[:,new_column_name] = df[orig_col] - df[normalisation_col]\n",
    "    #remove nan values in the new column\n",
    "    df = df[df[new_column_name].notna()]\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make individual plots\n",
    "def make_plots(df,location, normal,sample_order):\n",
    "    \"\"\"function to make barplots of relative expression of each target gene in each plant line\"\"\"\n",
    "    #plot height and width\n",
    "    height = 5\n",
    "    width = 3.5\n",
    "\n",
    "    #decide on stats test\n",
    "    if normal is True:\n",
    "        stats_test = 't-test_ind'\n",
    "    if normal is False:\n",
    "        stats_test = 't-test_welch'\n",
    "\n",
    "\n",
    "    #make individual plots\n",
    "     \n",
    "    for target in df['Target'].unique():\n",
    "        #if target is not EF1a, make plot\n",
    "        if target != 'EF1a':            \n",
    "            temp_df = df[df.Target == target]\n",
    "            #change condition values\n",
    "            temp_df.loc[temp_df['condition'] == '10mM_nitrate', 'condition'] = '10'\n",
    "            temp_df.loc[temp_df['condition'] == '1mM_nitrate', 'condition'] = '1'\n",
    "\n",
    "\n",
    "            #get list of samples\n",
    "            samples_unique = temp_df['Sample'].unique()\n",
    "\n",
    "            \n",
    "\n",
    "            #sort based on custom order\n",
    "            samples = []\n",
    "            for i in range(len(sample_order)):\n",
    "                if sample_order[i] in samples_unique:\n",
    "                    samples+=[sample_order[i]]\n",
    "            #create new df with only sample of interest and Col-0 based on plateID so that Col-0 from the same plate is prioritised\n",
    "            #if temp_df plateID is \"22.08.22_plate1\"\n",
    "\n",
    "            for sample in samples:\n",
    "                if sample != 'Col-0':\n",
    "                    plateID_value = temp_df.loc[temp_df['Sample'] == sample, 'plateID'].values[0]\n",
    "                   # print(plateID_value)\n",
    "                    if plateID_value == '22.08.22_plate1':   \n",
    "                        #print(f'platevalueis{plateID_value}')                \n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | ((temp_df.Sample == 'Col-0') & (temp_df.plateID == plateID_value))]\n",
    "\n",
    "                    if plateID_value == '22.08.22_plate2':\n",
    "\n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | ((temp_df.Sample == 'Col-0') & (temp_df.plateID == plateID_value))]\n",
    "                    if plateID_value == '06.09.22_plate1':\n",
    "\n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | ((temp_df.Sample == 'Col-0') & (temp_df.plateID == plateID_value))]\n",
    "                    if plateID_value == '06.09.22_plate2':\n",
    "\n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | ((temp_df.Sample == 'Col-0') & (temp_df.plateID == plateID_value))]\n",
    "                    if plateID_value == '06.09.22_plate3':\n",
    "\n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | ((temp_df.Sample == 'Col-0') & (temp_df.plateID == plateID_value))]\n",
    "                    if plateID_value == '10.8.22':\n",
    "                        #include all col-0 values from both plates       \n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | (temp_df.Sample == 'Col-0')]\n",
    "                    #create box pairs\n",
    "                    pairs = [(('Col-0','1'),(sample,'1')),(('Col-0','10'),(sample,'10'))]\n",
    "\n",
    "                    order = ['Col-0',sample]\n",
    "\n",
    "\n",
    "                    #make figure\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # #get length of number of samples\n",
    "            # length_samples = len(samples)\n",
    "\n",
    "            # #create order and box pairs based on the length of TFs\n",
    "            # order = []\n",
    "            # box_pairs = []\n",
    "            # for x in range (0, (length_samples)):\n",
    "            #     order.append(samples[x])\n",
    "            #     # if 'Col-0' in samples:\n",
    "            #     #     if samples[x] != 'Col-0':\n",
    "            #     #         box_pairs.append(('col-0', samples[x]))\n",
    "            #     # if 'ol-0' not in samples:\n",
    "            #     box_pairs.append(((samples[x],'1'), (samples[x],'10')))\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            # order = ['1','10']\n",
    "            # #create box pairs\n",
    "            # pair = [('1', '10')]\n",
    "\n",
    "                    #make plot\n",
    "                    fig_args = {'x':'Sample', 'y':'relative_expression','hue':'condition', 'hue_order':['1','10'],'data':df_new, 'order':order, 'dodge':True}\n",
    "\n",
    "                    configuration = {'test':stats_test, 'text_format':'star', 'pvalue_thresholds':[[1e-3, \"***\"],[1e-2, \"**\"],[0.05, \"*\"],[1, \"ns\"]]}\n",
    "\n",
    "                    _ = plt.figure(figsize=(width,height))\n",
    "\n",
    "                    fig = sns.barplot(**fig_args, palette=[\"lightcyan\", \"cyan\"],linewidth=2,  errcolor=\"black\", edgecolor=\"black\", ci=68, errwidth=1,capsize=0.4)\n",
    "                    fig = sns.swarmplot(**fig_args, color='black')\n",
    "                    \n",
    "                    #fig = sns.barplot(x='Sample', y='relative_expression', data=temp_df, order=order, linewidth=2,  errcolor=\"black\", edgecolor=\"black\", ci=68, errwidth=1,capsize=0.4,color='cyan')\n",
    "\n",
    "                    #fig = sns.swarmplot(x='condition', y='relative_expression', data=temp_df, order=order,color='black')\n",
    "\n",
    "                    #add stats\n",
    "                    annotator = Annotator(fig, pairs, **fig_args,verbose=False)\n",
    "                    annotator.configure(**configuration)\n",
    "                    # annotator = Annotator(fig, pairs, data=temp_df, x='condition', y='relative_expression',order=order,verbose=False)\n",
    "                    # annotator.configure(test=stats_test, text_format='star',pvalue_thresholds=[[1e-3, \"***\"],[1e-2, \"**\"],[0.05, \"*\"],[1, \"ns\"]])\n",
    "                    \n",
    "                    #save stats to file\n",
    "                    ax, test_results = annotator.apply_and_annotate()\n",
    "                    with open(f'{location}/individual/stats.txt', 'a') as f:                            \n",
    "                        for res in test_results:\n",
    "                            f.write(f'{str(sample)},{target},{pairs},{str(res.data)}\\n')\n",
    "                    \n",
    "                    # change axes labels\n",
    "                    _ = plt.ylabel('Relative expression (a.u.)')\n",
    "                    \n",
    "                    \n",
    "                    #add plot title\n",
    "                    _ = plt.title(f'{target}')\n",
    "\n",
    "                    #rename x axis labels\n",
    "                    #_ = plt.set_xticklabels( ('1','10') )\n",
    "                    #change x axis name\n",
    "                    _ = plt.xlabel('Plant line')\n",
    "            \n",
    "                    #make xticks diagonal\n",
    "                    # _ = plt.xticks(rotation=90, ha='center')\n",
    "\n",
    "                    #plot legend, excluding legend from swarm plot\n",
    "                    h,l = fig.get_legend_handles_labels()\n",
    "                    #change name of label\n",
    "                    l[3] = \"10 mM nitrate\"\n",
    "                    #l[2] = \"20 mM KNO\\u2083 + 20 mM NH\\u2083NO\\u2083\"   \n",
    "                    l[2] = \"1 mM nitrate\"     \n",
    "                    plt.legend(h[2:4],l[2:4],fontsize=10,frameon=False)#,bbox_to_anchor=(0,0.85), loc='best',\n",
    "\n",
    "\n",
    "\n",
    "                    #save plot to file\n",
    "                    plt.savefig(\n",
    "                                    f'{location}/individual/{sample}_{target}_col0.pdf',\n",
    "                                    format=\"pdf\",\n",
    "                                    bbox_inches=\"tight\",transparent=True)\n",
    "                    plt.savefig(\n",
    "                                    f'{location}/individual/{sample}_{target}_col0.svg',\n",
    "                                    format=\"svg\",\n",
    "                                    bbox_inches=\"tight\",transparent=True)\n",
    "                    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make individual plots to compare nitrate\n",
    "def make_plots_nitrate(df,location, normal,sample_order):\n",
    "    \"\"\"function to make barplots of relative expression of each target gene in each plant line\"\"\"\n",
    "    #plot height and width\n",
    "    height = 5\n",
    "    width = 3.5\n",
    "\n",
    "    #decide on stats test\n",
    "    if normal is True:\n",
    "        stats_test = 't-test_ind'\n",
    "    if normal is False:\n",
    "        stats_test = 't-test_welch'\n",
    "\n",
    "\n",
    "    #make individual plots\n",
    "     \n",
    "    for target in df['Target'].unique():\n",
    "        #if target is not EF1a, make plot\n",
    "        if target != 'EF1a':            \n",
    "            temp_df = df[df.Target == target]\n",
    "            #change condition values\n",
    "            temp_df.loc[temp_df['condition'] == '10mM_nitrate', 'condition'] = '10'\n",
    "            temp_df.loc[temp_df['condition'] == '1mM_nitrate', 'condition'] = '1'\n",
    "\n",
    "\n",
    "            #get list of samples\n",
    "            samples_unique = temp_df['Sample'].unique()\n",
    "\n",
    "            \n",
    "\n",
    "            #sort based on custom order\n",
    "            samples = []\n",
    "            for i in range(len(sample_order)):\n",
    "                if sample_order[i] in samples_unique:\n",
    "                    samples+=[sample_order[i]]\n",
    "            #create new df with only sample of interest and Col-0 based on plateID so that Col-0 from the same plate is prioritised\n",
    "            #if temp_df plateID is \"22.08.22_plate1\"\n",
    "\n",
    "            for sample in samples:\n",
    "                if sample != 'Col-0':\n",
    "                    plateID_value = temp_df.loc[temp_df['Sample'] == sample, 'plateID'].values[0]\n",
    "                   # print(plateID_value)\n",
    "                    if plateID_value == '22.08.22_plate1':   \n",
    "                        #print(f'platevalueis{plateID_value}')                \n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | ((temp_df.Sample == 'Col-0') & (temp_df.plateID == plateID_value))]\n",
    "\n",
    "                    if plateID_value == '22.08.22_plate2':\n",
    "\n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | ((temp_df.Sample == 'Col-0') & (temp_df.plateID == plateID_value))]\n",
    "\n",
    "                    if plateID_value == '06.09.22_plate1':\n",
    "\n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | ((temp_df.Sample == 'Col-0') & (temp_df.plateID == plateID_value))]\n",
    "                    if plateID_value == '06.09.22_plate2':\n",
    "\n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | ((temp_df.Sample == 'Col-0') & (temp_df.plateID == plateID_value))]\n",
    "                    if plateID_value == '06.09.22_plate3':\n",
    "\n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | ((temp_df.Sample == 'Col-0') & (temp_df.plateID == plateID_value))]\n",
    "                    if plateID_value == '10.8.22':\n",
    "                        #include all col-0 values from both plates       \n",
    "                        df_new = temp_df[(temp_df.Sample == sample) | (temp_df.Sample == 'Col-0')]\n",
    "                    #create box pairs\n",
    "                    pairs = [(('Col-0','1'),('Col-0','10')),((sample,'1'),(sample,'10'))]\n",
    "\n",
    "                    order = ['Col-0',sample]\n",
    "\n",
    "\n",
    "                    #make figure\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # #get length of number of samples\n",
    "            # length_samples = len(samples)\n",
    "\n",
    "            # #create order and box pairs based on the length of TFs\n",
    "            # order = []\n",
    "            # box_pairs = []\n",
    "            # for x in range (0, (length_samples)):\n",
    "            #     order.append(samples[x])\n",
    "            #     # if 'Col-0' in samples:\n",
    "            #     #     if samples[x] != 'Col-0':\n",
    "            #     #         box_pairs.append(('col-0', samples[x]))\n",
    "            #     # if 'ol-0' not in samples:\n",
    "            #     box_pairs.append(((samples[x],'1'), (samples[x],'10')))\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            # order = ['1','10']\n",
    "            # #create box pairs\n",
    "            # pair = [('1', '10')]\n",
    "\n",
    "                    #make plot\n",
    "                    fig_args = {'x':'Sample', 'y':'relative_expression','hue':'condition', 'hue_order':['1','10'],'data':df_new, 'order':order, 'dodge':True}\n",
    "\n",
    "                    configuration = {'test':stats_test, 'text_format':'star', 'pvalue_thresholds':[[1e-3, \"***\"],[1e-2, \"**\"],[0.05, \"*\"],[1, \"ns\"]]}\n",
    "\n",
    "                    _ = plt.figure(figsize=(width,height))\n",
    "\n",
    "                    fig = sns.barplot(**fig_args, palette=[\"lightcyan\", \"cyan\"],linewidth=2,  errcolor=\"black\", edgecolor=\"black\", ci=68, errwidth=1,capsize=0.4)\n",
    "                    fig = sns.swarmplot(**fig_args, color='black')\n",
    "                    \n",
    "                    #fig = sns.barplot(x='Sample', y='relative_expression', data=temp_df, order=order, linewidth=2,  errcolor=\"black\", edgecolor=\"black\", ci=68, errwidth=1,capsize=0.4,color='cyan')\n",
    "\n",
    "                    #fig = sns.swarmplot(x='condition', y='relative_expression', data=temp_df, order=order,color='black')\n",
    "\n",
    "                    #add stats\n",
    "                    annotator = Annotator(fig, pairs, **fig_args,verbose=False)\n",
    "                    annotator.configure(**configuration)\n",
    "                    # annotator = Annotator(fig, pairs, data=temp_df, x='condition', y='relative_expression',order=order,verbose=False)\n",
    "                    # annotator.configure(test=stats_test, text_format='star',pvalue_thresholds=[[1e-3, \"***\"],[1e-2, \"**\"],[0.05, \"*\"],[1, \"ns\"]])\n",
    "                    \n",
    "                    #save stats to file\n",
    "                    ax, test_results = annotator.apply_and_annotate()\n",
    "                    with open(f'{location}/individual/stats.txt', 'a') as f:                            \n",
    "                        for res in test_results:\n",
    "                            f.write(f'{str(sample)},{target},{pairs},{str(res.data)}\\n')\n",
    "                    \n",
    "                    # change axes labels\n",
    "                    _ = plt.ylabel('Relative expression (a.u.)')\n",
    "                    \n",
    "                    \n",
    "                    #add plot title\n",
    "                    _ = plt.title(f'{target}')\n",
    "\n",
    "                    #rename x axis labels\n",
    "                    #_ = plt.set_xticklabels( ('1','10') )\n",
    "                    #change x axis name\n",
    "                    _ = plt.xlabel('Plant line')\n",
    "            \n",
    "                    #make xticks diagonal\n",
    "                    # _ = plt.xticks(rotation=90, ha='center')\n",
    "\n",
    "                    #plot legend, excluding legend from swarm plot\n",
    "                    h,l = fig.get_legend_handles_labels()\n",
    "                    #change name of label\n",
    "                    l[3] = \"10 mM nitrate\"\n",
    "                    #l[2] = \"20 mM KNO\\u2083 + 20 mM NH\\u2083NO\\u2083\"   \n",
    "                    l[2] = \"1 mM nitrate\"     \n",
    "                    plt.legend(h[2:4],l[2:4],fontsize=10,frameon=False)#,bbox_to_anchor=(0,0.85), loc='best',\n",
    "\n",
    "\n",
    "\n",
    "                    #save plot to file\n",
    "                    plt.savefig(\n",
    "                                    f'{location}/individual/{sample}_{target}_nitrate.pdf',\n",
    "                                    format=\"pdf\",\n",
    "                                    bbox_inches=\"tight\",transparent=True)\n",
    "                    plt.savefig(\n",
    "                                    f'{location}/individual/{sample}_{target}_nitrate.svg',\n",
    "                                    format=\"svg\",\n",
    "                                    bbox_inches=\"tight\",transparent=True)\n",
    "                    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make combined plots with all samples\n",
    "def make_combined_plots(df,location, normal,sample_order):\n",
    "    \"\"\"function to make barplots of relative expression of each target gene in each plant line on the same axes\"\"\"\n",
    "    #plot height and width\n",
    "    height = 5\n",
    "    bar_width = 0.3\n",
    "    #decide on stats test\n",
    "    if normal is True:\n",
    "        stats_test = 't-test_ind'\n",
    "    if normal is False:\n",
    "        stats_test = 't-test_welch'\n",
    "\n",
    "    #set width of bars\n",
    "    def change_width(ax, new_value) :\n",
    "        for patch in ax.patches :\n",
    "            current_width = patch.get_width()\n",
    "            diff = current_width - new_value\n",
    "            # we change the bar width\n",
    "            patch.set_width(new_value)\n",
    "            # we recenter the bar\n",
    "            patch.set_x(patch.get_x() + diff * .5)\n",
    "\n",
    "    for target in df['Target'].unique():\n",
    "        #if target is not EF1a, make plot\n",
    "        if target != 'EF1a':\n",
    "            temp_df = df[df.Target == target]\n",
    "            #change condition values\n",
    "            temp_df.loc[temp_df['condition'] == '10mM_nitrate', 'condition'] = '10'\n",
    "            temp_df.loc[temp_df['condition'] == '1mM_nitrate', 'condition'] = '1'\n",
    "\n",
    "            #get list of samples\n",
    "            samples_unique = temp_df['Sample'].unique()\n",
    "\n",
    "            \n",
    "\n",
    "            #sort based on custom order\n",
    "            samples = []\n",
    "            for i in range(len(sample_order)):\n",
    "                if sample_order[i] in samples_unique:\n",
    "                    samples+=[sample_order[i]]\n",
    "\n",
    "            #get length of number of samples\n",
    "            length_samples = len(samples)\n",
    "\n",
    "            #create order and box pairs based on the length of TFs\n",
    "            order = []\n",
    "            box_pairs = []\n",
    "            for x in range (0, (length_samples)):\n",
    "                order.append(samples[x])\n",
    "                # if 'Col-0' in samples:\n",
    "                #     if samples[x] != 'Col-0':\n",
    "                #         box_pairs.append(('col-0', samples[x]))\n",
    "                # if 'ol-0' not in samples:\n",
    "                box_pairs.append(((samples[x],'1'), (samples[x],'10')))\n",
    "\n",
    "\n",
    "            fig_args = {'x':'Sample', 'y':'relative_expression','hue':'condition', 'hue_order':['1','10'],'data':temp_df, 'order':order, 'dodge':True}\n",
    "            #'linewidth':2,  'errcolor':\"black\", 'edgecolor':\"black\", 'ci':68, 'errwidth':1,'capsize':0.4\n",
    "\n",
    "            configuration = {'test':stats_test, 'text_format':'star', 'pvalue_thresholds':[[1e-3, \"***\"],[1e-2, \"**\"],[0.05, \"*\"],[1, \"ns\"]]}\n",
    "\n",
    "\n",
    "            #make plot              \n",
    "            \n",
    "            _ = plt.figure(figsize=((3+(length_samples-1)*2),height))\n",
    "            \n",
    "            #_ = plt.figure(figsize=(width,height))\n",
    "            fig = sns.barplot(**fig_args, palette=[\"lightcyan\", \"cyan\"],linewidth=2,  errcolor=\"black\", edgecolor=\"black\", ci=68, errwidth=1,capsize=0.4)\n",
    "            fig = sns.swarmplot(**fig_args, color='black')\n",
    "\n",
    "            #set width of bars\n",
    "            change_width(fig, bar_width)\n",
    "\n",
    "            # #add stats\n",
    "            annotator = Annotator(fig, box_pairs, **fig_args,verbose=False)\n",
    "            annotator.configure(**configuration)\n",
    "\n",
    "\n",
    "            # fig = sns.barplot(x='Sample', y='relative_expression',hue='condition', data=temp_df, order=order, linewidth=2,  errcolor=\"black\", edgecolor=\"black\", ci=68, errwidth=1,capsize=0.4,color='cyan')\n",
    "\n",
    "            # fig = sns.swarmplot(x='Sample', y='relative_expression',hue='condition', data=temp_df, order=order,color='black')\n",
    "\n",
    "            #add stats\n",
    "            # annotator = Annotator(fig, pair, data=temp_df, x='Sample', y='relative_expression',order=order,verbose=False)\n",
    "            # annotator.configure(test='t-test_ind', text_format='star',pvalue_thresholds=[[1e-3, \"***\"],[1e-2, \"**\"],[0.05, \"*\"],[1, \"ns\"]])\n",
    "            \n",
    "            #save stats to file\n",
    "            ax, test_results = annotator.apply_and_annotate()\n",
    "            with open(f'{location}/targets/stats.txt', 'a') as f:                            \n",
    "                for res in test_results:\n",
    "                    f.write(f'{target},{box_pairs},{str(res.data)}\\n')\n",
    "            \n",
    "            # change axes labels\n",
    "            _ = plt.ylabel('Relative expression (a.u.)')\n",
    "            \n",
    "            \n",
    "            #add plot title\n",
    "            _ = plt.title(f'{target}')\n",
    "\n",
    "            #rename x axis labels\n",
    "            #_ = plt.set_xticklabels( ('1','10') )\n",
    "            #change x axis name\n",
    "            _ = plt.xlabel('Nitrate concentration (mM)')\n",
    "    \n",
    "            #make xticks diagonal\n",
    "            _ = plt.xticks(rotation=45, ha='center')\n",
    "\n",
    "            #plot legend, excluding legend from swarm plot\n",
    "            h,l = fig.get_legend_handles_labels()\n",
    "            #change name of label\n",
    "            l[3] = \"10 mM nitrate\"\n",
    "            #l[2] = \"20 mM KNO\\u2083 + 20 mM NH\\u2083NO\\u2083\"   \n",
    "            l[2] = \"1 mM nitrate\"     \n",
    "            plt.legend(h[2:4],l[2:4],bbox_to_anchor=(0.3,0.87), loc='lower left',fontsize=10)\n",
    "\n",
    "            # tight layout\n",
    "            #plt.tight_layout()\n",
    "\n",
    "\n",
    "            #save plot to file\n",
    "            plt.savefig(\n",
    "                            f'{location}/targets/{target}_nitrate.pdf',\n",
    "                            format=\"pdf\",\n",
    "                            bbox_inches=\"tight\",transparent=True)\n",
    "            plt.savefig(\n",
    "                            f'{location}/targets/{target}_nitrate.svg',\n",
    "                            format=\"svg\",\n",
    "                            bbox_inches=\"tight\",transparent=True)\n",
    "            plt.close()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make combined plots with all samples relative to Col-0\n",
    "def make_combined_plots_col0(df,location, normal,sample_order, fontsize):\n",
    "    \"\"\"function to make barplots of relative expression of each target gene in each plant line on the same axes\"\"\"\n",
    "    #plot height and width\n",
    "    height = 5\n",
    "    bar_width = 0.3\n",
    "    #decide on stats test\n",
    "    if normal is True:\n",
    "        stats_test = 't-test_ind'\n",
    "    if normal is False:\n",
    "        stats_test = 't-test_welch'\n",
    "\n",
    "    #set width of bars\n",
    "    def change_width(ax, new_value) :\n",
    "        for patch in ax.patches :\n",
    "            current_width = patch.get_width()\n",
    "            diff = current_width - new_value\n",
    "            # we change the bar width\n",
    "            patch.set_width(new_value)\n",
    "            # we recenter the bar\n",
    "            patch.set_x(patch.get_x() + diff * .5)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    for target in df['Target'].unique():\n",
    "        #if target is not EF1a, make plot\n",
    "        if target != 'EF1a':\n",
    "            temp_df = df[df.Target == target]\n",
    "            #change condition values\n",
    "            temp_df.loc[temp_df['condition'] == '10mM_nitrate', 'condition'] = '10'\n",
    "            temp_df.loc[temp_df['condition'] == '1mM_nitrate', 'condition'] = '1'\n",
    "            #append _highnitrate to Sample column if condition column is '10'\n",
    "            temp_df.loc[temp_df['condition'] == '10', 'Sample'] = temp_df.loc[temp_df['condition'] == '10', 'Sample'] + '_highnitrate'\n",
    "\n",
    "\n",
    "            #get list of samples\n",
    "            samples_unique = temp_df['Sample'].unique()\n",
    "\n",
    "            \n",
    "\n",
    "            #sort based on custom order\n",
    "            samples = []\n",
    "            for i in range(len(sample_order)):\n",
    "                if sample_order[i] in samples_unique:\n",
    "                    samples+=[sample_order[i]]\n",
    "\n",
    "            #get length of number of samples\n",
    "            length_samples = len(samples)\n",
    "\n",
    "            #create order and box pairs based on the length of TFs\n",
    "            order = []\n",
    "            box_pairs = []\n",
    "            for x in range (0, (length_samples)):\n",
    "                order.append(samples[x])\n",
    "                if 'Col-0' in samples:\n",
    "                    if samples[x] != 'Col-0' or samples[x] != 'Col-0_highnitrate':\n",
    "                        if \"_highnitrate\" in samples[x]:\n",
    "                            box_pairs.append(('Col-0_highnitrate',samples[x]))\n",
    "                        else:\n",
    "                            box_pairs.append(('Col-0',samples[x]))\n",
    "\n",
    "                if 'Col-0' not in samples:\n",
    "                    box_pairs.append(((samples[x],'1'), (samples[x],'10')))\n",
    "            #make box pairs dict with box pair and p value\n",
    "            box_pairs_all_pvalues = {}\n",
    "            #make dict containing the plant line and p value compared to its control (either Col-0 with 10mM nitrate or Col-0 1mM nitrate)\n",
    "            lines_pvalues = {}\n",
    "            for pair in box_pairs:\n",
    "                #create series objects\n",
    "                line1 = df.query(f'Sample == \"{pair[0]}\"')['relative_expression']\n",
    "                line2 = df.query(f'Sample == \"{pair[1]}\"')['relative_expression']\n",
    "            \n",
    "                #equal variance = false so do Welch's T-test\n",
    "                results = stats.ttest_ind(line1, line2, equal_var=False)\n",
    "                #append pvalue to dict\n",
    "                box_pairs_all_pvalues[pair] = results.pvalue\n",
    "                lines_pvalues[pair[1]] = results.pvalue\n",
    "\n",
    "            # #filter dict by significance and put in a new dictionary\n",
    "            box_pairs_significant = {}\n",
    "            for k,v in box_pairs_all_pvalues.items():\n",
    "                if v <0.05:\n",
    "                    box_pairs_significant[k] = v\n",
    "\n",
    "            def convert_pvalue_to_asterisks(pvalue):\n",
    "                if pvalue <= 0.001:\n",
    "                    return \"***\"\n",
    "                elif pvalue <= 0.01:\n",
    "                    return \"**\"\n",
    "                elif pvalue <= 0.05:\n",
    "                    return \"*\"\n",
    "                return \"ns\"\n",
    "\n",
    "\n",
    "\n",
    "            fig_args = {'x':'Sample', 'y':'relative_expression','data':temp_df, 'order':order, 'dodge':True}#'hue':'condition', 'hue_order':['1','10'],\n",
    "            #'linewidth':2,  'errcolor':\"black\", 'edgecolor':\"black\", 'ci':68, 'errwidth':1,'capsize':0.4\n",
    "\n",
    "            # configuration = {'test':stats_test, 'text_format':'star', 'pvalue_thresholds':[[1e-3, \"***\"],[1e-2, \"**\"],[0.05, \"*\"],[1, \"ns\"]]}\n",
    "\n",
    "\n",
    "            #make plot              \n",
    "            \n",
    "            _ = plt.figure(figsize=((3+(length_samples-1)*2),height))\n",
    "            \n",
    "            #_ = plt.figure(figsize=(width,height))\n",
    "            fig = sns.barplot(**fig_args, linewidth=2,  errcolor=\"black\", edgecolor=\"black\", ci=68, errwidth=1,capsize=0.4,color='#E0FFFF')#palette=[\"#E0FFFF\", \"#00EEEE\"],\n",
    "            fig = sns.swarmplot(**fig_args, color='black')\n",
    "\n",
    "            #set width of bars\n",
    "            change_width(fig, bar_width)\n",
    "\n",
    "            # # #add stats\n",
    "            # annotator = Annotator(fig, box_pairs, **fig_args,verbose=False)\n",
    "            # annotator.configure(**configuration)\n",
    "\n",
    "\n",
    "            # fig = sns.barplot(x='Sample', y='relative_expression',hue='condition', data=temp_df, order=order, linewidth=2,  errcolor=\"black\", edgecolor=\"black\", ci=68, errwidth=1,capsize=0.4,color='#00EEEE')\n",
    "\n",
    "            # fig = sns.swarmplot(x='Sample', y='relative_expression',hue='condition', data=temp_df, order=order,color='black')\n",
    "\n",
    "            #add stats\n",
    "            # annotator = Annotator(fig, pair, data=temp_df, x='Sample', y='relative_expression',order=order,verbose=False)\n",
    "            # annotator.configure(test='t-test_ind', text_format='star',pvalue_thresholds=[[1e-3, \"***\"],[1e-2, \"**\"],[0.05, \"*\"],[1, \"ns\"]])\n",
    "            \n",
    "            #save stats to file\n",
    "            # ax, test_results = annotator.apply_and_annotate()\n",
    "            with open(f'{location}/targets/stats_col0.txt', 'a') as f:                            \n",
    "                for pair in lines_pvalues:\n",
    "                    f.write(f'{target}_{pair}\\n')\n",
    "            \n",
    "            #get x length\n",
    "            xlength=len(fig.patches)\n",
    "\n",
    "            #also add asterisks for p values\n",
    "                #make empty variable to show when Col-0_1μM_NAA has been iterated over\n",
    "            high_nitrate_picked = False\n",
    "            for x in range (0, (xlength)):\n",
    "                current_line = order[x]\n",
    "                if current_line == \"Col-0\" or current_line == '':                \n",
    "                    pass\n",
    "                elif current_line == \"Col-0_highnitrate\":\n",
    "                    high_nitrate_picked = True                    \n",
    "                # hatch = next(hatches)\n",
    "                    fig.patches[x].set_facecolor('#00EEEE')\n",
    "                else:\n",
    "                    pvalue = lines_pvalues[current_line]\n",
    "\n",
    "                    \n",
    "                # pvalue = list(box_pairs_all_pvalues.values())[x]\n",
    "                    #key=list(box_pairs_all_pvalues.keys())[x][1]\n",
    "                    p = fig.patches[x]\n",
    "                    fig.annotate(convert_pvalue_to_asterisks(pvalue),\n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha = 'center', va = 'center',\n",
    "                    size=fontsize,\n",
    "                    xytext = (0, 20), \n",
    "                    textcoords = 'offset points')\n",
    "                    #change colour of 10mM nitrate bars\n",
    "                    if high_nitrate_picked == True:\n",
    "                        \n",
    "                        p.set_facecolor('#00EEEE')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # change axes labels\n",
    "            _ = plt.ylabel('Relative expression (a.u.)')\n",
    "            \n",
    "            \n",
    "            #add plot title\n",
    "            _ = plt.title(f'{target}')\n",
    "\n",
    "            #rename x axis labels\n",
    "            #_ = plt.set_xticklabels( ('1','10') )\n",
    "            #change x axis name\n",
    "            _ = plt.xlabel('Nitrate concentration (mM)')\n",
    "    \n",
    "            #make xticks diagonal\n",
    "            _ = plt.xticks(rotation=45, ha='center')\n",
    "\n",
    "            #add custom legend\n",
    "            handles = []\n",
    "            labels = []\n",
    "            low_nitrate = mpatches.Patch(facecolor='#E0FFFF', hatch='',edgecolor='black',linewidth=2)\n",
    "            high_nitrate = mpatches.Patch(facecolor='#00EEEE', hatch='',edgecolor='black',linewidth=2)\n",
    "            low_nitrate_label = \"1 mM nitrate\"\n",
    "            high_nitrate_label = \"10 mM nitrate\"\n",
    "            handles.append(low_nitrate)\n",
    "            handles.append(high_nitrate)\n",
    "            labels.append(low_nitrate_label)\n",
    "            labels.append(high_nitrate_label)\n",
    "            fig.legend(handles=handles,labels=labels,ncol=1,bbox_to_anchor=(0.1,0.85), loc='lower left',fontsize=fontsize)#color=None\n",
    "            \n",
    "            new_labels = []        \n",
    "            for plant_line in order:\n",
    "                if '_highnitrate' in plant_line:\n",
    "                    lines_orig_renamed = plant_line[:len(plant_line)-12]\n",
    "                    new_labels.append(lines_orig_renamed)\n",
    "                else:\n",
    "                    new_labels.append(plant_line)\n",
    "            fig.set_xticklabels(new_labels)\n",
    "\n",
    "                # tight layout\n",
    "                #plt.tight_layout()\n",
    "\n",
    "\n",
    "            #save plot to file\n",
    "            plt.savefig(\n",
    "                            f'{location}/targets/{target}_col0.pdf',\n",
    "                            format=\"pdf\",\n",
    "                            bbox_inches=\"tight\",transparent=True)\n",
    "            plt.savefig(\n",
    "                            f'{location}/targets/{target}_col0.svg',\n",
    "                            format=\"svg\",\n",
    "                            bbox_inches=\"tight\",transparent=True)\n",
    "            plt.close()        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set matplotlib rc parameters\n",
    "def set_rc_params():\n",
    "    #set matplotlib default parameters\n",
    "    rcParams['xtick.major.width'] = 2\n",
    "    rcParams['ytick.major.width'] = 2\n",
    "    rcParams['axes.linewidth'] = 2\n",
    "    #rcParams['lines.linewidth'] = 2\n",
    "    #remove top and right lines\n",
    "    rcParams['axes.spines.top'] = False\n",
    "    rcParams['axes.spines.right'] = False\n",
    "    #font size\n",
    "    fontsize = 14\n",
    "    rcParams['font.size'] = fontsize\n",
    "    #for getting the microsoft font Arial working, please follow this guide: https://alexanderlabwhoi.github.io/post/2021-03-missingfont/\n",
    "    rcParams['font.family'] = 'sans-serif'\n",
    "    rcParams['font.sans-serif'] = ['Arial']\n",
    "    #allow font to be edited later in pdf editor\n",
    "    #make svg text editable\n",
    "    rcParams['svg.fonttype'] = 'none'\n",
    "    rcParams ['pdf.fonttype'] = 42 \n",
    "    #align y-axis top most tick with end of axis\n",
    "    rcParams['axes.autolimit_mode'] = 'round_numbers'\n",
    "    #set margins to ensure any error bars fit\n",
    "    rcParams['axes.xmargin'] = 0.2\n",
    "    rcParams['axes.ymargin'] = 0.2\n",
    "    #define bar width\n",
    "    #bar_width = 0.65\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\" function\n",
    "def main():\n",
    "    location = '../../data/CRISPR_library/qPCR'\n",
    "    csv_file1 = f'{location}/06.09.22/06.09.22_plate1_19310threshold.csv'\n",
    "    csv_file2 = f'{location}/06.09.22/06.09.22_plate2_19310threshold.csv'\n",
    "    csv_file3 = f'{location}/06.09.22/06.09.22_plate3_19310threshold.csv'\n",
    "    #read in files\n",
    "    df1 = read_csv(csv_file1)\n",
    "    df2 = read_csv(csv_file2)\n",
    "    df3 = read_csv(csv_file3)\n",
    "    #filter, sort and normalise to plate calibrator\n",
    "    def filter_sort_normalise(df,location,name):\n",
    "        #filter out the data points with amp_status = Amp and cq above 32\n",
    "        df = filter_data(df, 'Amp', 40)\n",
    "\n",
    "        \n",
    "        #sort the data, and normalise to the eEF1a gene\n",
    "        df = sort_data(df,location,name)\n",
    "        \n",
    "        #normalise to sample 125-4AH on each plate (plate normalisation so can compare between plates)\n",
    "        #get 125-4AH NIR1 10mM nitrate sample MeanCq_ECnormalised\n",
    "        # sample_125_4AH = df[(df.Sample_old == '125-4A')&(df.condition == '10mM_nitrate') &(df.Target == \"NIR1\")].MeanCq_ECnormalised.values[0]\n",
    "        # print(f'{sample_125_4AH}')\n",
    "        # #normalise\n",
    "        # df.loc[:,'MeanCq_EC_plate_calibrated'] = df['MeanCq_ECnormalised'] - sample_125_4AH\n",
    "        # #remove nan values in the new column\n",
    "        # df = df[df['MeanCq_EC_plate_calibrated'].notna()]\n",
    "        # #add column with name\n",
    "        # df['plateID'] = name\n",
    "        return df\n",
    "    #filter, sort and normalise to plate calibrator\n",
    "    df1 = filter_sort_normalise(df1,location,\"06.09.22_plate1\")\n",
    "    #save df1 to file\n",
    "    #df1.to_csv(f'{location}/10.08.22/10.8.22_plate_test.csv')\n",
    "    #print(df1)\n",
    "\n",
    "    df2 = filter_sort_normalise(df2,location,\"06.09.22_plate2\")\n",
    "    #df2.to_csv(f'{location}/22.08.22_plate1_test.tsv',sep='\\t')\n",
    "    #print(df2)\n",
    "    df3 = filter_sort_normalise(df3,location,\"06.09.22_plate3\")\n",
    "\n",
    "    #merge the dfs\n",
    "    df = pd.concat([df1,df2,df3])\n",
    "    #sort by Sample, Target and condition\n",
    "    df = df.sort_values(by=['Sample','Target','condition'])\n",
    "    #save df to file\n",
    "    df.to_csv(f'{location}/merged_plates.tsv', sep='\\t')\n",
    "    #make a copy of the df\n",
    "    df_col_norm = df.copy()\n",
    "\n",
    "    \n",
    "\n",
    "    #normalise based on 1mM_nitrate Cq values, mean between all 3 biological reps \n",
    "    df = normalise_data(df, 'MeanCq_EC_plate_calibrated','1mMnitrate_Cq_mean','MeanCq_EC_1mM_nitrate_normalised')\n",
    "    #now filter columns\n",
    "    df = df[['Sample','Target','MeanCq_EC_1mM_nitrate_normalised','condition']]\n",
    "    #now filter columns\n",
    "    #df = df[['Sample','Target','MeanCq_ECnormalised','condition']]\n",
    "    #first do inverse log transformation\n",
    "    #(fold change of GOI in treated sample if delta delta Ct value  = X then relative expression  = 2 ( to the power of X))\n",
    "    #df['relative_expression'] = 2**(df['MeanCq_ECnormalised'])\n",
    "    df['relative_expression'] = 2**(df['MeanCq_EC_1mM_nitrate_normalised'])\n",
    "    #save df to tsv\n",
    "    df.to_csv('../../data/CRISPR_library/qPCR/merged_plates_19310threshold_normEC1mMnitrate_relative_expression.tsv', sep='\\t', index=False)\n",
    "\n",
    "    #Normalise to 1mM_nitrate Col-0 within each original plate\n",
    "    #now make a df containing only Col-0 Samples with 1mM_nitrate condition\n",
    "    df_col_1mM_nitrate = df_col_norm.loc[(df_col_norm['condition'] == '1mM_nitrate') & (df_col_norm.Sample=='Col-0')].copy()\n",
    "\n",
    "    #make new column that is the Mean Col-0 1mM expression across biological replicates for that target on each plate\n",
    "    df_col_1mM_nitrate['Mean_biological_Cq_ECnormalised'] = df_col_1mM_nitrate.groupby(['Sample','Target', 'condition','plateID'])['MeanCq_EC_plate_calibrated'].transform('mean')\n",
    "\n",
    "\n",
    "    #rename Mean_biological_Cq_ECnormalised column to Col0_1mMnitrate_Cq_mean\n",
    "    df_col_1mM_nitrate.rename(columns={'Mean_biological_Cq_ECnormalised': 'Col0_1mMnitrate_Cq_mean'}, inplace=True)\n",
    "    #filter other columns\n",
    "    df_col_1mM_nitrate = df_col_1mM_nitrate[['Sample_old','Target','Col0_1mMnitrate_Cq_mean','plateID']]\n",
    "    #remove duplicates from df_col_1mM_nitrate\n",
    "    df_col_1mM_nitrate = df_col_1mM_nitrate.drop_duplicates()\n",
    "    #merge the dfs, putting the Col-0 1mM nitrate mean values for each target across all plant lines within each plate\n",
    "    df_col_norm = pd.merge(df_col_norm, df_col_1mM_nitrate, on=['Target', 'plateID'], how='left')\n",
    "    #save df to file\n",
    "    df_col_norm.to_csv('../../data/CRISPR_library/qPCR/merged_plates_19310threshold_norm_col0_1mMnitrate.tsv', sep='\\t', index=False)\n",
    "    #normalise based on Col0_1mMnitrate_Cq_mean Cq values, mean between all 3 biological reps \n",
    "    df_col_norm = normalise_data(df_col_norm, 'MeanCq_EC_plate_calibrated','Col0_1mMnitrate_Cq_mean','MeanCq_EC_Col0_1mM_nitrate_normalised')\n",
    "    #print(df_col_norm)\n",
    "    #now filter columns\n",
    "    df_col_norm = df_col_norm[['Sample','Target','MeanCq_EC_Col0_1mM_nitrate_normalised','condition', 'plateID']]\n",
    "\n",
    "\n",
    "    # #first do inverse log transformation\n",
    "    # #(fold change of GOI in treated sample if delta delta Ct value  = X then relative expression  = 2 ( to the power of X))\n",
    "    # #df['relative_expression'] = 2**(df['MeanCq_ECnormalised'])\n",
    "    df_col_norm['relative_expression'] = 2**(df_col_norm['MeanCq_EC_Col0_1mM_nitrate_normalised'])\n",
    "    #remove duplicates\n",
    "    df_col_norm = df_col_norm.drop_duplicates()\n",
    "    # #save df to tsv\n",
    "    df_col_norm.to_csv('../../data/CRISPR_library/qPCR/06.09.22_merged_plates_19310threshold_normEC_Col0_1mMnitrate_relative_expression.tsv', sep='\\t', index=False)\n",
    "\n",
    "\n",
    "    \n",
    "    # #get sample with lowest MeanCq_ECnormalised value that isn't equal to 0\n",
    "    # #remove all MeanCq_ECnormalised values equal to 0\n",
    "    # df_norm_nozeroes = df_norm_lowest_sample[df_norm_lowest_sample['MeanCq_ECnormalised'] != 0]\n",
    "    # #get lowest MeanCq_ECnormalised value in df_norm_lowest_sample\n",
    "    # lowest_mean_cq = df_norm_nozeroes['MeanCq_ECnormalised'].min()\n",
    "    # lowest_mean_cq_sample = df_norm_nozeroes[df_norm_nozeroes['MeanCq_ECnormalised'] == lowest_mean_cq].iloc[0]['Sample']\n",
    "    # print(f'lowestmeancq={lowest_mean_cq}')\n",
    "    # print(f'normalising to lowest mean cq sample: {lowest_mean_cq_sample}')\n",
    "    # #normalise df_norm_lowest_sample to lowest mean cq sample\n",
    "    # df_norm_lowest_sample.loc[:,'MeanCq_EClowestsample'] = df_norm_lowest_sample['MeanCq_ECnormalised'] - lowest_mean_cq\n",
    "    # #remove nan values in the new column\n",
    "    # df_norm_lowest_sample = df_norm_lowest_sample[df_norm_lowest_sample['MeanCq_EClowestsample'].notna()]\n",
    "\n",
    "    # #do inverse log transformation\n",
    "    # df_norm_lowest_sample['relative_expression'] = 2**(df_norm_lowest_sample['MeanCq_EClowestsample'])\n",
    "    # #save df to tsv\n",
    "    # df_norm_lowest_sample.to_csv('../../data/CRISPR_library/qPCR/10.8.22_platelayout_19310threshold_normEClowest_sample_relative_expression.tsv', sep='\\t', index=False)\n",
    "\n",
    "    #create plot folder name\n",
    "    #make directory for the plots to be exported to\n",
    "    dirName = f'{location}/plots'\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir(dirName)\n",
    "        print(\"Directory \" , dirName ,  \" created\") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , dirName ,  \" already exists\")\n",
    "\n",
    "\n",
    "    dirName = f'{location}/plots/individual'\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir(dirName)\n",
    "        print(\"Directory \" , dirName ,  \" created\") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , dirName ,  \" already exists\")\n",
    "\n",
    "    dirName = f'{location}/plots/targets'\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir(dirName)\n",
    "        print(\"Directory \" , dirName ,  \" created\") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , dirName ,  \" already exists\")\n",
    "\n",
    "\n",
    "    #save df to csv\n",
    "    #df.to_csv(f'{location}/mean_normalised.csv')\n",
    "\n",
    "\n",
    "\n",
    "    #set matplotlib rc parameters\n",
    "    set_rc_params()\n",
    "\n",
    "    #test for normality of data - Shapiro-Wilk test\n",
    "    #test_normality(df)\n",
    "    normality = test_normality(df_col_norm, location)\n",
    "\n",
    "    #check if any of the p values are less than 0.05 (not normal)\n",
    "    significant = normality[normality['pvalue'] < 0.05]\n",
    "    if significant.empty:\n",
    "        print('all p values are greater than 0.05, data is normal, using independent t-test')\n",
    "        normal = True\n",
    "    if not significant.empty:\n",
    "        print('some p values are less than 0.05, data is not normal, using welchs t-test')\n",
    "        normal = False\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "    #sample order in the plots\n",
    "    sample_order = ['Col-0','69-9','125-4','127-10','130-4','134-3','139-9','142-4','142-8','144-5','154-4']\n",
    "    sample_order_col0 = ['Col-0','69-9','125-4','127-10','130-4','134-3','139-9','142-4','142-8','144-5','154-4','Col-0_highnitrate','69-9_highnitrate','125-4_highnitrate','127-10_highnitrate','130-4_highnitrate','134-3_highnitrate','139-9_highnitrate','142-4_highnitrate','142-8_highnitrate','144-5_highnitrate','154-4_highnitrate']\n",
    "    #individual plots compare between 1 and 10mM nitrate, and only show Col-0 from that plate if present on that plate, otherwise show all Col-0 samples from other two plates\n",
    "    make_plots_nitrate(df_col_norm,f'{location}/plots', normal,sample_order)\n",
    "    #individual plots compared to Col-0 1 and 10mM nitrate\n",
    "    make_plots(df_col_norm,f'{location}/plots', normal,sample_order)\n",
    "    #combined plots\n",
    "    #compare between 1 and 10mM nitrate\n",
    "    make_combined_plots(df_col_norm,f'{location}/plots', normal,sample_order)\n",
    "    #make plots compared to Col-0 1 and 10mM nitrate\n",
    "    make_combined_plots_col0(df_col_norm,f'{location}/plots', normal,sample_order_col0,14)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Warning: minimum size of technical replicate group is 2\n",
      "Directory  ../../data/CRISPR_library/qPCR/plots  already exists\n",
      "Directory  ../../data/CRISPR_library/qPCR/plots/individual  already exists\n",
      "Directory  ../../data/CRISPR_library/qPCR/plots/targets  already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/scipy/stats/_morestats.py:1797: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some p values are less than 0.05, data is not normal, using welchs t-test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/witham/opt/anaconda3/envs/qpcr/lib/python3.9/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #normality tests - kolmogorov smirnov test\n",
    "# #returns test statistic, p-value\n",
    "# for name1 in prom_names_plate1:\n",
    "#     for name in names_plate1:\n",
    "#         print(name1,'{}: {}'.format(name, stats.shapiro(luminescence_raw_df_plate1['nluc/fluc'][luminescence_raw_df_plate1.TF_added == name])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('qpcr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c2acf9d6025fe51d3e4a4cb09a2ff19b54eaae2da571c8e6469319b5fd828be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
