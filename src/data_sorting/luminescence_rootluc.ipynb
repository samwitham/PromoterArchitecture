{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Sort the protoplast luminescence data from the xlsx output from the Glariostar platereader. \n",
    "Use 2 input excels at a time (one firefly, one nanoluc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlsx_2_csv(xlsx):  \n",
    "    \"\"\" Function to read and convert xlsx file to csv file. Also return the data (name of the folder the xlsx is in)\"\"\"\n",
    "    \n",
    "    # Read in the xlsx file, second sheet\n",
    "    file = pd.read_excel(xlsx, 'Table End point', index_col=None) \n",
    "    \n",
    "    filename = os.path.basename(xlsx)\n",
    "    removed_extension = os.path.splitext(filename)[0]\n",
    "    path = Path(xlsx).parent #find parent directory to the one the xlsx fields are in\n",
    "    date = Path(xlsx)\n",
    "    \n",
    "    file.to_csv(f'{path}/{removed_extension}.csv', encoding='utf-8', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csvs(input_protein1,input_protein2,input_nluc,layout_csv,layout_protein1,layout_protein2,date,output_file_raw):\n",
    "    \"\"\"Function to combine two csv files containing luminescence or absorbance data, and label values using layout csv file (plate layout)\"\"\"\n",
    "    #read in files\n",
    "    protein1 = pd.read_csv(input_protein1, header=0)\n",
    "    protein2 = pd.read_csv(input_protein2, header=0)\n",
    "    nluc = pd.read_csv(input_nluc, header=0)\n",
    "    #rename 3rd column\n",
    "    protein1.rename(columns={protein1.columns[2]: \"absorbance\" }, inplace = True)\n",
    "    protein2.rename(columns={protein2.columns[2]: \"absorbance\" }, inplace = True)\n",
    "    nluc.rename(columns={nluc.columns[2]: \"luminescence\" }, inplace = True)\n",
    "    layout_df = pd.read_csv(layout_csv, header=0)\n",
    "    layout_protein1_df = pd.read_csv(layout_protein1, header=0)\n",
    "    layout_protein2_df = pd.read_csv(layout_protein2, header=0)\n",
    "\n",
    "    #make new df with correct column names, including both fluc and nluc data\n",
    "    #combined = fluc[['Well\\nRow', 'Well\\nCol', 'Content','Average over replicates based on Blank corrected (No filter)']].copy()\n",
    "    combined_protein1 = protein1[['Well','Content','absorbance']].copy()\n",
    "    combined_protein1.rename(columns={'Well': \"well_plate1\" }, inplace = True)\n",
    "    combined_protein1.rename(columns={'Content': \"content\" }, inplace = True)\n",
    "    combined_protein2 = protein2[['Well','Content','absorbance']].copy()\n",
    "    combined_protein2.rename(columns={'Well': \"well_plate2\" }, inplace = True)\n",
    "    combined_protein2.rename(columns={'Content': \"content\" }, inplace = True)\n",
    "\n",
    "    #combined.rename(columns = {'Well\\nRow':'well_row', 'Well\\nCol':'well_col', 'Content':'content', 'Average over replicates based on Blank corrected (No filter)':'fluc_luminescence'}, inplace = True)\n",
    "    # # combined.rename(columns = {'Absorbance':'fluc_luminescence'}, inplace = True)\n",
    "    # #merge with protein 2 data\n",
    "    # combined = combined.merge(protein2[['Well','Content','absorbance']], on=['absorbance'], how='left')\n",
    "    # combined.rename(columns = {'Well':'well_plate2'}, inplace=True)\n",
    "    # combined.rename(columns = {'Content':'content_plate2'}, inplace=True)\n",
    "    # #add well row and column columns    \n",
    "    # combined['well_row_plate1'] = combined.well_plate1.str[:1]\n",
    "    # combined['well_col_plate1'] = combined.well_plate1.str[-2:]\n",
    "    # combined['well_row_plate2'] = combined.well_plate2.str[:1]\n",
    "    # combined['well_col_plate2'] = combined.well_plate2.str[-2:]\n",
    "\n",
    "\n",
    "    #prepend layout well col with a 0\n",
    "    layout_protein1 = layout_protein1_df.copy()\n",
    "    layout_protein1['well_col_plate1'] = layout_protein1_df['well_col'].astype(str).str.zfill(width=2)\n",
    "    #rename well_row to well_row_plate1\n",
    "    layout_protein1.rename(columns = {'well_row':'well_row_plate1'}, inplace=True)\n",
    "\n",
    "    layout_protein2 = layout_protein2_df.copy()\n",
    "    layout_protein2['well_col_plate2'] = layout_protein2_df['well_col'].astype(str).str.zfill(width=2)\n",
    "    #rename well_row to well_row_plate2\n",
    "    layout_protein2.rename(columns = {'well_row':'well_row_plate2'}, inplace=True)\n",
    "    #\n",
    "    #change df content data type to string\n",
    "    combined_protein1.content = combined_protein1.content.astype(str)\n",
    "    combined_protein2.content = combined_protein2.content.astype(str)\n",
    "    # #add well row and column columns    \n",
    "    combined_protein1['well_row_plate1'] = combined_protein1.well_plate1.str[:1]\n",
    "    combined_protein1['well_col_plate1'] = combined_protein1.well_plate1.str[-2:]\n",
    "    combined_protein2['well_row_plate2'] = combined_protein2.well_plate2.str[:1]\n",
    "    combined_protein2['well_col_plate2'] = combined_protein2.well_plate2.str[-2:]\n",
    "    #merge layout with combined\n",
    "    combined_named_protein1 = pd.merge(combined_protein1, layout_protein1,on=['well_row_plate1','well_col_plate1'])\n",
    "    \n",
    "    combined_named_protein2 = pd.merge(combined_protein2, layout_protein2, on=['well_row_plate2','well_col_plate2'])\n",
    "    #convert well_col column data type to string so it is excluded from the next bit\n",
    "    combined_named_protein1.well_col = combined_named_protein1.well_col_plate1.astype(np.str)\n",
    "    combined_named_protein2.well_col = combined_named_protein2.well_col_plate2.astype(np.str)\n",
    "    #get Col-0-1A absorbance value\n",
    "    # print(combined_named_protein2.name.unique())\n",
    "    col0_protein1 = combined_named_protein1.loc[(combined_named_protein1['name'] == 'Col-0-1A') & ((combined_named_protein1['condition'] == '10mM_nitrate')|(combined_named_protein1['condition'] == 'calibrator'))]['absorbance'].values[0]\n",
    "    col0_protein2 = combined_named_protein2.loc[(combined_named_protein2['name'] == 'Col-0-1A') & ((combined_named_protein2['condition'] == '10mM_nitrate')|(combined_named_protein2['condition'] == 'calibrator'))]['absorbance'].values[0]\n",
    "    #normalise to Col-0-1A absorbance value\n",
    "    combined_named_protein1['norm_absorbance'] = combined_named_protein1['absorbance']/col0_protein1\n",
    "    combined_named_protein2['norm_absorbance'] = combined_named_protein2['absorbance']/col0_protein2\n",
    "\n",
    "\n",
    "    #concat dfs, merging columns on name condition and absorbance\n",
    "    combined_named_protein = pd.merge(combined_named_protein1, combined_named_protein2, on=['name','condition','absorbance','norm_absorbance'], how='outer')\n",
    "    # print(combined_named_protein)\n",
    "    # combined_named_protein = pd.concat([combined_named_protein1, combined_named_protein2], axis=1)\n",
    "    # combined_named_protein = pd.merge(combined_named_protein1, combined_named_protein2, on=['name','condition','absorbance'])\n",
    "    # print(combined_named_protein)\n",
    "    #merge with layout df\n",
    "    # print(combined_named_protein)\n",
    "    #merge nluc data with layout\n",
    "    combined_nluc = nluc[['Well','Content','luminescence']].copy()\n",
    "    #rename nluc luminescence\n",
    "    combined_nluc.rename(columns = {'luminescence':'nluc_luminescence', 'Well':'well','Content':'content'}, inplace=True)\n",
    "    #add well row and column columns    \n",
    "    combined_nluc['well_row'] = combined_nluc.well.str[:1]\n",
    "    combined_nluc['well_col'] = combined_nluc.well.str[-2:]\n",
    "\n",
    "    #prepend layout well col with a 0\n",
    "    layout = layout_df.copy()\n",
    "    layout['well_col'] = layout_df['well_col'].astype(str).str.zfill(width=2)\n",
    "    #change df content data type to string\n",
    "    combined_nluc.content = combined_nluc.content.astype(str)\n",
    "    #merge layout with combined\n",
    "    combined_named_nluc = pd.merge(combined_nluc, layout, on=['well_row','well_col'])\n",
    "    #convert well_col column data type to string so it is excluded from the next bit\n",
    "    combined_named_nluc.well_col = combined_named_nluc.well_col.astype(np.str)\n",
    "    #get plate calibrator value\n",
    "    plate_calibrator = combined_named_nluc.loc[(combined_named_nluc['name'] == 'plate_calibrator')]['nluc_luminescence'].values[0]\n",
    "    #normalise to plate calibrator value\n",
    "    combined_named_nluc['norm_nluc_luminescence'] = combined_named_nluc['nluc_luminescence']/plate_calibrator\n",
    "    # print(combined_named_nluc)\n",
    "    # print(combined_named_nluc)\n",
    "    # print(combined_named_protein)\n",
    "    #merge combined_named_nluc with combined_named_protein\n",
    "    combined = pd.merge(combined_named_nluc,combined_named_protein, on=['name','condition'], how = 'left')\n",
    "\n",
    "    #mask any values less than 400 (turn into NaNs)  \n",
    "    # combined['fluc_luminescence'] = combined.fluc_luminescence.mask(combined.fluc_luminescence < 340)\n",
    "    # combined['nluc_luminescence'] = combined.nluc_luminescence.mask(combined.nluc_luminescence < 340)\n",
    "\n",
    "    #change df content data type to string\n",
    "    combined.content = combined.content.astype(str)\n",
    "\n",
    "    #add new column, nluc/absorbance\n",
    "    combined['nluc/absorbance'] = combined.norm_nluc_luminescence / combined.norm_absorbance\n",
    "    #remove NaNs\n",
    "    combined_named_no_null = combined[pd.notnull(combined['nluc/absorbance'])]\n",
    "    #add date to the data\n",
    "    combined_named_no_null_date = combined_named_no_null.copy()\n",
    "    combined_named_no_null_date['date'] = date\n",
    "    #filter columns, only keeping name well\tcontent\tnluc_luminescence\twell_row\twell_col condition norm_nluc_luminescence absorbance norm_absorbance nluc/absorbance date\n",
    "    combined_named_no_null_date = combined_named_no_null_date[['name','well','content','nluc_luminescence','well_row','well_col','condition','norm_nluc_luminescence','absorbance','norm_absorbance','nluc/absorbance','date']]\n",
    "    # combined_named_no_null_date = combined_named_no_null_date[['well','content','nluc_luminescence','well_row','well_col','condition','norm_nluc_luminescence','absorbance','norm_absorbance','nluc/absorbance','date']]\n",
    "\n",
    "    #make csv of raw data\n",
    "    combined_named_no_null_date.to_csv(output_file_raw, encoding='utf-8', index=False)\n",
    "    #make new df with mean luminescence\n",
    "    # mean = combined_named_no_null[['name','condition', 'nluc/absorbance']].groupby(['name','condition']).mean().reset_index()\n",
    "    ######mean = combined_named_no_null[['name', 'nluc/absorbance']].groupby('name').mean().reset_index()\n",
    "    # mean.rename(columns = {'nluc/absorbance':'mean_luminescence'}, inplace = True)\n",
    "    #add standard error\n",
    "    # standard_error = combined_named_no_null[['name','condition', 'nluc/absorbance']].groupby(['name','condition']).sem().reset_index()\n",
    "    #####standard_error = combined_named_no_null[['name','nluc/absorbance']].groupby('name').sem().reset_index()\n",
    "    # standard_error.rename(columns = {'nluc/absorbance':'standard_error'}, inplace=True)\n",
    "    # mean_samples = pd.merge(mean, standard_error, on=['name','condition'])\n",
    "    #####mean_samples = pd.merge(mean, standard_error, on='name')\n",
    "    #add date of experiment\n",
    "    # mean_samples['date'] = date\n",
    "    #create output file\n",
    "    # mean_samples.to_csv(output_file_means, encoding='utf-8', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(plate_list, date, file_suffix):\n",
    "    \"\"\"add variables named after plates in plate list and then create output files\"\"\"\n",
    "    date = date\n",
    "    #find all xlsx files recursively in the 'to_be_sorted' folder\n",
    "    xlsx_filenames = glob.glob(f'../../data/luminescence/root_lucN_luminescence/{date}/*.xlsx', recursive=True)\n",
    "    #run the xlsx_2_csv function across all xlsx file in to_be_sorted folder\n",
    "    list(map(xlsx_2_csv,xlsx_filenames))\n",
    "    \n",
    "    for plate_letter in plate_list:\n",
    "        #input_fluc = f'../../data/luminescence/to_be_sorted/{date}/lucf_plate{plate_number}{file_suffix}.csv'\n",
    "        input_protein1 = f'../../data/luminescence/root_lucN_luminescence/{date}/root_protein_pierce660nm_13.10.22_plate1_h20blank_inclraw.csv'\n",
    "        input_protein2 = f'../../data/luminescence/root_lucN_luminescence/{date}/root_protein_pierce660nm_13.10.22_plate2_h20blank_inclraw.csv'\n",
    "        layout_protein1 = f'../../data/luminescence/root_lucN_luminescence/{date}/layout_protein_plate1.csv'\n",
    "        layout_protein2 = f'../../data/luminescence/root_lucN_luminescence/{date}/layout_protein_plate2.csv'\n",
    "        \n",
    "        \n",
    "        #input_nluc = f'../../data/luminescence/to_be_sorted/{date}/lucn_plate{plate_number}{file_suffix}.csv'\n",
    "        input_nluc = f'../../data/luminescence/root_lucN_luminescence/{date}/root_lucn{file_suffix}_plate{plate_letter}_2000gain_5ulcalibrator.csv'\n",
    "        layout = f'../../data/luminescence/root_lucN_luminescence/{date}/layout_plate{plate_letter}.csv'\n",
    "        # output = f'../../data/luminescence/root_lucN_luminescence/{date}/plate{plate_letter}_output_means.csv'\n",
    "        output_raw = f'../../data/luminescence/root_lucN_luminescence/{date}/plate{plate_letter}_output_raw.csv'\n",
    "        #combine the csvs\n",
    "        combine_csvs(input_protein1,input_protein2,input_nluc,layout,layout_protein1,layout_protein2,date,output_raw)\n",
    "    #make directory in plotting folder\n",
    "    if not os.path.exists(f'../../data/plots/luminescence/{date}'):\n",
    "        os.mkdir(f'../../data/plots/luminescence/{date}')\n",
    "    #make another directory in the src folder\n",
    "    if not os.path.exists(f'../../src/plotting/luminescence/{date}'):\n",
    "        os.mkdir(f'../../src/plotting/luminescence/{date}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main([1,2], '27.9.21',\"_270921\")\n",
    "main(['A','B','C'], '13.10.22',\"_131022\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use os.scandir when scanning a directory, this is the fastest way according to Matt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rename columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge layout with combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add new column, nluc/fluc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #set style to ticks\n",
    "# sns.set(style=\"ticks\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate data by condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nitrate_free = combined_named_no_null[combined_named_no_null.condition == 'nitrate_free']\n",
    "# #reset indexes so residuals can be calculated later\n",
    "# nitrate_free.reset_index(inplace=True)\n",
    "\n",
    "# nitrate_2hrs_morning = combined_named_no_null[combined_named_no_null.condition == 'nitrate_2hrs_morning']\n",
    "# nitrate_2hrs_morning.reset_index(inplace=True)\n",
    "\n",
    "# nitrate_overnight = combined_named_no_null[combined_named_no_null.condition == 'nitrate_overnight']\n",
    "# nitrate_overnight.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Categorical(combined_named_no_null.condition)\n",
    "# names = combined_named_no_null.condition.unique()\n",
    "# for name in names:\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61814b3769a66904c2a16b3ed0b96552c32ee93da6b5ac19d252723e448480da"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('PromoterArchitecturePipeline': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
