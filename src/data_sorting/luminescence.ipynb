{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Sort the protoplast luminescence data from the xlsx output from the Glariostar platereader. \n",
    "Use 2 input excels at a time (one firefly, one nanoluc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlsx_2_csv(xlsx):  \n",
    "    \"\"\" Function to read and convert xlsx file to csv file. Also return the data (name of the folder the xlsx is in)\"\"\"\n",
    "    \n",
    "    # Read in the xlsx file, second sheet\n",
    "    file = pd.read_excel(xlsx, 'Table End point', index_col=None) \n",
    "    \n",
    "    filename = os.path.basename(xlsx)\n",
    "    removed_extension = os.path.splitext(filename)[0]\n",
    "    path = Path(xlsx).parent #find parent directory to the one the xlsx fields are in\n",
    "    date = Path(xlsx)\n",
    "    \n",
    "    file.to_csv(f'{path}/{removed_extension}.csv', encoding='utf-8', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csvs(input_fluc,input_nluc,layout_csv,date,output_file_means,output_file_raw):\n",
    "    \"\"\"Function to combine two csv files containingg luminescence data, and label values using layout csv file (plate layout)\"\"\"\n",
    "    #read in files\n",
    "    fluc = pd.read_csv(input_fluc, header=0)\n",
    "    nluc = pd.read_csv(input_nluc, header=0)\n",
    "    #rename 3rd column\n",
    "    fluc.rename(columns={fluc.columns[2]: \"Luminescence\" }, inplace = True)\n",
    "    nluc.rename(columns={nluc.columns[2]: \"Luminescence\" }, inplace = True)\n",
    "    layout_df = pd.read_csv(layout_csv, header=0)\n",
    "    #make new df with correct column names, including both fluc and nluc data\n",
    "    #combined = fluc[['Well\\nRow', 'Well\\nCol', 'Content','Average over replicates based on Blank corrected (No filter)']].copy()\n",
    "    combined = fluc[['Well','Content','Luminescence']].copy()  \n",
    "    #combined.rename(columns = {'Well\\nRow':'well_row', 'Well\\nCol':'well_col', 'Content':'content', 'Average over replicates based on Blank corrected (No filter)':'fluc_luminescence'}, inplace = True)\n",
    "    combined.rename(columns = {'Luminescence':'fluc_luminescence'}, inplace = True)\n",
    "    #merge with nluc\n",
    "    combined = pd.merge(combined, nluc, on=['Well','Content'], how='left')\n",
    "    #combined['nluc_luminescence'] = nluc['Luminescence'].copy()\n",
    "    #rename nluc luminescence\n",
    "    combined.rename(columns = {'Luminescence':'nluc_luminescence', 'Well':'well','Content':'content'}, inplace=True)\n",
    "    #add well row and column columns    \n",
    "    combined['well_row'] = combined.well.str[:1]\n",
    "    combined['well_col'] = combined.well.str[-2:]\n",
    "    #mask any values less than 400 (turn into NaNs)  \n",
    "    combined['fluc_luminescence'] = combined.fluc_luminescence.mask(combined.fluc_luminescence < 340)\n",
    "    combined['nluc_luminescence'] = combined.nluc_luminescence.mask(combined.nluc_luminescence < 340)\n",
    "    #prepend layout well col with a 0\n",
    "    layout = layout_df.copy()\n",
    "    layout['well_col'] = layout_df['well_col'].astype(str).str.zfill(width=2)\n",
    "    #change df content data type to string\n",
    "    combined.content = combined.content.astype(str)\n",
    "    #merge layout with combined\n",
    "    combined_named = pd.merge(combined, layout, on=['well_row','well_col'])\n",
    "    #convert well_col column data type to string so it is excluded from the next bit\n",
    "    combined_named.well_col = combined_named.well_col.astype(np.str)\n",
    "    #add new column, nluc/fluc\n",
    "    combined_named['nluc/fluc'] = combined_named.nluc_luminescence / combined_named.fluc_luminescence\n",
    "    #remove NaNs\n",
    "    combined_named_no_null = combined_named[pd.notnull(combined_named['nluc/fluc'])]\n",
    "    #add date to the data\n",
    "    combined_named_no_null_date = combined_named_no_null.copy()\n",
    "    combined_named_no_null_date['date'] = date\n",
    "    #make csv of raw data\n",
    "    combined_named_no_null_date.to_csv(output_file_raw, encoding='utf-8', index=False)\n",
    "    #make new df with mean luminescence\n",
    "    mean = combined_named_no_null[['name','condition', 'nluc/fluc']].groupby(['name','condition']).mean().reset_index()\n",
    "    ######mean = combined_named_no_null[['name', 'nluc/fluc']].groupby('name').mean().reset_index()\n",
    "    mean.rename(columns = {'nluc/fluc':'mean_luminescence'}, inplace = True)\n",
    "    #add standard error\n",
    "    standard_error = combined_named_no_null[['name','condition', 'nluc/fluc']].groupby(['name','condition']).sem().reset_index()\n",
    "    #####standard_error = combined_named_no_null[['name','nluc/fluc']].groupby('name').sem().reset_index()\n",
    "    standard_error.rename(columns = {'nluc/fluc':'standard_error'}, inplace=True)\n",
    "    mean_samples = pd.merge(mean, standard_error, on=['name','condition'])\n",
    "    #####mean_samples = pd.merge(mean, standard_error, on='name')\n",
    "    #add date of experiment\n",
    "    mean_samples['date'] = date\n",
    "    #create output file\n",
    "    mean_samples.to_csv(output_file_means, encoding='utf-8', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(plate_list, date, file_suffix):\n",
    "    \"\"\"add variables named after plates in plate list and then create output files\"\"\"\n",
    "    date = date\n",
    "    #find all xlsx files recursively in the 'to_be_sorted' folder\n",
    "    xlsx_filenames = glob.glob(f'../../data/luminescence/to_be_sorted/{date}/*.xlsx', recursive=True)\n",
    "    #run the xlsx_2_csv function across all xlsx file in to_be_sorted folder\n",
    "    list(map(xlsx_2_csv,xlsx_filenames))\n",
    "    for plate_number in plate_list:\n",
    "        #input_fluc = f'../../data/luminescence/to_be_sorted/{date}/lucf_plate{plate_number}{file_suffix}.csv'\n",
    "        input_fluc = f'../../data/luminescence/to_be_sorted/{date}/lucf{file_suffix}_plate{plate_number}.csv'\n",
    "        #input_nluc = f'../../data/luminescence/to_be_sorted/{date}/lucn_plate{plate_number}{file_suffix}.csv'\n",
    "        input_nluc = f'../../data/luminescence/to_be_sorted/{date}/lucn{file_suffix}_plate{plate_number}.csv'\n",
    "        layout = f'../../data/luminescence/to_be_sorted/{date}/layout_plate{plate_number}.csv'\n",
    "        output = f'../../data/luminescence/to_be_sorted/{date}/plate{plate_number}_output_means.csv'\n",
    "        output_raw = f'../../data/luminescence/to_be_sorted/{date}/plate{plate_number}_output_raw.csv'\n",
    "        #combine the csvs\n",
    "        combine_csvs(input_fluc,input_nluc,layout,date,output,output_raw)\n",
    "    #make directory in plotting folder\n",
    "    if not os.path.exists(f'../../data/plots/luminescence/{date}'):\n",
    "        os.mkdir(f'../../data/plots/luminescence/{date}')\n",
    "    #make another directory in the src folder\n",
    "    if not os.path.exists(f'../../src/plotting/luminescence/{date}'):\n",
    "        os.mkdir(f'../../src/plotting/luminescence/{date}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main([1,2], '27.9.21',\"_270921\")\n",
    "main([1,2,3,4], '27.04.22',\"_270422\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use os.scandir when scanning a directory, this is the fastest way according to Matt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rename columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge layout with combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add new column, nluc/fluc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-b97910ea8c7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#set style to ticks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ticks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_codes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "#set style to ticks\n",
    "sns.set(style=\"ticks\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate data by condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nitrate_free = combined_named_no_null[combined_named_no_null.condition == 'nitrate_free']\n",
    "# #reset indexes so residuals can be calculated later\n",
    "# nitrate_free.reset_index(inplace=True)\n",
    "\n",
    "# nitrate_2hrs_morning = combined_named_no_null[combined_named_no_null.condition == 'nitrate_2hrs_morning']\n",
    "# nitrate_2hrs_morning.reset_index(inplace=True)\n",
    "\n",
    "# nitrate_overnight = combined_named_no_null[combined_named_no_null.condition == 'nitrate_overnight']\n",
    "# nitrate_overnight.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nitrate_free\n",
      "nitrate_2hrs_morning\n",
      "nitrate_overnight\n"
     ]
    }
   ],
   "source": [
    "pd.Categorical(combined_named_no_null.condition)\n",
    "names = combined_named_no_null.condition.unique()\n",
    "for name in names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61814b3769a66904c2a16b3ed0b96552c32ee93da6b5ac19d252723e448480da"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('PromoterArchitecturePipeline': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
